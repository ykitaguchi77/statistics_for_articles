{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1MxfhEzx9di3AoOiOjEUE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/statistics_for_articles/blob/main/Refractive_change_blepharoptosis_surgery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Refractive change in blepharoptosis surgery**"
      ],
      "metadata": {
        "id": "OqObWQc1_T1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yup3T2Lay4gD",
        "outputId": "f124d3db-78d4-40f5-8219-7f354d88bb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 300)\n",
        "pd.set_option('display.max_rows', 300)"
      ],
      "metadata": {
        "id": "9nC8Dlyz7RBz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂.xlsx\"\n",
        "\n",
        "data = pd.read_excel(xlsx_path, header=1)\n",
        "\n",
        "# Display the first few rows of the dataframe and its columns to understand its structure\n",
        "#data"
      ],
      "metadata": {
        "id": "nVb210bozJ73",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Filter rows where surgery is bilateral (手術側 == 'B')\n",
        "bilateral_cases = data[data['手術側'] == 'B'].copy()\n",
        "unilateral_cases = data[data['手術側'] != 'B'].copy()\n",
        "unilateral_right_cases = data[data['手術側'] == 'R'].copy()\n",
        "unilateral_left_cases = data[data['手術側'] == 'L'].copy()\n",
        "print(f\"Number of bilateral cases: {len(bilateral_cases)}\")\n",
        "print(f\"Number of unilateral cases: {len(unilateral_cases)}\")\n",
        "\n",
        "# Step 2: Duplicate these rows for 'R' and 'L'\n",
        "bilateral_right_cases = bilateral_cases.copy()\n",
        "bilateral_left_cases = bilateral_cases.copy()\n",
        "\n",
        "# Assign 'R' and 'L' to the new surgery side columns\n",
        "bilateral_right_cases.loc[:, '手術側'] = 'R'\n",
        "bilateral_left_cases.loc[:, '手術側'] = 'L'\n",
        "\n",
        "# Step 3: Concatenate the modified bilateral and unilateral cases\n",
        "right_cases = pd.concat([bilateral_right_cases, unilateral_right_cases])\n",
        "left_cases = pd.concat([bilateral_left_cases, unilateral_left_cases])\n",
        "\n",
        "# Step 3: Rename and reallocate columns containing 'R' or 'L' for bilateral cases\n",
        "for column in right_cases.columns:\n",
        "    if ' R' in column:\n",
        "        # Extract the base column name without ' R'\n",
        "        new_column_name = column.replace(' R', '')\n",
        "        # Copy data to a new column without side specification\n",
        "        right_cases.loc[:, new_column_name] = right_cases[column]\n",
        "        # Drop the original ' R' column\n",
        "        right_cases.drop(column, axis=1, inplace=True)\n",
        "    elif ' L' in column:\n",
        "        # # Extract the base column name without ' L'\n",
        "        # new_column_name = column.replace(' L', '')\n",
        "        # # Copy data to a new column without side specification\n",
        "        # right_cases.loc[:, new_column_name] = right_cases[column]\n",
        "        # Drop the original ' L' column\n",
        "        right_cases.drop(column, axis=1, inplace=True)\n",
        "\n",
        "for column in left_cases.columns:\n",
        "    if ' R' in column:\n",
        "        # # Extract the base column name without ' R'\n",
        "        # new_column_name = column.replace(' R', '')\n",
        "        # # Copy data to a new column without side specification\n",
        "        # left_cases.loc[:, new_column_name] = left_cases[column]\n",
        "        # # Drop the original ' R' column\n",
        "        left_cases.drop(column, axis=1, inplace=True)\n",
        "    elif ' L' in column:\n",
        "        # Extract the base column name without ' L'\n",
        "        new_column_name = column.replace(' L', '')\n",
        "        # Copy data to a new column without side specification\n",
        "        left_cases.loc[:, new_column_name] = left_cases[column]\n",
        "        # Drop the original ' L' column\n",
        "        left_cases.drop(column, axis=1, inplace=True)\n",
        "\n",
        "# Combine the duplicated rows back into a single dataframe\n",
        "final_df = pd.concat([right_cases, left_cases])\n",
        "final_df = final_df.sort_values(by='ID').reset_index(drop=True)\n",
        "# ソート後のデータフレームを表示して確認\n",
        "#final_df\n",
        "\n",
        "#final_df.to_excel('output.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "knMc1iJR6Ciu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f89c9b0-333e-448e-c0c4-3370b2733648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of bilateral cases: 94\n",
            "Number of unilateral cases: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['波面3M'] = final_df[['波面3M', '波面4M', '波面post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['波面4M', '波面post'], inplace=True)\n",
        "    print(\"波面3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['AveK 3M'] = final_df[['AveK 3M', 'AveK post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['AveK post'], inplace=True)\n",
        "    print(\"AveK 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['CYL 3M'] = final_df[['CYL 3M', 'CYL post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['CYL post'], inplace=True)\n",
        "    print(\"CYL 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "lgJLhag6ELZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b4f4a6-54e8-41b5-b0d9-820cac9d9df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "波面3M updated!\n",
            "AveK 3M updated!\n",
            "CYL 3M updated!\n",
            "angle 3M updated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# レフケラの欠損値を削除：Drop rows with missing values only in specified columns\n",
        "specified_columns = ['AveK pre', 'AveK 3M', 'CYL pre', 'CYL 3M', 'angle pre', 'angle 3M', 'MRD-1 pre', 'MRD-1 3M']\n",
        "final_df = final_df.dropna(subset=specified_columns).reset_index(drop=True)\n",
        "\n",
        "# SPKの有無を数字に置換\n",
        "final_df[\"SPK pre\"] = final_df[\"SPK pre\"].replace({\"あり\": 1, \"なし\": 0})\n",
        "final_df[\"SPK post\"] = final_df[\"SPK post\"].replace({\"あり\": 1, \"なし\": 0})\n",
        "# 57行目の\"MRD-1 pre\"列の値を0.5に置換\n",
        "final_df.at[57, \"MRD-1 pre\"] = 0.5\n",
        "\n",
        "# # 挙筋機能\"good\"のカラムを10に置換\n",
        "# final_df[\"挙筋機能 pre\"] = final_df[\"挙筋機能 pre\"].replace(\"good\", 10)\n",
        "\n",
        "# 挙筋機能\"good\"のカラムを10に置換し、10より大きい値も10に制限する\n",
        "final_df[\"挙筋機能 pre\"] = final_df[\"挙筋機能 pre\"].replace(\"good\", 10)\n",
        "final_df[\"挙筋機能 pre\"] = pd.to_numeric(final_df[\"挙筋機能 pre\"], errors='coerce')\n",
        "final_df[\"挙筋機能 pre\"] = final_df[\"挙筋機能 pre\"].clip(upper=10)\n",
        "\n",
        "\n",
        "# \"MRD-1 3M\"列と\"挙筋機能 pre\"列をfloat型に変換\n",
        "final_df[\"MRD-1 pre\"] = final_df[\"MRD-1 pre\"].astype(float)\n",
        "final_df[\"MRD-1 3M\"] = final_df[\"MRD-1 3M\"].astype(float)\n",
        "final_df[\"挙筋機能 pre\"] = final_df[\"挙筋機能 pre\"].astype(float)\n",
        "\n",
        "final_df[\"sex\"] = final_df[\"sex\"].replace({\"M\": 1, \"F\": 0})\n",
        "final_df[\"手術側\"] = final_df[\"手術側\"].replace({\"L\": 1, \"R\": 0})\n",
        "\n",
        "#ΔMRD-1という列を新規に作成\n",
        "final_df[\"ΔMRD-1\"] = final_df[\"MRD-1 3M\"] - final_df[\"MRD-1 pre\"]\n",
        "\n",
        "final_df"
      ],
      "metadata": {
        "id": "Fb8lFR0bz-vy",
        "outputId": "8410391e-f0e3-4436-fc24-86f1a35a6805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'final_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-080cc1366665>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# レフケラの欠損値を削除：Drop rows with missing values only in specified columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mspecified_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'AveK pre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AveK 3M'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CYL pre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CYL 3M'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'angle pre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'angle 3M'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MRD-1 pre'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MRD-1 3M'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecified_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# SPKの有無を数字に置換\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_excel('眼瞼下垂_proprocessed1.1.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "qc9S9nxE3N49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########\n",
        "#分析用のカラムに変更。SIAの計算\n",
        "##########\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 元のカラムリスト\n",
        "original_columns = ['ID', 'name', 'date', 'birthday', 'age', 'sex', '手術側', '備考', '挙筋短縮術後', 'Unnamed: 9', 'date.1', '手術側.1', '波面', 'post date', 'CASIA post date', 'レフケラ post date', '手術側.2', '矯正視力pre', '矯正視力3M', 'preMS(4mm)>=0.3', '波面pre', '波面1Ｍ', '波面2Ｍ', '波面3M', 'AveK pre', 'AveK 3M', 'CYL pre', 'CYL 3M', 'angle pre', 'angle 3M', 'レフケラAVE pre', 'レフケラAVE 3～12M', 'レフケラAVE post', 'レフケラCYL pre', 'レフケラCYL 3～12M', 'レフケラCYL post', 'レフケラangle pre', 'レフケラangle 3～12M', 'レフケラangle post', 'MRD-1 pre', 'MRD-1 3M', '挙筋機能 pre', '挙筋機能 3M', 'SPK pre', 'SPK post']\n",
        "\n",
        "# 新しいカラムリスト\n",
        "new_columns = ['ID', 'name', 'date', 'birthday', 'age', 'sex', 'side', 'intraoocular_surg', 'corneal_matter', 'gla_surg', 'glaucoma', 'eyelid_surg', '備考', '挙筋短縮術後', 'Unnamed: 9', 'date.1', '手術側.1', '矯正視力pre', '矯正視力3M', '波面pre', '波面1Ｍ', '波面2Ｍ', '波面3M', 'AveK pre', 'AveK 3M', 'CYL pre', 'CYL 3M', 'angle pre', 'angle 3M', 'asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45', 'SIA_D', 'SIA_ax', 'MRD-1 pre', 'MRD-1 3M', 'levator_function', '挙筋機能 3M', 'SPK pre', 'SPK post']\n",
        "\n",
        "# カラムのマッピングを作成\n",
        "column_mapping = {\n",
        "    'ID': 'ID',\n",
        "    'name': 'name',\n",
        "    'date': 'date',\n",
        "    'birthday': 'birthday',\n",
        "    'age': 'age',\n",
        "    'sex': 'sex',\n",
        "    'side': '手術側',\n",
        "    'intraoocular_surg': None,\n",
        "    'corneal_matter': None,\n",
        "    'gla_surg': None,\n",
        "    'glaucoma': None,\n",
        "    'eyelid_surg': None,\n",
        "    '備考': '備考',\n",
        "    '挙筋短縮術後': '挙筋短縮術後',\n",
        "    'Unnamed: 9': 'Unnamed: 9',\n",
        "    'date.1': 'date.1',\n",
        "    '手術側.1': '手術側.1',\n",
        "    '矯正視力pre': '矯正視力pre',\n",
        "    '矯正視力3M': '矯正視力3M',\n",
        "    '波面pre': '波面pre',\n",
        "    '波面1Ｍ': '波面1Ｍ',\n",
        "    '波面2Ｍ': '波面2Ｍ',\n",
        "    '波面3M': '波面3M',\n",
        "    'AveK pre': 'AveK pre',\n",
        "    'AveK 3M': 'AveK 3M',\n",
        "    'CYL pre': 'CYL pre',\n",
        "    'CYL 3M': 'CYL 3M',\n",
        "    'angle pre': 'angle pre',\n",
        "    'angle 3M': 'angle 3M',\n",
        "    'MRD-1 pre': 'MRD-1 pre',\n",
        "    'MRD-1 3M': 'MRD-1 3M',\n",
        "    'levator_function': '挙筋機能 pre',\n",
        "    '挙筋機能 3M': '挙筋機能 3M',\n",
        "    'SPK pre': 'SPK pre',\n",
        "    'SPK post': 'SPK post'\n",
        "}\n",
        "\n",
        "# データを読み込む（ファイル名は適宜変更してください）\n",
        "df = pd.read_excel('眼瞼下垂_proprocessed1.1.xlsx')\n",
        "\n",
        "# 新しいデータフレームを作成\n",
        "new_df = pd.DataFrame()\n",
        "\n",
        "# 新しいカラムに対応するデータを設定\n",
        "for new_col in new_columns:\n",
        "    if new_col in column_mapping and column_mapping[new_col] is not None and column_mapping[new_col] in df.columns:\n",
        "        new_df[new_col] = df[column_mapping[new_col]]\n",
        "    else:\n",
        "        new_df[new_col] = None\n",
        "\n",
        "# asg_0_pre と asg_45_pre の計算\n",
        "new_df['asg_0_pre'] = np.abs(new_df['CYL pre']) * np.cos(np.radians(new_df['angle pre'] * 2))\n",
        "new_df['asg_45_pre'] = np.abs(new_df['CYL pre']) * np.sin(np.radians(new_df['angle pre'] * 2))\n",
        "\n",
        "# asg_0_3M と asg_45_3M の計算\n",
        "new_df['asg_0_3M'] = np.abs(new_df['CYL 3M']) * np.cos(np.radians(new_df['angle 3M'] * 2))\n",
        "new_df['asg_45_3M'] = np.abs(new_df['CYL 3M']) * np.sin(np.radians(new_df['angle 3M'] * 2))\n",
        "\n",
        "# Δasg_0 と Δasg_45 の計算\n",
        "new_df['Δasg_0'] = new_df['asg_0_3M'] - new_df['asg_0_pre']\n",
        "new_df['Δasg_45'] = new_df['asg_45_3M'] - new_df['asg_45_pre']\n",
        "\n",
        "# SIA_D と SIA_ax の計算\n",
        "new_df['SIA_D'] = np.sqrt(new_df['Δasg_0']**2 + new_df['Δasg_45']**2)\n",
        "new_df['SIA_ax'] = 0.5 * np.degrees(np.arctan2(new_df['Δasg_45'], new_df['Δasg_0']))\n",
        "\n",
        "# 新しいExcelファイルとして保存（ファイル名は適宜変更してください）\n",
        "new_df.to_excel('眼瞼下垂_proprocessed1.2.xlsx', index=False)\n",
        "\n",
        "print(\"新しいExcelファイルが作成されました。\")"
      ],
      "metadata": {
        "id": "8qITWJ6y4Ox8",
        "outputId": "778ac774-4702-49ec-e9c0-07b0bb710ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '眼瞼下垂_proprocessed1.1.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-88ce1bf8327f>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# データを読み込む（ファイル名は適宜変更してください）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'眼瞼下垂_proprocessed1.1.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# 新しいデータフレームを作成\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1564\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1420\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '眼瞼下垂_proprocessed1.1.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessed_dataを用いて解析**"
      ],
      "metadata": {
        "id": "lns4IjGOVq77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J5sUBakWORy",
        "outputId": "ab6d1ead-2335-4a44-e1cb-6c40daa7e989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 300)\n",
        "pd.set_option('display.max_rows', 300)"
      ],
      "metadata": {
        "id": "C-JwDuMtWLWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂_proprocessed.xlsx\"\n",
        "\n",
        "data = pd.read_excel(xlsx_path, header=0)\n",
        "\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "id": "12LgQoOAWQqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2f4257-f9db-459a-d735-8fd32388b996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 112\n",
            "Total number of rows: 189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 眼瞼手術歴を除外\n",
        "##################\n",
        "\n",
        "# Filter out rows where 'exclude' column is equal to 1\n",
        "data = data[data['eyelid_surg'] != 1]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY-iSF1bSX-q",
        "outputId": "2771b495-2279-4a72-f020-e9c1880718dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 107\n",
            "Total number of rows: 179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# 角膜混濁/HCL症例を除外\n",
        "########################\n",
        "\n",
        "# Filter out rows where 'exclude' column is equal to 1\n",
        "data = data[data['corneal_matter'] != 1]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9ZtBRlEuM30",
        "outputId": "f1f65278-854e-4535-a3e5-55dbb6b7169a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 101\n",
            "Total number of rows: 167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 緑内障症例を抽出\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['glaucoma'] == 1]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kJkYilnu7sX",
        "outputId": "86f194fe-71a7-4812-ebd8-698001d21ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 31\n",
            "Total number of rows: 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 緑内障症例を除外\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['glaucoma'] == 0]\n",
        "\n",
        "# Display the first few rows of the resulting data to confirm\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZtMiHX_vBbw",
        "outputId": "aa7e1100-c81d-4beb-ddfe-f71df0721bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 眼内手術歴なしを抽出\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['intraoocular_surg'] == 0]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBESEHHnTShV",
        "outputId": "1ec93f46-d05f-406f-fea7-7e876b64d308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 眼内手術歴ありを抽出\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['intraoocular_surg'] != 0]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uxhtfvYTrld",
        "outputId": "750334ce-4254-487e-eceb-428c25ce3eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 79\n",
            "Total number of rows: 129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 外れ値を除外\n",
        "##################\n",
        "\n",
        "def remove_outliers(data, columns):\n",
        "    for column in columns:\n",
        "        q1 = data[column].quantile(0.25)\n",
        "        q3 = data[column].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "        data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
        "    return data\n",
        "\n",
        "# 外れ値を除外する列のリスト\n",
        "columns_to_remove_outliers = [\"asg_0_pre\", \"asg_45_pre\", \"MRD-1 3M\"]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWXMZ2qqHwtR",
        "outputId": "f5512bcf-24f0-4263-9b2e-8357c91c9761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 104\n",
            "Total number of rows: 172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 緑内障手術歴ありを抽出\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['gla_surg'] == 1]\n",
        "\n",
        "# Display the first few rows of the resulting data to confirm\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qisi3sTiYrYv",
        "outputId": "85f124e7-5442-4654-c89a-58a930942d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 緑内障手術歴なしを抽出\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['gla_surg'] == 0]\n",
        "\n",
        "# Display the first few rows of the resulting data to confirm\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-6d2sq7YxuI",
        "outputId": "eff557e9-b196-40d0-ff61-ee7acda67ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**術前の屈折（sideによる有意差）**"
      ],
      "metadata": {
        "id": "tbN_MZ8bz-cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリのインポート\n",
        "from scipy.stats import ttest_ind\n",
        "import pandas as pd\n",
        "\n",
        "# 独立t検定のための平均、標準偏差、およびp値を計算する関数\n",
        "def calculate_independent_statistics(side0, side1):\n",
        "    mean_side0 = side0.mean()\n",
        "    std_side0 = side0.std()\n",
        "    mean_side1 = side1.mean()\n",
        "    std_side1 = side1.std()\n",
        "\n",
        "    t_test = ttest_ind(side0.dropna(), side1.dropna(), nan_policy='omit')\n",
        "\n",
        "    return {\n",
        "        'side0_mean_sd': f\"{mean_side0:.3f} ± {std_side0:.3f}\",\n",
        "        'side1_mean_sd': f\"{mean_side1:.3f} ± {std_side1:.3f}\",\n",
        "        'p_value': f\"{t_test.pvalue:.3e}\"\n",
        "    }\n",
        "\n",
        "# サイドごとの統計量を計算し、結果を表示する関数\n",
        "def process_and_print_statistics(data, column_name):\n",
        "    side0 = data[data['side'] == 0][column_name]\n",
        "    side1 = data[data['side'] == 1][column_name]\n",
        "    stats = calculate_independent_statistics(side0, side1)\n",
        "    print(f\"{column_name}: {stats}\")\n",
        "\n",
        "# 統計量を計算する列のリスト\n",
        "columns_to_process = ['asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45']\n",
        "\n",
        "# 各列に対して統計量を計算し、結果を表示\n",
        "for column in columns_to_process:\n",
        "    process_and_print_statistics(data, column)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hny5i4F6Dbo0",
        "outputId": "afcbc978-7ae8-4edd-9022-28624209500f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asg_0_pre: {'side0_mean_sd': '-0.179 ± 0.954', 'side1_mean_sd': '-0.037 ± 1.007', 'p_value': '3.620e-01'}\n",
            "asg_45_pre: {'side0_mean_sd': '0.078 ± 0.476', 'side1_mean_sd': '-0.128 ± 0.573', 'p_value': '1.399e-02'}\n",
            "asg_0_3M: {'side0_mean_sd': '0.042 ± 1.100', 'side1_mean_sd': '0.210 ± 1.089', 'p_value': '3.334e-01'}\n",
            "asg_45_3M: {'side0_mean_sd': '0.077 ± 0.626', 'side1_mean_sd': '-0.235 ± 0.694', 'p_value': '3.257e-03'}\n",
            "Δasg_0: {'side0_mean_sd': '0.221 ± 0.605', 'side1_mean_sd': '0.247 ± 0.603', 'p_value': '7.837e-01'}\n",
            "Δasg_45: {'side0_mean_sd': '-0.001 ± 0.538', 'side1_mean_sd': '-0.106 ± 0.676', 'p_value': '2.761e-01'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr, linregress\n",
        "\n",
        "def calculate_correlation_and_p_value(column1, column2):\n",
        "    column1_clean = column1.dropna()\n",
        "    column2_clean = column2.dropna()\n",
        "    common_index = column1_clean.index.intersection(column2_clean.index)\n",
        "    column1_clean = column1_clean.loc[common_index]\n",
        "    column2_clean = column2_clean.loc[common_index]\n",
        "\n",
        "    correlation, p_value = pearsonr(column1_clean, column2_clean)\n",
        "    return correlation, p_value, column1_clean, column2_clean\n",
        "\n",
        "def analyze_and_plot_correlation_with_MRD1_pre(data, target_column, x_lim, y_lim):\n",
        "    MRD1_pre = data['MRD-1 pre']\n",
        "    correlation, p_value, target_data_clean, MRD1_pre_clean = calculate_correlation_and_p_value(data[target_column], MRD1_pre)\n",
        "\n",
        "    # Calculate regression line\n",
        "    slope, intercept, _, _, _ = linregress(MRD1_pre_clean, target_data_clean)\n",
        "    regression_line = slope * MRD1_pre_clean + intercept\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.scatter(MRD1_pre_clean, target_data_clean, alpha=0.5, color='black', s=200)\n",
        "    plt.plot(MRD1_pre_clean, regression_line, color='red', linewidth=5)\n",
        "    plt.title(f'Correlation between {target_column} and MRD-1 pre\\n'\n",
        "              f'r={correlation:.3f}, p={p_value:.3f}', fontsize=24)  # Reduced font size by half\n",
        "    plt.xlabel('MRD-1 pre', fontsize=44)\n",
        "    plt.ylabel(target_column, fontsize=44)\n",
        "    # Legend removed\n",
        "    plt.xlim(x_lim)\n",
        "    plt.ylim(y_lim)\n",
        "    plt.xticks(fontsize=36)\n",
        "    plt.yticks(fontsize=36)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 調査する列のリスト\n",
        "columns_to_analyze = ['asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45']\n",
        "\n",
        "# グラフのスケールを決定\n",
        "x_min = data['MRD-1 pre'].min()\n",
        "x_max = data['MRD-1 3M'].max()\n",
        "y_min = min(data[col].min() for col in columns_to_analyze)\n",
        "y_max = max(data[col].max() for col in columns_to_analyze)\n",
        "\n",
        "# 各列に対して相関を分析してグラフを描画\n",
        "for column in columns_to_analyze:\n",
        "    analyze_and_plot_correlation_with_MRD1_pre(data, column, (x_min, x_max), (y_min, y_max))"
      ],
      "metadata": {
        "id": "VQ5LDk2lGRY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr, linregress\n",
        "\n",
        "def calculate_correlation_and_p_value(column1, column2):\n",
        "    column1_clean = column1.dropna()\n",
        "    column2_clean = column2.dropna()\n",
        "    common_index = column1_clean.index.intersection(column2_clean.index)\n",
        "    column1_clean = column1_clean.loc[common_index]\n",
        "    column2_clean = column2_clean.loc[common_index]\n",
        "\n",
        "    correlation, p_value = pearsonr(column1_clean, column2_clean)\n",
        "    return correlation, p_value, column1_clean, column2_clean\n",
        "\n",
        "def analyze_and_plot_correlation_with_MRD1_pre(data, target_column, x_lim, y_lim):\n",
        "    MRD1_pre = data['MRD-1 3M']\n",
        "    correlation, p_value, target_data_clean, MRD1_pre_clean = calculate_correlation_and_p_value(data[target_column], MRD1_pre)\n",
        "\n",
        "    # Calculate regression line\n",
        "    slope, intercept, _, _, _ = linregress(MRD1_pre_clean, target_data_clean)\n",
        "    regression_line = slope * MRD1_pre_clean + intercept\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.scatter(MRD1_pre_clean, target_data_clean, alpha=0.5, color='black', s=200)\n",
        "    plt.plot(MRD1_pre_clean, regression_line, color='red', linewidth=5)\n",
        "    plt.title(f'Correlation between {target_column} and MRD-1 3M\\n'\n",
        "              f'r={correlation:.3f}, p={p_value:.3f}', fontsize=24)  # Reduced font size by half\n",
        "    plt.xlabel('MRD-1 3M', fontsize=44)\n",
        "    plt.ylabel(target_column, fontsize=44)\n",
        "    # Legend removed\n",
        "    plt.xlim(x_lim)\n",
        "    plt.ylim(y_lim)\n",
        "    plt.xticks(fontsize=36)\n",
        "    plt.yticks(fontsize=36)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 調査する列のリスト\n",
        "columns_to_analyze = ['asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45']\n",
        "\n",
        "# グラフのスケールを決定\n",
        "x_min = data['MRD-1 pre'].min()\n",
        "x_max = data['MRD-1 3M'].max()\n",
        "y_min = min(data[col].min() for col in columns_to_analyze)\n",
        "y_max = max(data[col].max() for col in columns_to_analyze)\n",
        "\n",
        "# 各列に対して相関を分析してグラフを描画\n",
        "for column in columns_to_analyze:\n",
        "    analyze_and_plot_correlation_with_MRD1_pre(data, column, (x_min, x_max), (y_min, y_max))"
      ],
      "metadata": {
        "id": "d3ofPJMylk48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr, linregress\n",
        "\n",
        "def calculate_correlation_and_p_value(column1, column2):\n",
        "    column1_clean = column1.dropna()\n",
        "    column2_clean = column2.dropna()\n",
        "    common_index = column1_clean.index.intersection(column2_clean.index)\n",
        "    column1_clean = column1_clean.loc[common_index]\n",
        "    column2_clean = column2_clean.loc[common_index]\n",
        "\n",
        "    correlation, p_value = pearsonr(column1_clean, column2_clean)\n",
        "    return correlation, p_value, column1_clean, column2_clean\n",
        "\n",
        "def analyze_and_plot_correlation_with_MRD1_pre(data, target_column, x_lim, y_lim):\n",
        "    MRD1_pre = data['ΔMRD-1']\n",
        "    correlation, p_value, target_data_clean, MRD1_pre_clean = calculate_correlation_and_p_value(data[target_column], MRD1_pre)\n",
        "\n",
        "    # Calculate regression line\n",
        "    slope, intercept, _, _, _ = linregress(MRD1_pre_clean, target_data_clean)\n",
        "    regression_line = slope * MRD1_pre_clean + intercept\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.scatter(MRD1_pre_clean, target_data_clean, alpha=0.5, color='black', s=200)\n",
        "    plt.plot(MRD1_pre_clean, regression_line, color='red', linewidth=5)\n",
        "    plt.title(f'Correlation between {target_column} and ΔMRD-1\\n'\n",
        "              f'r={correlation:.3f}, p={p_value:.3f}', fontsize=24)  # Reduced font size by half\n",
        "    plt.xlabel('ΔMRD-1', fontsize=44)\n",
        "    plt.ylabel(target_column, fontsize=44)\n",
        "    # Legend removed\n",
        "    plt.xlim(x_lim)\n",
        "    plt.ylim(y_lim)\n",
        "    plt.xticks(fontsize=36)\n",
        "    plt.yticks(fontsize=36)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 調査する列のリスト\n",
        "columns_to_analyze = ['asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45']\n",
        "\n",
        "# グラフのスケールを決定\n",
        "x_min = data['ΔMRD-1'].min()\n",
        "x_max = data['ΔMRD-1'].max()\n",
        "y_min = min(data[col].min() for col in columns_to_analyze)\n",
        "y_max = max(data[col].max() for col in columns_to_analyze)\n",
        "\n",
        "# 各列に対して相関を分析してグラフを描画\n",
        "for column in columns_to_analyze:\n",
        "    analyze_and_plot_correlation_with_MRD1_pre(data, column, (x_min, x_max), (y_min, y_max))"
      ],
      "metadata": {
        "id": "27vkLNUJuTz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MRD-1 preとasg45_preとの関係（side別）\n",
        "\n",
        "# MRD-1 pre との関連を調べてグラフを描画するための関数（side別）\n",
        "def analyze_and_plot_correlation_with_MRD1_pre_by_side(data, target_column):\n",
        "    sides = data['side'].unique()\n",
        "\n",
        "    for side in sides:\n",
        "        side_data = data[data['side'] == side]\n",
        "        MRD1_pre = side_data['MRD-1 pre']\n",
        "        correlation, p_value, target_data_clean, MRD1_pre_clean = calculate_correlation_and_p_value(side_data[target_column], MRD1_pre)\n",
        "\n",
        "        # 回帰線の計算\n",
        "        slope, intercept, _, _, _ = linregress(MRD1_pre_clean, target_data_clean)\n",
        "        regression_line = slope * MRD1_pre_clean + intercept\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(MRD1_pre_clean, target_data_clean, alpha=0.5, color='black', label='Data points')\n",
        "        plt.plot(MRD1_pre_clean, regression_line, color='red', label='Fit line')\n",
        "        plt.title(f'Correlation between {target_column} and MRD-1 pre (side {side})\\n'\n",
        "                  f'r={correlation:.3f}, p={p_value:.3f}')\n",
        "        plt.xlabel('MRD-1 pre')\n",
        "        plt.ylabel(target_column)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "# グラフ化したい列の指定\n",
        "target_column = 'asg_45_pre'\n",
        "\n",
        "# 指定した列に対して相関を分析し、side別にグラフを描画\n",
        "analyze_and_plot_correlation_with_MRD1_pre_by_side(data, target_column)\n"
      ],
      "metadata": {
        "id": "JYYMdEFxNHS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**各項目の変化**"
      ],
      "metadata": {
        "id": "Ct-sEXI_u8ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#正規分布でないことを確認\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import shapiro\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Extract relevant columns\n",
        "asg_0_pre = data['asg_0_pre']\n",
        "asg_0_3M = data['asg_0_3M']\n",
        "asg_45_pre = data['asg_45_pre']\n",
        "asg_45_3M = data['asg_45_3M']\n",
        "\n",
        "# Define a function to check normality\n",
        "def check_normality(data):\n",
        "    stat, p = shapiro(data.dropna())\n",
        "    return stat, p\n",
        "\n",
        "# Check normality for each group\n",
        "asg_0_pre_normality = check_normality(asg_0_pre)\n",
        "asg_0_3M_normality = check_normality(asg_0_3M)\n",
        "asg_45_pre_normality = check_normality(asg_45_pre)\n",
        "asg_45_3M_normality = check_normality(asg_45_3M)\n",
        "# Define a function to plot Q-Q plots\n",
        "def plot_qq(data, ax, title):\n",
        "    stats.probplot(data.dropna(), dist=\"norm\", plot=ax)\n",
        "    ax.set_title(title)\n",
        "\n",
        "# Create histograms and Q-Q plots for visual inspection\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "\n",
        "# Histograms\n",
        "sns.histplot(asg_0_pre.dropna(), kde=True, ax=axes[0, 0]).set(title='asg_0_pre Histogram')\n",
        "sns.histplot(asg_0_3M.dropna(), kde=True, ax=axes[0, 1]).set(title='asg_0_3M Histogram')\n",
        "sns.histplot(asg_45_pre.dropna(), kde=True, ax=axes[0, 2]).set(title='asg_45_pre Histogram')\n",
        "sns.histplot(asg_45_3M.dropna(), kde=True, ax=axes[0, 3]).set(title='asg_45_3M Histogram')\n",
        "\n",
        "# Q-Q plots\n",
        "plot_qq(asg_0_pre, axes[1, 0], 'asg_0_pre Q-Q Plot')\n",
        "plot_qq(asg_0_3M, axes[1, 1], 'asg_0_3M Q-Q Plot')\n",
        "plot_qq(asg_45_pre, axes[1, 2], 'asg_45_pre Q-Q Plot')\n",
        "plot_qq(asg_45_3M, axes[1, 3], 'asg_45_3M Q-Q Plot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "asg_0_pre_normality, asg_0_3M_normality, asg_45_pre_normality, asg_45_3M_normality\n"
      ],
      "metadata": {
        "id": "qoAh9sFvvCND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Wilcoxon signed-rank test to compare pre and 3M values\n",
        "asg_0_wilcoxon = stats.wilcoxon(asg_0_pre.dropna(), asg_0_3M.dropna())\n",
        "asg_45_wilcoxon = stats.wilcoxon(asg_45_pre.dropna(), asg_45_3M.dropna())\n",
        "\n",
        "asg_0_wilcoxon, asg_45_wilcoxon\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8c7NWGNv27q",
        "outputId": "a7d665ab-3f30-478f-8cb5-e679755b485a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(WilcoxonResult(statistic=4269.0, pvalue=1.9673109497202122e-06),\n",
              " WilcoxonResult(statistic=6715.0, pvalue=0.3250911574386459))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from scipy.stats import ttest_rel\n",
        "import pandas as pd\n",
        "\n",
        "# Define a function to remove outliers based on IQR\n",
        "def remove_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)\n",
        "    Q3 = data.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return data[(data >= lower_bound) & (data <= upper_bound)]\n",
        "\n",
        "# Define a function to calculate mean, SD, and p-value for paired t-test\n",
        "def calculate_statistics(pre, post):\n",
        "    pre_no_outliers = remove_outliers_iqr(pre)\n",
        "    post_no_outliers = remove_outliers_iqr(post)\n",
        "\n",
        "    matched_data = pd.DataFrame({'pre': pre_no_outliers, 'post': post}).dropna()\n",
        "\n",
        "    mean_pre = pre_no_outliers.mean()\n",
        "    std_pre = pre_no_outliers.std()\n",
        "    mean_post = matched_data['post'].mean()\n",
        "    std_post = matched_data['post'].std()\n",
        "\n",
        "    t_test = ttest_rel(matched_data['pre'], matched_data['post'], nan_policy='omit')\n",
        "\n",
        "    return {\n",
        "        'pre_mean_sd': f\"{mean_pre:.3f} ± {std_pre:.3f}\",\n",
        "        'post_mean_sd': f\"{mean_post:.3f} ± {std_post:.3f}\",\n",
        "        'p_value': f\"{t_test.pvalue:.3e}\"\n",
        "    }\n",
        "\n",
        "# Applying the function to evaluate pre and post-surgery changes in asg_0 and asg_45\n",
        "asg_0_stats = calculate_statistics(data['asg_0_pre'], data['asg_0_3M'])\n",
        "asg_45_stats = calculate_statistics(data['asg_45_pre'], data['asg_45_3M'])\n",
        "\n",
        "print(f\"change in asg_0: {asg_0_stats}\")\n",
        "print(f\"change in asg_45: {asg_45_stats}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLVcSTL6y71Y",
        "outputId": "cedb584c-f53f-4ac5-925c-9f7b024703b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change in asg_0: {'pre_mean_sd': '-0.088 ± 0.981', 'post_mean_sd': '0.160 ± 1.100', 'p_value': '2.195e-07'}\n",
            "change in asg_45: {'pre_mean_sd': '-0.016 ± 0.547', 'post_mean_sd': '-0.076 ± 0.671', 'p_value': '2.058e-01'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Linear regression analysis**\n",
        "\n",
        "線形回帰モデルのAIC（赤池情報量基準）を用いた多変量解析も併用\n",
        "\n"
      ],
      "metadata": {
        "id": "tpw9-FE4e8JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂_proprocessed.xlsx\"\n",
        "\n",
        "# data = pd.read_excel(xlsx_path, header=0)"
      ],
      "metadata": {
        "id": "AJQS1L8Y1iv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['ID', 'Δasg_0', 'Δasg_45', 'age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function', 'ΔMRD-1']\n",
        "regression_data = data[columns].dropna()\n",
        "\n",
        "# 各項目の統計量を表示\n",
        "statistics = regression_data.describe(include='all')\n",
        "\n",
        "# age, sex, sideの内訳を表示\n",
        "sex_counts = regression_data['sex'].value_counts()\n",
        "side_counts = regression_data['side'].value_counts()\n",
        "\n",
        "# idが同じものは1例に数える\n",
        "unique_sex_counts = regression_data.drop_duplicates(subset='ID')['sex'].value_counts()\n",
        "\n",
        "print(statistics)\n",
        "print(\"Sex counts:\\n\", sex_counts)\n",
        "print(\"Side counts:\\n\", side_counts)\n",
        "print(\"Unique Sex counts:\\n\", unique_sex_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSmcXd1ha2tv",
        "outputId": "97391fa5-c9a2-433e-d487-852e691903fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 ID   Δasg_0  Δasg_45      age      sex     side  asg_0_pre  \\\n",
            "count      165.0000 165.0000 165.0000 165.0000 165.0000 165.0000   165.0000   \n",
            "mean   9836909.8182   0.2478  -0.0537  75.4667   0.3758   0.4909    -0.0846   \n",
            "std    2562205.8830   0.6006   0.6045   8.5108   0.4858   0.5014     0.9873   \n",
            "min    1655521.0000  -1.2409  -3.7378  46.0000   0.0000   0.0000    -2.5256   \n",
            "25%    8037167.0000  -0.1286  -0.3331  70.0000   0.0000   0.0000    -0.7431   \n",
            "50%   10948582.0000   0.2203  -0.0240  76.0000   0.0000   0.0000    -0.0832   \n",
            "75%   11751109.0000   0.6020   0.2709  81.0000   1.0000   1.0000     0.5393   \n",
            "max   12422011.0000   2.0000   1.7585  92.0000   1.0000   1.0000     2.3776   \n",
            "\n",
            "       asg_45_pre  MRD-1 pre  MRD-1 3M  levator_function   ΔMRD-1  \n",
            "count    165.0000   165.0000  165.0000          165.0000 165.0000  \n",
            "mean      -0.0243     0.4636    3.4667            9.3667   3.0030  \n",
            "std        0.5375     1.1655    1.0048            2.2914   1.4169  \n",
            "min       -1.2318    -3.0000    1.0000            4.0000   0.0000  \n",
            "25%       -0.3694     0.0000    3.0000            8.0000   2.0000  \n",
            "50%        0.0000     0.5000    3.5000            9.0000   3.0000  \n",
            "75%        0.2884     1.0000    4.0000           11.0000   4.0000  \n",
            "max        1.3856     3.0000    7.0000           16.0000   8.0000  \n",
            "Sex counts:\n",
            " sex\n",
            "0    103\n",
            "1     62\n",
            "Name: count, dtype: int64\n",
            "Side counts:\n",
            " side\n",
            "0    84\n",
            "1    81\n",
            "Name: count, dtype: int64\n",
            "Unique Sex counts:\n",
            " sex\n",
            "0    62\n",
            "1    38\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['Δasg_0', 'Δasg_45', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']\n",
        "regression_data = data[columns].dropna()\n",
        "\n",
        "# 各項目の統計量を表示\n",
        "statistics = regression_data.describe(include='all')\n",
        "print(statistics)\n",
        "\n",
        "# Δasg_0とΔasg_45の箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['Δasg_0', 'Δasg_45']].boxplot()\n",
        "plt.title('Boxplot of Δasg_0 and Δasg_45')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_0_preとasg_45_preの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_0_pre', 'asg_45_pre']].boxplot()\n",
        "plt.title('Boxplot of asg_0_pre and asg_45_pre')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# MRD-1 preとMRD-1 3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['MRD-1 pre', 'MRD-1 3M']].boxplot()\n",
        "plt.title('Boxplot of MRD-1 pre and MRD-1 3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# levator_functionの箱ひげ図を作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data.boxplot(column=['levator_function'])\n",
        "plt.title('Boxplot of levator_function')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jBZ3zioDinsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['Δasg_0','Δasg_45', 'age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']\n",
        "regression_data = data[columns].dropna()\n",
        "\n",
        "# 説明変数と目的変数の設定\n",
        "def set_variables(target):\n",
        "    X = regression_data[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']]\n",
        "    y = regression_data[target]\n",
        "    return X, y\n",
        "\n",
        "# 太字表示のための関数\n",
        "def print_bold(text):\n",
        "    print(f\"\\033[1m{text}\\033[0m\")\n",
        "\n",
        "# 線形回帰モデルを作成・評価\n",
        "def linear_regression_analysis(X, y, target, test_size=0.2, random_state=0):\n",
        "    print_bold(f\"\\n--- Linear Regression Analysis for {target} ---\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"MSE: {mse}, R2: {r2}\")\n",
        "\n",
        "    X_train_sm = sm.add_constant(X_train)\n",
        "    model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
        "    print(model_sm.summary())\n",
        "\n",
        "    return model, X_train, X_test, y_train, y_test\n",
        "\n",
        "# ステップワイズ回帰関数\n",
        "def stepwise_selection(X, y, initial_list=[], threshold_in=0.05, threshold_out=0.10, verbose=True):\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed = False\n",
        "        excluded = list(set(X.columns) - set(included))\n",
        "        new_pval = pd.Series(index=excluded)\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        best_pval = new_pval.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_feature = new_pval.idxmin()\n",
        "            included.append(best_feature)\n",
        "            changed = True\n",
        "            if verbose:\n",
        "                print(f'Add  {best_feature} with p-value {best_pval}')\n",
        "\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        pvalues = model.pvalues.iloc[1:]\n",
        "        worst_pval = pvalues.max()\n",
        "        if worst_pval > threshold_out:\n",
        "            changed = True\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            included.remove(worst_feature)\n",
        "            if verbose:\n",
        "                print(f'Drop {worst_feature} with p-value {worst_pval}')\n",
        "        if not changed:\n",
        "            break\n",
        "\n",
        "    return included\n",
        "\n",
        "# ステップワイズ回帰を実行し、選択された変数で線形回帰を行う\n",
        "def stepwise_regression_analysis(X, y, target, test_size=0.2, random_state=0, threshold_in=0.01, threshold_out=0.05):\n",
        "    print_bold(f\"\\n--- Stepwise Regression Analysis for {target} ---\")\n",
        "    X_with_constant = sm.add_constant(X)\n",
        "    selected_features = stepwise_selection(X_with_constant, y, threshold_in=threshold_in, threshold_out=threshold_out)\n",
        "\n",
        "    if 'const' in selected_features:\n",
        "        selected_features.remove('const')\n",
        "\n",
        "    if not selected_features:\n",
        "        print(f\"No features were selected for {target}.\")\n",
        "        return\n",
        "\n",
        "    print(f'Selected features: {selected_features}')\n",
        "\n",
        "    X_selected = X[selected_features]\n",
        "    X_train_selected, X_test_selected, y_train, y_test = train_test_split(X_selected, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    model_selected = LinearRegression()\n",
        "    model_selected.fit(X_train_selected, y_train)\n",
        "\n",
        "    y_pred_selected = model_selected.predict(X_test_selected)\n",
        "\n",
        "    mse_selected = mean_squared_error(y_test, y_pred_selected)\n",
        "    r2_selected = r2_score(y_test, y_pred_selected)\n",
        "\n",
        "    print(f\"Selected model MSE: {mse_selected}, R2: {r2_selected}\")\n",
        "\n",
        "    X_train_selected_sm = sm.add_constant(X_train_selected)\n",
        "    model_selected_sm = sm.OLS(y_train, X_train_selected_sm).fit()\n",
        "    print(model_selected_sm.summary())\n",
        "\n",
        "# 線形回帰とステップワイズ回帰を実行するメイン関数\n",
        "def main_analysis(target):\n",
        "    X, y = set_variables(target)\n",
        "    linear_regression_analysis(X, y, target)\n",
        "    stepwise_regression_analysis(X, y, target)\n",
        "\n",
        "# Δasg_0とΔasg_45についての解析\n",
        "main_analysis('Δasg_0')\n",
        "main_analysis('Δasg_45')\n"
      ],
      "metadata": {
        "id": "Dhz6tBzJhm_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpXLRB9ehnD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['Δasg_0','Δasg_45', 'age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']\n",
        "regression_data = data[columns].dropna()\n",
        "\n",
        "# 外れ値を除外する関数\n",
        "def remove_outliers(df, outlier_columns):\n",
        "    filtered_df = df.copy()\n",
        "    for column in outlier_columns:\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        filtered_df = filtered_df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "    return filtered_df\n",
        "\n",
        "# 説明変数と目的変数の設定\n",
        "def set_variables(target, outliers_excluded=False, outlier_columns=[]):\n",
        "    if outliers_excluded:\n",
        "        filtered_data = remove_outliers(regression_data, outlier_columns)\n",
        "        X = filtered_data[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']]\n",
        "        y = filtered_data[target]\n",
        "    else:\n",
        "        X = regression_data[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']]\n",
        "        y = regression_data[target]\n",
        "    return X, y\n",
        "\n",
        "# 太字表示のための関数\n",
        "def print_bold(text):\n",
        "    print(f\"\\033[1m{text}\\033[0m\")\n",
        "\n",
        "# データを訓練セットとテストセットに分割し、SVRモデルを作成・評価\n",
        "def svr_regression_analysis(X, y, target, kernel='rbf', test_size=0.2, random_state=0):\n",
        "    print_bold(f\"\\n--- SVR Regression Analysis for {target} ---\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    model = SVR(kernel=kernel)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"MSE: {mse}, R2: {r2}\")\n",
        "\n",
        "    return model, X_train, X_test, y_train, y_test\n",
        "\n",
        "# Δasg_0についての解析\n",
        "X, y = set_variables('Δasg_0', outliers_excluded=False)\n",
        "svr_regression_analysis(X, y, 'Δasg_0')\n",
        "\n",
        "X, y = set_variables('Δasg_0', outliers_excluded=True, outlier_columns=['asg_0_pre', 'asg_45_pre'])\n",
        "svr_regression_analysis(X, y, 'Δasg_0 (Outliers Excluded)')\n",
        "\n",
        "# Δasg_45についての解析\n",
        "X, y = set_variables('Δasg_45', outliers_excluded=False)\n",
        "svr_regression_analysis(X, y, 'Δasg_45')\n",
        "\n",
        "X, y = set_variables('Δasg_45', outliers_excluded=True, outlier_columns=['asg_0_pre', 'asg_45_pre'])\n",
        "svr_regression_analysis(X, y, 'Δasg_45 (Outliers Excluded)')\n"
      ],
      "metadata": {
        "id": "bZYqs7KghnGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ytjJ1S4-Zz0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kG2v9FPIZz2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Random forest analysis**"
      ],
      "metadata": {
        "id": "gqdt-ZxZgOp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Selecting the relevant columns\n",
        "analysis_data = data[['Δasg_0', 'asg_0_pre', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "# Define features and target\n",
        "X = analysis_data[['asg_0_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "y = analysis_data['Δasg_0']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForestRegressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "mse, r2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC4xXQa6gWDc",
        "outputId": "ddd72da3-db01-456d-ad21-c756b66e2265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4928290860567575, -0.25533069874429226)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 解析データの準備\n",
        "analysis_data = data[['Δasg_0', 'asg_0_pre', 'Δasg_45', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "# Δasg_0 の解析\n",
        "# 特徴量と目的変数の定義\n",
        "X_0 = analysis_data[['asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "y_0 = analysis_data['Δasg_0']\n",
        "\n",
        "# データを訓練セットとテストセットに分割\n",
        "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_0, y_0, test_size=0.3, random_state=42)\n",
        "\n",
        "# ランダムフォレスト回帰モデルの初期化と訓練\n",
        "rf_model_0 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model_0.fit(X_train_0, y_train_0)\n",
        "\n",
        "# テストセットでの予測\n",
        "predictions_0 = rf_model_0.predict(X_test_0)\n",
        "\n",
        "# モデルの評価\n",
        "mse_0 = mean_squared_error(y_test_0, predictions_0)\n",
        "r2_0 = r2_score(y_test_0, predictions_0)\n",
        "\n",
        "# Δasg_45 の解析\n",
        "# 特徴量と目的変数の定義\n",
        "X_45 = analysis_data[['asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "y_45 = analysis_data['Δasg_45']\n",
        "\n",
        "# データを訓練セットとテストセットに分割\n",
        "X_train_45, X_test_45, y_train_45, y_test_45 = train_test_split(X_45, y_45, test_size=0.3, random_state=42)\n",
        "\n",
        "# ランダムフォレスト回帰モデルの初期化と訓練\n",
        "rf_model_45 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model_45.fit(X_train_45, y_train_45)\n",
        "\n",
        "# テストセットでの予測\n",
        "predictions_45 = rf_model_45.predict(X_test_45)\n",
        "\n",
        "# モデルの評価\n",
        "mse_45 = mean_squared_error(y_test_45, predictions_45)\n",
        "r2_45 = r2_score(y_test_45, predictions_45)\n",
        "\n",
        "mse_0, r2_0, mse_45, r2_45\n"
      ],
      "metadata": {
        "id": "JaXJz0vN9cB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 解析データの準備\n",
        "analysis_data = data[['Δasg_0', 'asg_0_pre', 'Δasg_45', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "def train_and_evaluate_model(X, y):\n",
        "    # データを訓練セットとテストセットに分割\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # ランダムフォレスト回帰モデルの初期化と訓練\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    # テストセットでの予測\n",
        "    predictions = rf_model.predict(X_test)\n",
        "\n",
        "    # モデルの評価\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    # 特徴量の重要度を取得\n",
        "    feature_importances = rf_model.feature_importances_\n",
        "\n",
        "    return mse, r2, feature_importances\n",
        "\n",
        "# Δasg_0 の解析\n",
        "X_0 = analysis_data[['asg_0_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "y_0 = analysis_data['Δasg_0']\n",
        "mse_0, r2_0, feature_importances_0 = train_and_evaluate_model(X_0, y_0)\n",
        "\n",
        "# Δasg_0 の特徴量重要度をデータフレームに変換\n",
        "feature_importance_df_0 = pd.DataFrame({\n",
        "    'Feature': X_0.columns,\n",
        "    'Importance': feature_importances_0\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Δasg_45 の解析\n",
        "X_45 = analysis_data[['asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "y_45 = analysis_data['Δasg_45']\n",
        "mse_45, r2_45, feature_importances_45 = train_and_evaluate_model(X_45, y_45)\n",
        "\n",
        "# Δasg_45 の特徴量重要度をデータフレームに変換\n",
        "feature_importance_df_45 = pd.DataFrame({\n",
        "    'Feature': X_45.columns,\n",
        "    'Importance': feature_importances_45\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 結果の表示\n",
        "print(\"Δasg_0 Model Evaluation\")\n",
        "print(f\"MSE: {mse_0}\")\n",
        "print(f\"R²: {r2_0}\")\n",
        "print(feature_importance_df_0)\n",
        "\n",
        "print(\"\\nΔasg_45 Model Evaluation\")\n",
        "print(f\"MSE: {mse_45}\")\n",
        "print(f\"R²: {r2_45}\")\n",
        "print(feature_importance_df_45)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py-8urgEwTHE",
        "outputId": "17fa1899-5cd4-44ad-ae47-3f11e2b5174b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Δasg_0 Model Evaluation\n",
            "MSE: 0.4928290860567575\n",
            "R²: -0.25533069874429226\n",
            "     Feature  Importance\n",
            "0  asg_0_pre    0.618630\n",
            "1  MRD-1 pre    0.217431\n",
            "2   MRD-1 3M    0.163939\n",
            "\n",
            "Δasg_45 Model Evaluation\n",
            "MSE: 0.40930488761670164\n",
            "R²: -0.30633992043812697\n",
            "      Feature  Importance\n",
            "0  asg_45_pre    0.680591\n",
            "1   MRD-1 pre    0.175465\n",
            "2    MRD-1 3M    0.143944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# 解析データの準備\n",
        "analysis_data = data[['Δasg_0', 'asg_0_pre', 'Δasg_45', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "def train_and_evaluate_model(X, y):\n",
        "    # データを訓練セットとテストセットに分割\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # ランダムフォレスト回帰モデルの初期化と訓練\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    # テストセットでの予測\n",
        "    predictions = rf_model.predict(X_test)\n",
        "\n",
        "    # モデルの評価\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    # 特徴量の重要度を取得\n",
        "    feature_importances = rf_model.feature_importances_\n",
        "\n",
        "    return rf_model, mse, r2, feature_importances\n",
        "\n",
        "def analyze_variable(target_var, feature_vars):\n",
        "    X = analysis_data[feature_vars]\n",
        "    y = analysis_data[target_var]\n",
        "    rf_model, mse, r2, feature_importances = train_and_evaluate_model(X, y)\n",
        "\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': feature_importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # モデルから一つのツリーを抽出して可視化\n",
        "    tree_example = rf_model.estimators_[0]\n",
        "    dot_data = export_graphviz(tree_example, out_file=None,\n",
        "                               feature_names=X.columns,\n",
        "                               filled=True, rounded=True,\n",
        "                               special_characters=True)\n",
        "    graph = graphviz.Source(dot_data)\n",
        "    graph.render(f\"{target_var}_tree\")  # 画像として保存\n",
        "\n",
        "    return mse, r2, feature_importance_df, graph\n",
        "\n",
        "# Δasg_0 の解析\n",
        "mse_0, r2_0, feature_importance_df_0, graph_0 = analyze_variable('Δasg_0', ['MRD-1 3M'])\n",
        "\n",
        "# Δasg_45 の解析\n",
        "mse_45, r2_45, feature_importance_df_45, graph_45 = analyze_variable('Δasg_45', ['MRD-1 3M'])\n",
        "\n",
        "# 結果の表示\n",
        "print(\"Δasg_0 Model Evaluation\")\n",
        "print(f\"MSE: {mse_0}\")\n",
        "print(f\"R²: {r2_0}\")\n",
        "print(feature_importance_df_0)\n",
        "\n",
        "print(\"\\nΔasg_45 Model Evaluation\")\n",
        "print(f\"MSE: {mse_45}\")\n",
        "print(f\"R²: {r2_45}\")\n",
        "print(feature_importance_df_45)\n",
        "\n",
        "# 表示\n",
        "graph_0\n",
        "# graph_45\n"
      ],
      "metadata": {
        "id": "MaRhgHorhugH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the graph to a file\n",
        "graph_path = '/content/graph.dot'\n",
        "graph_0.render(graph_path)\n",
        "\n",
        "# Provide the path to the saved graph file\n",
        "graph_path + '.pdf'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CDS9c11jkJ3X",
        "outputId": "d7fd3ba9-95f6-4804-e1bb-33f0066334a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/graph.dot.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Decision tree analysis**"
      ],
      "metadata": {
        "id": "Dp12aNSRFw4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# データの準備\n",
        "analysis_data = data[['Δasg_0', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "# 特徴量と目的変数の定義\n",
        "X = analysis_data[['MRD-1 3M']]\n",
        "y = analysis_data['Δasg_0']\n",
        "\n",
        "# データを訓練セットとテストセットに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 決定木回帰モデルの初期化と訓練\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# テストセットでの予測\n",
        "predictions = dt_model.predict(X_test)\n",
        "\n",
        "# モデルの評価\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"R²: {r2}\")\n",
        "\n",
        "# 決定木の可視化\n",
        "dot_data = export_graphviz(dt_model, out_file=None,\n",
        "                           feature_names=X.columns,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree_Δasg_0\")  # 画像として保存\n",
        "\n",
        "# グラフを表示\n",
        "graph\n"
      ],
      "metadata": {
        "id": "Gt7dUKb5hRAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import graphviz\n",
        "\n",
        "# データの準備\n",
        "analysis_data = data[['Δasg_0', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "# 特徴量と目的変数の定義\n",
        "X = analysis_data[['MRD-1 pre']]\n",
        "y = (analysis_data['Δasg_0'] > analysis_data['Δasg_0'].mean()).astype(int)\n",
        "\n",
        "# データを訓練セットとテストセットに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 決定木分類モデルの初期化と訓練\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# テストセットでの予測\n",
        "predictions = dt_model.predict(X_test)\n",
        "\n",
        "# モデルの評価\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# 決定木の可視化\n",
        "dot_data = export_graphviz(dt_model, out_file=None,\n",
        "                           feature_names=X.columns,\n",
        "                           class_names=['Below Average', 'Above Average'],\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree_Δasg_0_classification\")  # 画像として保存\n",
        "\n",
        "# グラフを表示\n",
        "graph\n"
      ],
      "metadata": {
        "id": "Hb4Z526QYWoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(data[\"MRD-1 3M\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ly8eqZfF1_C",
        "outputId": "36468272-5f9c-4593-dbe4-eb5a24bdd93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.0"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MRD-1 preとMRD-1 3Mのプロット（Δasg-0で色分けあり）\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(data['MRD-1 3M'], data['MRD-1 pre'], c=data['Δasg_0'], cmap='viridis')\n",
        "plt.colorbar(scatter, label='Δasg_0')\n",
        "\n",
        "plt.title('Scatter Plot of MRD-1 pre vs MRD-1 3M with Δasg_0 Color Coding')\n",
        "plt.xlabel('MRD-1 3M')\n",
        "plt.ylabel('MRD-1 pre')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GegUf6ipx6NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0UiBlgzRFJmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JoV-iGS4voZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qNCvp01zvoav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yKqnpF1jvoc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**一括して解析 (眼光学学会)**"
      ],
      "metadata": {
        "id": "mbmP8y-kvopJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "pd.set_option('display.max_columns', 300)\n",
        "pd.set_option('display.max_rows', 300)\n",
        "\n",
        "xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂_proprocessed.xlsx\"\n",
        "data = pd.read_excel(xlsx_path, header=0)\n",
        "\n",
        "def print_stats(data, step_name):\n",
        "    unique_id_count = data['ID'].nunique()\n",
        "    total_rows = len(data)\n",
        "    print(f\"\\n{step_name}\")\n",
        "    print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "    print(f\"Total number of rows: {total_rows}\")\n",
        "\n",
        "print_stats(data, \"Initial data\")\n",
        "\n",
        "##################\n",
        "# 眼瞼手術歴を除外\n",
        "##################\n",
        "excluded_data = data[data['eyelid_surg'] == 1]\n",
        "excluded_count = excluded_data['ID'].nunique()\n",
        "data = data[data['eyelid_surg'] != 1]\n",
        "print_stats(data, \"眼瞼手術歴を除外\")\n",
        "print(f\"Number of unique IDs excluded: {excluded_count}\")\n",
        "\n",
        "########################\n",
        "# 角膜混濁/HCL症例を除外\n",
        "########################\n",
        "excluded_data = data[data['corneal_matter'] == 1]\n",
        "excluded_count = excluded_data['ID'].nunique()\n",
        "data = data[data['corneal_matter'] != 1]\n",
        "print_stats(data, \"角膜混濁を除外\")\n",
        "print(f\"Number of unique IDs excluded: {excluded_count}\")\n",
        "\n",
        "#################\n",
        "# 外れ値を除外\n",
        "#################\n",
        "def remove_outliers(data, columns):\n",
        "    excluded_ids = set()\n",
        "    for column in columns:\n",
        "        q1 = data[column].quantile(0.25)\n",
        "        q3 = data[column].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "        excluded_ids.update(outliers['ID'])\n",
        "        data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
        "    return data, len(excluded_ids)\n",
        "\n",
        "# 外れ値を除外する列のリスト\n",
        "#columns_to_remove_outliers = [\"asg_0_pre\", \"asg_45_pre\", \"MRD-1 3M\"]\n",
        "columns_to_remove_outliers = [\"asg_0_pre\", \"asg_45_pre\"]\n",
        "\n",
        "\n",
        "# 外れ値を除外\n",
        "data, excluded_count = remove_outliers(data, columns_to_remove_outliers)\n",
        "print_stats(data, \"外れ値を除外\")\n",
        "print(f\"Number of unique IDs excluded: {excluded_count}\")\n",
        "\n",
        "print(\"\\nFinal dataset:\")\n",
        "print_stats(data, \"After all exclusions\")"
      ],
      "metadata": {
        "id": "HeV2wSpRvtO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# このスクリプトは処理済みのDataFrameをExcelファイルとして保存します。\n",
        "# 保存先は /content/ ディレクトリで、ファイル名には現在の日時が含まれます。\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# 現在の日時を取得\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# タイムスタンプを含むファイル名を作成\n",
        "file_name = f\"processed_data_{timestamp}.xlsx\"\n",
        "\n",
        "# 新しいExcelファイルの完全なパスを設定\n",
        "output_path = f\"/content/{file_name}\"\n",
        "\n",
        "# DataFrameをExcelファイルとして保存\n",
        "# index=Falseを指定して、インデックスを除外\n",
        "data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"DataFrameを次の場所に保存しました: {output_path}\")"
      ],
      "metadata": {
        "id": "i-rZQztsI-Bv",
        "outputId": "1fd5232f-4442-48a1-933d-476054339b7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrameを次の場所に保存しました: /content/processed_data_20240812_104734.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant columns\n",
        "columns_of_interest = ['ID', 'MRD-1 pre', 'MRD-1 3M', 'asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45', 'age', 'sex', 'side', 'levator_function', 'ΔMRD-1']\n",
        "data_relevant = data[columns_of_interest]\n",
        "\n",
        "# 各項目の統計量を表示\n",
        "statistics = data_relevant.describe(include='all')\n",
        "\n",
        "# age, sex, sideの内訳を表示\n",
        "sex_counts = data_relevant['sex'].value_counts()\n",
        "side_counts = data_relevant['side'].value_counts()\n",
        "\n",
        "# idが同じものは1例に数える\n",
        "unique_sex_counts = data_relevant.drop_duplicates(subset='ID')['sex'].value_counts()\n",
        "\n",
        "print(statistics)\n",
        "print(\"Sex counts:\\n\", sex_counts)\n",
        "print(\"Side counts:\\n\", side_counts)\n",
        "print(\"Unique Sex counts:\\n\", unique_sex_counts)\n"
      ],
      "metadata": {
        "id": "h5Lg_VxCwCvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "性別との交絡因子の解析\n",
        "'''\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_gender_differences(data):\n",
        "    # データの基本情報を確認\n",
        "    print(\"データの基本情報:\")\n",
        "    print(data.info())\n",
        "\n",
        "    print(\"\\nデータの先頭数行:\")\n",
        "    print(data.head())\n",
        "\n",
        "    # 数値データの列を抽出（'ID'と'sex'と'side'を除外）\n",
        "    numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    numeric_columns = [col for col in numeric_columns if col not in ['ID', 'sex', 'side']]\n",
        "\n",
        "    # 性別ごとのグループを作成（元のデータを変更せずに）\n",
        "    male_group = data[data['sex'] == 1]\n",
        "    female_group = data[data['sex'] == 0]\n",
        "\n",
        "    # 各数値列に対して t検定を実施\n",
        "    t_test_results = {}\n",
        "    for column in numeric_columns:\n",
        "        male_data = male_group[column].dropna()\n",
        "        female_data = female_group[column].dropna()\n",
        "\n",
        "        if len(male_data) > 0 and len(female_data) > 0:\n",
        "            t_stat, p_value = stats.ttest_ind(male_data, female_data)\n",
        "            t_test_results[column] = {'t_statistic': t_stat, 'p_value': p_value}\n",
        "        else:\n",
        "            print(f\"警告: {column}列にデータが不足しています\")\n",
        "\n",
        "    # カテゴリカルデータ（side）に対してはカイ二乗検定を実施\n",
        "    side_crosstab = pd.crosstab(data['sex'], data['side'])\n",
        "    if side_crosstab.size > 0 and side_crosstab.min().min() > 0:\n",
        "        chi2, p_value, dof, expected = stats.chi2_contingency(side_crosstab)\n",
        "        chi2_result = {'chi2_statistic': chi2, 'p_value': p_value}\n",
        "    else:\n",
        "        print(\"警告: 'side'列にデータが不足しているか、期待度数が0のセルがあります\")\n",
        "        chi2_result = {'chi2_statistic': np.nan, 'p_value': np.nan}\n",
        "\n",
        "    # 結果の表示\n",
        "    print(\"\\nT検定の結果:\")\n",
        "    for column, result in t_test_results.items():\n",
        "        print(f\"{column}: t統計量 = {result['t_statistic']:.4f}, p値 = {result['p_value']:.4f}\")\n",
        "\n",
        "    print(\"\\nカイ二乗検定の結果 (side):\")\n",
        "    print(f\"カイ二乗統計量 = {chi2_result['chi2_statistic']:.4f}, p値 = {chi2_result['p_value']:.4f}\")\n",
        "\n",
        "    # 有意差のある項目をリストアップ\n",
        "    significant_items = [column for column, result in t_test_results.items() if result['p_value'] < 0.05]\n",
        "    if chi2_result['p_value'] < 0.05:\n",
        "        significant_items.append('side')\n",
        "\n",
        "    print(\"\\n有意差のある項目:\")\n",
        "    for item in significant_items:\n",
        "        print(item)\n",
        "\n",
        "    # 各変数の記述統計量を性別ごとに計算\n",
        "    descriptive_stats = data.groupby('sex')[numeric_columns].agg(['mean', 'std'])\n",
        "    descriptive_stats.index = ['Female', 'Male']  # 0をFemale、1をMaleに変更\n",
        "    print(\"\\n性別ごとの記述統計量:\")\n",
        "    print(descriptive_stats)\n",
        "\n",
        "    return t_test_results, chi2_result, significant_items, descriptive_stats\n",
        "\n",
        "# 分析の実行\n",
        "t_test_results, chi2_result, significant_items, descriptive_stats = analyze_gender_differences(data_relevant)"
      ],
      "metadata": {
        "id": "ZAHeQe682018"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['Δasg_0', 'Δasg_45', 'asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1', 'levator_function']\n",
        "regression_data = data_relevant[columns].dropna()\n",
        "\n",
        "# 各項目の統計量を表示\n",
        "statistics = regression_data.describe(include='all')\n",
        "print(statistics)\n",
        "\n",
        "# Δasg_0とΔasg_45の箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['Δasg_0', 'Δasg_45']].boxplot()\n",
        "plt.title('Boxplot of Δasg_0 and Δasg_45')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_0_preとasg_45_preの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_0_pre', 'asg_45_pre']].boxplot()\n",
        "plt.title('Boxplot of asg_0_pre and asg_45_pre')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_0_preとasg_0_3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_0_pre', 'asg_0_3M']].boxplot()\n",
        "plt.title('Boxplot of asg_0_pre and asg_0_3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_45_preとasg_45_3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_45_pre', 'asg_45_3M']].boxplot()\n",
        "plt.title('Boxplot of asg_45_pre and asg_45_3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# MRD-1 preとMRD-1 3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['MRD-1 pre', 'MRD-1 3M']].boxplot()\n",
        "plt.title('Boxplot of MRD-1 pre and MRD-1 3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# levator_functionの箱ひげ図を作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data.boxplot(column=['levator_function'])\n",
        "plt.title('Boxplot of levator_function')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mf99GdYc4CbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from scipy.stats import ttest_rel\n",
        "import pandas as pd\n",
        "\n",
        "# Define a function to remove outliers based on IQR\n",
        "def remove_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)\n",
        "    Q3 = data.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return data[(data >= lower_bound) & (data <= upper_bound)]\n",
        "\n",
        "# Define a function to calculate mean, SD, and p-value for paired t-test\n",
        "def calculate_statistics(pre, post):\n",
        "    # pre_no_outliers = remove_outliers_iqr(pre)\n",
        "    # post_no_outliers = remove_outliers_iqr(post)\n",
        "    pre_no_outliers = pre\n",
        "    post_no_outliers = post\n",
        "\n",
        "\n",
        "    matched_data = pd.DataFrame({'pre': pre_no_outliers, 'post': post}).dropna()\n",
        "\n",
        "    mean_pre = pre_no_outliers.mean()\n",
        "    std_pre = pre_no_outliers.std()\n",
        "    mean_post = matched_data['post'].mean()\n",
        "    std_post = matched_data['post'].std()\n",
        "\n",
        "    t_test = ttest_rel(matched_data['pre'], matched_data['post'], nan_policy='omit')\n",
        "\n",
        "    return {\n",
        "        'pre_mean_sd': f\"{mean_pre:.3f} ± {std_pre:.3f}\",\n",
        "        'post_mean_sd': f\"{mean_post:.3f} ± {std_post:.3f}\",\n",
        "        'p_value': f\"{t_test.pvalue:.3e}\"\n",
        "    }\n",
        "\n",
        "# Applying the function to evaluate pre and post-surgery changes in asg_0 and asg_45\n",
        "asg_0_stats = calculate_statistics(data_relevant['asg_0_pre'], data_relevant['asg_0_3M'])\n",
        "asg_45_stats = calculate_statistics(data_relevant['asg_45_pre'], data_relevant['asg_45_3M'])\n",
        "\n",
        "print(f\"change in asg_0: {asg_0_stats}\")\n",
        "print(f\"change in asg_45: {asg_45_stats}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-QkjO233Pez",
        "outputId": "16b1fd6e-a171-4a5c-c710-95b806dbd82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change in asg_0: {'pre_mean_sd': '-0.110 ± 0.980', 'post_mean_sd': '0.124 ± 1.095', 'p_value': '2.189e-06'}\n",
            "change in asg_45: {'pre_mean_sd': '-0.022 ± 0.534', 'post_mean_sd': '-0.075 ± 0.676', 'p_value': '2.774e-01'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "asg_0_preとasg_45_preに関連する項目の検討\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Prepare the data for regression analysis for asg_0_pre and asg_45_pre\n",
        "X_asg_pre = data_relevant[['age', 'sex', 'side', 'MRD-1 pre', 'levator_function']]\n",
        "y_asg_0_pre = data_relevant['asg_0_pre']\n",
        "y_asg_45_pre = data_relevant['asg_45_pre']\n",
        "\n",
        "# Perform regression analysis for asg_0_pre\n",
        "model_asg_0_pre = sm.OLS(y_asg_0_pre, sm.add_constant(X_asg_pre)).fit()\n",
        "\n",
        "# Perform regression analysis for asg_45_pre\n",
        "model_asg_45_pre = sm.OLS(y_asg_45_pre, sm.add_constant(X_asg_pre)).fit()\n",
        "\n",
        "# Get the summary of the regression analysis\n",
        "summary_asg_0_pre = model_asg_0_pre.summary()\n",
        "summary_asg_45_pre = model_asg_45_pre.summary()\n",
        "\n",
        "summary_asg_0_pre, summary_asg_45_pre\n"
      ],
      "metadata": {
        "id": "AjuWua991cq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import statsmodels.api as sm\n",
        "\n",
        "# # Ordinary Least Squares (最小二乗法)を用いた解析\n",
        "\n",
        "# # Prepare the data for regression analysis for Δasg_0 and Δasg_45\n",
        "# X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "# X = sm.add_constant(X)  # Adding a constant term for the intercept\n",
        "\n",
        "# # Dependent variables\n",
        "# y_asg_0 = data_relevant['Δasg_0']\n",
        "# y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# # Perform regression analysis for Δasg_0\n",
        "# model_asg_0 = sm.OLS(y_asg_0, X).fit()\n",
        "\n",
        "# # Perform regression analysis for Δasg_45\n",
        "# model_asg_45 = sm.OLS(y_asg_45, X).fit()\n",
        "\n",
        "# # Get the summary of the regression analysis\n",
        "# summary_asg_0 = model_asg_0.summary()\n",
        "# summary_asg_45 = model_asg_45.summary()\n",
        "\n",
        "# summary_asg_0, summary_asg_45\n"
      ],
      "metadata": {
        "id": "DN7K_dBYwMp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "\n",
        "def print_bold(text):\n",
        "    print('\\033[1m' + text + '\\033[0m')\n",
        "\n",
        "def multivariate_regression_analysis(X, y, target):\n",
        "    print_bold(f\"\\n--- Multivariate Linear Regression Analysis for {target} ---\")\n",
        "    X_sm = sm.add_constant(X)\n",
        "    model = sm.OLS(y, X_sm).fit()\n",
        "    print(model.summary())\n",
        "\n",
        "    # Calculate and print MSE\n",
        "    y_pred = model.predict(X_sm)\n",
        "    mse = np.mean((y - y_pred)**2)\n",
        "    print_bold(f\"\\nMean Squared Error (MSE): {mse:.4f}\")\n",
        "\n",
        "def univariate_regression_analysis(X, y, target):\n",
        "    print_bold(f\"\\n--- Univariate Linear Regression Analysis for {target} ---\")\n",
        "    results = []\n",
        "    for column in X.columns:\n",
        "        X_uni = X[[column]]\n",
        "\n",
        "        # statsmodelsを使用して回帰分析を実行\n",
        "        X_sm = sm.add_constant(X_uni)\n",
        "        model_sm = sm.OLS(y, X_sm).fit()\n",
        "\n",
        "        # 結果を取得\n",
        "        coef = model_sm.params[column]  # 変数名を使用して係数を取得\n",
        "        std_err = model_sm.bse[column]\n",
        "        t_value = model_sm.tvalues[column]\n",
        "        p_value = model_sm.pvalues[column]\n",
        "        ci = model_sm.conf_int().loc[column]\n",
        "        r_squared = model_sm.rsquared\n",
        "\n",
        "        results.append({\n",
        "            'Variable': column,\n",
        "            'Coefficient': coef,\n",
        "            'Std Error': std_err,\n",
        "            't-value': t_value,\n",
        "            'P-value': p_value,\n",
        "            'CI Lower': ci[0],\n",
        "            'CI Upper': ci[1],\n",
        "            'R-squared': r_squared\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    pd.set_option('display.float_format', '{:.4f}'.format)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "# Prepare the data for regression analysis for Δasg_0 and Δasg_45\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1']]\n",
        "X = sm.add_constant(X)  # Adding a constant term for the intercept\n",
        "\n",
        "# Dependent variables\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# Perform multivariate regression analysis\n",
        "multivariate_regression_analysis(X, y_asg_0, 'Δasg_0')\n",
        "multivariate_regression_analysis(X, y_asg_45, 'Δasg_45')\n",
        "\n",
        "# Perform univariate regression analysis\n",
        "univariate_regression_analysis(X, y_asg_0, 'Δasg_0')\n",
        "univariate_regression_analysis(X, y_asg_45, 'Δasg_45')"
      ],
      "metadata": {
        "id": "Hl46UPL_MQAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Δasg_0について、関連しそうな変数を使用した多変量線形回帰分析\n",
        "X_reduced = X[['sex', 'asg_0_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "multivariate_regression_analysis(X_reduced, y_asg_0, 'Δasg_0')"
      ],
      "metadata": {
        "id": "u9tbBrgVepNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Δasg_45について、関連しそうな変数を使用した多変量線形回帰分析\n",
        "X_reduced = X[['asg_45_pre']]\n",
        "multivariate_regression_analysis(X_reduced, y_asg_45, 'Δasg_45')"
      ],
      "metadata": {
        "id": "6OgdeL0z0iQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Stepwise linear regression analysis #####\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tools import add_constant\n",
        "\n",
        "def print_bold(text):\n",
        "    print(f\"\\033[1m{text}\\033[0m\")\n",
        "\n",
        "def stepwise_selection(X, y, initial_list=[], threshold_in=0.01, threshold_out=0.05, verbose=True):\n",
        "    \"\"\" Perform a forward-backward feature selection\n",
        "    based on p-value from statsmodels.api.OLS\n",
        "    Arguments:\n",
        "        X - pandas.DataFrame with candidate features\n",
        "        y - list-like with the target\n",
        "        initial_list - list of features to start with (keep fixed)\n",
        "        threshold_in - include a feature if its p-value < threshold_in\n",
        "        threshold_out - exclude a feature if its p-value > threshold_out\n",
        "        verbose - whether to print the sequence of inclusions and exclusions\n",
        "    Returns: list of selected features\n",
        "    \"\"\"\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed = False\n",
        "        # forward step\n",
        "        excluded = list(set(X.columns) - set(included))\n",
        "        new_pval = pd.Series(index=excluded, dtype=float)\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        best_pval = new_pval.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_feature = new_pval.idxmin()\n",
        "            included.append(best_feature)\n",
        "            changed = True\n",
        "            if verbose:\n",
        "                print(f'Add  {best_feature} with p-value {best_pval}')\n",
        "        # backward step\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        # use all coefs except intercept\n",
        "        pvalues = model.pvalues.iloc[1:]\n",
        "        worst_pval = pvalues.max()\n",
        "        if worst_pval > threshold_out:\n",
        "            changed = True\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            included.remove(worst_feature)\n",
        "            if verbose:\n",
        "                print(f'Drop {worst_feature} with p-value {worst_pval}')\n",
        "        if not changed:\n",
        "            break\n",
        "    return included\n",
        "\n",
        "def linear_regression_analysis(X, y, target, test_size=0.2, random_state=0):\n",
        "    print_bold(f\"\\n--- Linear Regression Analysis for {target} ---\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    selected_features = stepwise_selection(X_train, y_train)\n",
        "    if not selected_features:\n",
        "        print(\"No features were selected using stepwise selection.\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    print(f\"Selected features: {selected_features}\")\n",
        "\n",
        "    X_train_selected = X_train[selected_features]\n",
        "    X_test_selected = X_test[selected_features]\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_selected, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
        "\n",
        "    X_train_sm = sm.add_constant(X_train_selected)\n",
        "    model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
        "    print(model_sm.summary())\n",
        "\n",
        "    # Calculate AIC\n",
        "    aic = model_sm.aic\n",
        "    print(f\"AIC: {aic:.4f}\")\n",
        "\n",
        "    return model, X_train_selected, X_test_selected, y_train, y_test, aic\n",
        "\n",
        "# Perform regression analysis for Δasg_0\n",
        "model_asg_0, X_train_asg_0, X_test_asg_0, y_train_asg_0, y_test_asg_0, aic_asg_0 = linear_regression_analysis(X, y_asg_0, 'Δasg_0')\n",
        "\n",
        "# Perform regression analysis for Δasg_45\n",
        "model_asg_45, X_train_asg_45, X_test_asg_45, y_train_asg_45, y_test_asg_45, aic_asg_45 = linear_regression_analysis(X, y_asg_45, 'Δasg_45')\n"
      ],
      "metadata": {
        "id": "sZIPxQap_b4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the data\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1']]\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_asg_0_train, y_asg_0_test = train_test_split(X, y_asg_0, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_asg_45_train, y_asg_45_test = train_test_split(X, y_asg_45, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Function to perform GridSearchCV and return the best model\n",
        "def get_best_rf_model(X_train, y_train):\n",
        "    rf = RandomForestRegressor(random_state=43)\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Get the best model for Δasg_0\n",
        "print(\"Tuning for Δasg_0:\")\n",
        "best_rf_asg_0 = get_best_rf_model(X_train, y_asg_0_train)\n",
        "\n",
        "# Get the best model for Δasg_45\n",
        "print(\"\\nTuning for Δasg_45:\")\n",
        "best_rf_asg_45 = get_best_rf_model(X_train, y_asg_45_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_0\n",
        "y_asg_0_pred = best_rf_asg_0.predict(X_test)\n",
        "mse_asg_0 = mean_squared_error(y_asg_0_test, y_asg_0_pred)\n",
        "r2_asg_0 = r2_score(y_asg_0_test, y_asg_0_pred)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_45\n",
        "y_asg_45_pred = best_rf_asg_45.predict(X_test)\n",
        "mse_asg_45 = mean_squared_error(y_asg_45_test, y_asg_45_pred)\n",
        "r2_asg_45 = r2_score(y_asg_45_test, y_asg_45_pred)\n",
        "\n",
        "print(f\"\\nResults after tuning:\")\n",
        "print(f\"MSE_Δasg0: {mse_asg_0}, r2_Δasg0: {r2_asg_0}\")\n",
        "print(f\"MSE_Δasg45: {mse_asg_45}, r2_Δasg45: {r2_asg_45}\")\n",
        "\n",
        "# Get feature importances for Δasg_0 model\n",
        "importances_asg_0 = best_rf_asg_0.feature_importances_\n",
        "feature_importances_asg_0 = pd.Series(importances_asg_0, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Get feature importances for Δasg_45 model\n",
        "importances_asg_45 = best_rf_asg_45.feature_importances_\n",
        "feature_importances_asg_45 = pd.Series(importances_asg_45, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Display top 5 important features\n",
        "print(\"\\nTop 5 important features for Δasg_0:\")\n",
        "print(feature_importances_asg_0.head())\n",
        "\n",
        "print(\"\\nTop 5 important features for Δasg_45:\")\n",
        "print(feature_importances_asg_45.head())"
      ],
      "metadata": {
        "id": "mc8tqdWn01Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the data\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1']]\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_asg_0_train, y_asg_0_test = train_test_split(X, y_asg_0, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_asg_45_train, y_asg_45_test = train_test_split(X, y_asg_45, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Function to perform GridSearchCV and return the best model\n",
        "def get_best_rf_model(X_train, y_train):\n",
        "    rf = RandomForestRegressor(random_state=43)\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Get the best model for Δasg_0\n",
        "print(\"Tuning for Δasg_0:\")\n",
        "best_rf_asg_0 = get_best_rf_model(X_train, y_asg_0_train)\n",
        "\n",
        "# Get the best model for Δasg_45\n",
        "print(\"\\nTuning for Δasg_45:\")\n",
        "best_rf_asg_45 = get_best_rf_model(X_train, y_asg_45_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_0\n",
        "y_asg_0_pred = best_rf_asg_0.predict(X_test)\n",
        "mse_asg_0 = mean_squared_error(y_asg_0_test, y_asg_0_pred)\n",
        "r2_asg_0 = r2_score(y_asg_0_test, y_asg_0_pred)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_45\n",
        "y_asg_45_pred = best_rf_asg_45.predict(X_test)\n",
        "mse_asg_45 = mean_squared_error(y_asg_45_test, y_asg_45_pred)\n",
        "r2_asg_45 = r2_score(y_asg_45_test, y_asg_45_pred)\n",
        "\n",
        "print(f\"\\nResults after tuning:\")\n",
        "print(f\"MSE_Δasg0: {mse_asg_0}, r2_Δasg0: {r2_asg_0}\")\n",
        "print(f\"MSE_Δasg45: {mse_asg_45}, r2_Δasg45: {r2_asg_45}\")\n",
        "\n",
        "# Get feature importances for Δasg_0 model\n",
        "importances_asg_0 = best_rf_asg_0.feature_importances_\n",
        "feature_importances_asg_0 = pd.Series(importances_asg_0, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Get feature importances for Δasg_45 model\n",
        "importances_asg_45 = best_rf_asg_45.feature_importances_\n",
        "feature_importances_asg_45 = pd.Series(importances_asg_45, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Display top 5 important features\n",
        "print(\"\\nTop 5 important features for Δasg_0:\")\n",
        "print(feature_importances_asg_0.head())\n",
        "\n",
        "print(\"\\nTop 5 important features for Δasg_45:\")\n",
        "print(feature_importances_asg_45.head())\n",
        "\n",
        "# Function to show decision tree if showTree is True\n",
        "def show_decision_tree(model, X_columns, title=\"Decision Tree\"):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plot_tree(model.estimators_[0], feature_names=X_columns, filled=True, rounded=True, fontsize=10)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Set showTree to True or False\n",
        "showTree = True\n",
        "\n",
        "if showTree:\n",
        "    print(\"\\nDisplaying Decision Tree for Δasg_0:\")\n",
        "    show_decision_tree(best_rf_asg_0, X.columns, title=\"Decision Tree from Best Random Forest for Δasg_0\")\n",
        "\n",
        "    print(\"\\nDisplaying Decision Tree for Δasg_45:\")\n",
        "    show_decision_tree(best_rf_asg_45, X.columns, title=\"Decision Tree from Best Random Forest for Δasg_45\")\n"
      ],
      "metadata": {
        "id": "8iIpzXffQTLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the data\n",
        "X = data_relevant[['age', 'sex', 'side', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1']]\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_asg_0_train, y_asg_0_test = train_test_split(X, y_asg_0, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_asg_45_train, y_asg_45_test = train_test_split(X, y_asg_45, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Function to perform GridSearchCV and return the best model\n",
        "def get_best_rf_model(X_train, y_train):\n",
        "    rf = RandomForestRegressor(random_state=43)\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Get the best model for Δasg_0\n",
        "print(\"Tuning for Δasg_0:\")\n",
        "best_rf_asg_0 = get_best_rf_model(X_train, y_asg_0_train)\n",
        "\n",
        "# Get the best model for Δasg_45\n",
        "print(\"\\nTuning for Δasg_45:\")\n",
        "best_rf_asg_45 = get_best_rf_model(X_train, y_asg_45_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_0\n",
        "y_asg_0_pred = best_rf_asg_0.predict(X_test)\n",
        "mse_asg_0 = mean_squared_error(y_asg_0_test, y_asg_0_pred)\n",
        "r2_asg_0 = r2_score(y_asg_0_test, y_asg_0_pred)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_45\n",
        "y_asg_45_pred = best_rf_asg_45.predict(X_test)\n",
        "mse_asg_45 = mean_squared_error(y_asg_45_test, y_asg_45_pred)\n",
        "r2_asg_45 = r2_score(y_asg_45_test, y_asg_45_pred)\n",
        "\n",
        "print(f\"\\nResults after tuning:\")\n",
        "print(f\"MSE_Δasg0: {mse_asg_0}, r2_Δasg0: {r2_asg_0}\")\n",
        "print(f\"MSE_Δasg45: {mse_asg_45}, r2_Δasg45: {r2_asg_45}\")\n",
        "\n",
        "# Get feature importances for Δasg_0 model\n",
        "importances_asg_0 = best_rf_asg_0.feature_importances_\n",
        "feature_importances_asg_0 = pd.Series(importances_asg_0, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Get feature importances for Δasg_45 model\n",
        "importances_asg_45 = best_rf_asg_45.feature_importances_\n",
        "feature_importances_asg_45 = pd.Series(importances_asg_45, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Display top 5 important features\n",
        "print(\"\\nTop 5 important features for Δasg_0:\")\n",
        "print(feature_importances_asg_0.head())\n",
        "\n",
        "print(\"\\nTop 5 important features for Δasg_45:\")\n",
        "print(feature_importances_asg_45.head())\n",
        "\n",
        "# Function to show decision tree if showTree is True\n",
        "def show_decision_tree(model, X_columns, title=\"Decision Tree\"):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plot_tree(model.estimators_[0], feature_names=X_columns, filled=True, rounded=True, fontsize=10)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Set showTree to True or False\n",
        "showTree = True\n",
        "\n",
        "if showTree:\n",
        "    print(\"\\nDisplaying Decision Tree for Δasg_0:\")\n",
        "    show_decision_tree(best_rf_asg_0, X.columns, title=\"Decision Tree from Best Random Forest for Δasg_0\")\n",
        "\n",
        "    print(\"\\nDisplaying Decision Tree for Δasg_45:\")\n",
        "    show_decision_tree(best_rf_asg_45, X.columns, title=\"Decision Tree from Best Random Forest for Δasg_45\")\n"
      ],
      "metadata": {
        "id": "eZoEM6JH7kkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OIFWaonM7kmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Prepare the polynomial features\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1']]\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_poly_train, X_poly_test, y_asg_0_train, y_asg_0_test = train_test_split(X_poly, y_asg_0, test_size=0.2, random_state=42)\n",
        "X_poly_train, X_poly_test, y_asg_45_train, y_asg_45_test = train_test_split(X_poly, y_asg_45, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the LinearRegression model for Δasg_0\n",
        "poly_model_asg_0 = LinearRegression()\n",
        "poly_model_asg_0.fit(X_poly_train, y_asg_0_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_0\n",
        "y_asg_0_poly_pred = poly_model_asg_0.predict(X_poly_test)\n",
        "mse_poly_asg_0 = mean_squared_error(y_asg_0_test, y_asg_0_poly_pred)\n",
        "r2_poly_asg_0 = r2_score(y_asg_0_test, y_asg_0_poly_pred)\n",
        "\n",
        "# Initialize and train the LinearRegression model for Δasg_45\n",
        "poly_model_asg_45 = LinearRegression()\n",
        "poly_model_asg_45.fit(X_poly_train, y_asg_45_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_45\n",
        "y_asg_45_poly_pred = poly_model_asg_45.predict(X_poly_test)\n",
        "mse_poly_asg_45 = mean_squared_error(y_asg_45_test, y_asg_45_poly_pred)\n",
        "r2_poly_asg_45 = r2_score(y_asg_45_test, y_asg_45_poly_pred)\n",
        "\n",
        "print(mse_poly_asg_0, r2_poly_asg_0, mse_poly_asg_45, r2_poly_asg_45)\n",
        "\n",
        "def get_top_features(model, feature_names, top_n=5):\n",
        "    # Get the absolute coefficients\n",
        "    coef = np.abs(model.coef_)\n",
        "\n",
        "    # Sort the coefficients in descending order\n",
        "    sorted_idx = np.argsort(coef)[::-1]\n",
        "\n",
        "    # Get the top N feature names and their coefficients\n",
        "    top_features = [(feature_names[i], coef[i]) for i in sorted_idx[:top_n]]\n",
        "\n",
        "    return top_features\n",
        "\n",
        "# Get feature names\n",
        "feature_names = poly.get_feature_names_out(X.columns)\n",
        "\n",
        "# Get top 5 features for Δasg_0 model\n",
        "top_features_asg_0 = get_top_features(poly_model_asg_0, feature_names)\n",
        "\n",
        "# Get top 5 features for Δasg_45 model\n",
        "top_features_asg_45 = get_top_features(poly_model_asg_45, feature_names)\n",
        "\n",
        "print(\"Top 5 important features for Δasg_0:\")\n",
        "for feature, importance in top_features_asg_0:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "\n",
        "print(\"\\nTop 5 important features for Δasg_45:\")\n",
        "for feature, importance in top_features_asg_45:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSf-xsvb2XTk",
        "outputId": "9de46390-d2b1-4071-a921-fa594173bc4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7530592814193761 -0.8006176832682315 0.6962521394232071 -0.947605600889279\n",
            "Top 5 important features for Δasg_0:\n",
            "1: 25882275032.8964\n",
            "asg_45_pre: 1.9304\n",
            "sex^2: 1.0975\n",
            "sex: 1.0975\n",
            "side: 1.0378\n",
            "\n",
            "Top 5 important features for Δasg_45:\n",
            "1: 45757363910.7826\n",
            "asg_0_pre: 1.9223\n",
            "sex: 0.9390\n",
            "sex^2: 0.9390\n",
            "sex side: 0.9184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**一括して解析（緑内障・眼内手術込み）**"
      ],
      "metadata": {
        "id": "sYo8HdGQ-Wuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "pd.set_option('display.max_columns', 300)\n",
        "pd.set_option('display.max_rows', 300)\n",
        "\n",
        "xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂_proprocessed.xlsx\"\n",
        "data = pd.read_excel(xlsx_path, header=0)\n",
        "\n",
        "def print_stats(data, step_name):\n",
        "    unique_id_count = data['ID'].nunique()\n",
        "    total_rows = len(data)\n",
        "    print(f\"\\n{step_name}\")\n",
        "    print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "    print(f\"Total number of rows: {total_rows}\")\n",
        "\n",
        "print_stats(data, \"Initial data\")\n",
        "\n",
        "##################\n",
        "# 眼瞼手術歴を除外\n",
        "##################\n",
        "excluded_data = data[data['eyelid_surg'] == 1]\n",
        "excluded_count = excluded_data['ID'].nunique()\n",
        "data = data[data['eyelid_surg'] != 1]\n",
        "print_stats(data, \"眼瞼手術歴を除外\")\n",
        "print(f\"Number of unique IDs excluded: {excluded_count}\")\n",
        "\n",
        "########################\n",
        "# 角膜混濁/HCL症例を除外\n",
        "########################\n",
        "excluded_data = data[data['corneal_matter'] == 1]\n",
        "excluded_count = excluded_data['ID'].nunique()\n",
        "data = data[data['corneal_matter'] != 1]\n",
        "print_stats(data, \"角膜混濁を除外\")\n",
        "print(f\"Number of unique IDs excluded: {excluded_count}\")\n",
        "\n",
        "#################\n",
        "# 外れ値を除外 --> どうするか？？\n",
        "#################\n",
        "def remove_outliers(data, columns):\n",
        "    excluded_ids = set()\n",
        "    for column in columns:\n",
        "        q1 = data[column].quantile(0.25)\n",
        "        q3 = data[column].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "        excluded_ids.update(outliers['ID'])\n",
        "        data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
        "    return data, len(excluded_ids)\n",
        "\n",
        "# 外れ値を除外する列のリスト\n",
        "#columns_to_remove_outliers = [\"asg_0_pre\", \"asg_45_pre\", \"MRD-1 3M\"]\n",
        "columns_to_remove_outliers = [\"asg_0_pre\", \"asg_45_pre\"]\n",
        "\n",
        "\n",
        "# 外れ値を除外\n",
        "data, excluded_count = remove_outliers(data, columns_to_remove_outliers)\n",
        "print_stats(data, \"外れ値を除外\")\n",
        "print(f\"Number of unique IDs excluded: {excluded_count}\")\n",
        "\n",
        "print(\"\\nFinal dataset:\")\n",
        "print_stats(data, \"After all exclusions\")"
      ],
      "metadata": {
        "id": "pRnQRcQI_FKz",
        "outputId": "b1b97e61-31f8-4ae6-824a-fe4176e6261b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Initial data\n",
            "Number of unique IDs: 112\n",
            "Total number of rows: 189\n",
            "\n",
            "眼瞼手術歴を除外\n",
            "Number of unique IDs: 107\n",
            "Total number of rows: 179\n",
            "Number of unique IDs excluded: 6\n",
            "\n",
            "角膜混濁を除外\n",
            "Number of unique IDs: 101\n",
            "Total number of rows: 167\n",
            "Number of unique IDs excluded: 8\n",
            "\n",
            "外れ値を除外\n",
            "Number of unique IDs: 97\n",
            "Total number of rows: 160\n",
            "Number of unique IDs excluded: 7\n",
            "\n",
            "Final dataset:\n",
            "\n",
            "After all exclusions\n",
            "Number of unique IDs: 97\n",
            "Total number of rows: 160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant columns\n",
        "columns_of_interest = ['ID', 'MRD-1 pre', 'MRD-1 3M', 'asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45', 'age', 'sex', 'side', 'levator_function', 'ΔMRD-1', 'glaucoma', 'intraocular_surg']\n",
        "data_relevant = data[columns_of_interest]\n",
        "\n",
        "# 各項目の統計量を表示\n",
        "statistics = data_relevant.describe(include='all')\n",
        "\n",
        "# age, sex, sideの内訳を表示\n",
        "sex_counts = data_relevant['sex'].value_counts()\n",
        "side_counts = data_relevant['side'].value_counts()\n",
        "intraocular_counts = data_relevant['intraocular_surg'].value_counts()\n",
        "glaucoma_counts = data_relevant['glaucoma'].value_counts()\n",
        "\n",
        "# idが同じものは1例に数える\n",
        "unique_sex_counts = data_relevant.drop_duplicates(subset='ID')['sex'].value_counts()\n",
        "unique_intraocular_counts = data_relevant.drop_duplicates(subset='ID')['intraocular_surg'].value_counts()\n",
        "unique_glaucoma_counts = data_relevant.drop_duplicates(subset='ID')['glaucoma'].value_counts()\n",
        "\n",
        "\n",
        "print(statistics)\n",
        "print(\"Sex counts:\\n\", sex_counts)\n",
        "print(\"Unique Sex counts:\\n\", unique_sex_counts)\n",
        "print(\"Side counts:\\n\", side_counts)\n",
        "print(\"Intraocular_surg counts:\\n\", intraocular_counts)\n",
        "print(\"Unique Intraocular_surg counts:\\n\", unique_intraocular_counts)\n",
        "print(\"Glaucoma counts:\\n\", glaucoma_counts)\n",
        "print(\"Unique glaucoma counts:\\n\", unique_glaucoma_counts)\n",
        "\n"
      ],
      "metadata": {
        "id": "eSVCiwsU_lYl",
        "outputId": "1e051271-a52c-4f06-cdae-bd49f0afe1c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 ID   MRD-1 pre    MRD-1 3M   asg_0_pre    asg_45_pre  \\\n",
            "count  1.600000e+02  160.000000  160.000000  160.000000  1.600000e+02   \n",
            "mean   9.809503e+06    0.459375    3.459375   -0.109750 -2.247055e-02   \n",
            "std    2.589004e+06    1.176248    1.017105    0.979720  5.340108e-01   \n",
            "min    1.655521e+06   -3.000000    1.000000   -2.525611 -1.231823e+00   \n",
            "25%    8.015189e+06    0.000000    3.000000   -0.773719 -3.658451e-01   \n",
            "50%    1.097244e+07    0.500000    3.500000   -0.115269  1.408344e-16   \n",
            "75%    1.175821e+07    1.000000    4.000000    0.532146  3.031162e-01   \n",
            "max    1.242201e+07    3.000000    7.000000    2.377641  1.385641e+00   \n",
            "\n",
            "         asg_0_3M   asg_45_3M      Δasg_0     Δasg_45         age         sex  \\\n",
            "count  160.000000  160.000000  160.000000  160.000000  160.000000  160.000000   \n",
            "mean     0.124270   -0.074973    0.234020   -0.052503   75.706250    0.387500   \n",
            "std      1.094698    0.676107    0.602240    0.609376    8.450817    0.488709   \n",
            "min     -2.586874   -3.654182   -1.240938   -3.737805   46.000000    0.000000   \n",
            "25%     -0.621150   -0.422742   -0.141728   -0.327284   70.750000    0.000000   \n",
            "50%      0.077637   -0.087429    0.202420   -0.026976   76.000000    0.000000   \n",
            "75%      0.796591    0.338598    0.593294    0.271706   82.000000    1.000000   \n",
            "max      2.713754    1.695742    2.000000    1.758522   92.000000    1.000000   \n",
            "\n",
            "             side  levator_function     ΔMRD-1    glaucoma  intraocular_surg  \n",
            "count  160.000000        160.000000  160.00000  160.000000        160.000000  \n",
            "mean     0.487500          9.384375    3.00000    0.256250          0.750000  \n",
            "std      0.501413          2.302051    1.43299    0.437932          0.434372  \n",
            "min      0.000000          4.000000    0.00000    0.000000          0.000000  \n",
            "25%      0.000000          8.000000    2.00000    0.000000          0.750000  \n",
            "50%      0.000000          9.000000    3.00000    0.000000          1.000000  \n",
            "75%      1.000000         11.000000    4.00000    1.000000          1.000000  \n",
            "max      1.000000         16.000000    8.00000    1.000000          1.000000  \n",
            "Sex counts:\n",
            " sex\n",
            "0    98\n",
            "1    62\n",
            "Name: count, dtype: int64\n",
            "Unique Sex counts:\n",
            " sex\n",
            "0    59\n",
            "1    38\n",
            "Name: count, dtype: int64\n",
            "Side counts:\n",
            " side\n",
            "0    82\n",
            "1    78\n",
            "Name: count, dtype: int64\n",
            "Intraocular_surg counts:\n",
            " intraocular_surg\n",
            "1    120\n",
            "0     40\n",
            "Name: count, dtype: int64\n",
            "Unique Intraocular_surg counts:\n",
            " intraocular_surg\n",
            "1    72\n",
            "0    25\n",
            "Name: count, dtype: int64\n",
            "Glaucoma counts:\n",
            " glaucoma\n",
            "0    119\n",
            "1     41\n",
            "Name: count, dtype: int64\n",
            "Unique glaucoma counts:\n",
            " glaucoma\n",
            "0    72\n",
            "1    25\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_gender_differences(data):\n",
        "    # データの基本情報を確認\n",
        "    print(\"データの基本情報:\")\n",
        "    print(data.info())\n",
        "\n",
        "    print(\"\\nデータの先頭数行:\")\n",
        "    print(data.head())\n",
        "\n",
        "    # 数値データの列を抽出（'ID'と'sex'と'side'を除外）\n",
        "    numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    numeric_columns = [col for col in numeric_columns if col not in ['ID', 'sex', 'side', 'intraocular_surg', 'glaucoma']]\n",
        "\n",
        "    # カテゴリカル変数のリスト\n",
        "    categorical_columns = ['side', 'intraocular_surg', 'glaucoma']\n",
        "\n",
        "    # 性別ごとのグループを作成（元のデータを変更せずに）\n",
        "    male_group = data[data['sex'] == 1]\n",
        "    female_group = data[data['sex'] == 0]\n",
        "\n",
        "    # 各数値列に対して t検定を実施\n",
        "    t_test_results = {}\n",
        "    for column in numeric_columns:\n",
        "        male_data = male_group[column].dropna()\n",
        "        female_data = female_group[column].dropna()\n",
        "\n",
        "        if len(male_data) > 0 and len(female_data) > 0:\n",
        "            t_stat, p_value = stats.ttest_ind(male_data, female_data)\n",
        "            t_test_results[column] = {'t_statistic': t_stat, 'p_value': p_value}\n",
        "        else:\n",
        "            print(f\"警告: {column}列にデータが不足しています\")\n",
        "\n",
        "    # カテゴリカルデータに対してカイ二乗検定を実施\n",
        "    chi2_results = {}\n",
        "    for column in categorical_columns:\n",
        "        crosstab = pd.crosstab(data['sex'], data[column])\n",
        "        if crosstab.size > 0 and crosstab.min().min() > 0:\n",
        "            chi2, p_value, dof, expected = stats.chi2_contingency(crosstab)\n",
        "            chi2_results[column] = {'chi2_statistic': chi2, 'p_value': p_value}\n",
        "        else:\n",
        "            print(f\"警告: '{column}'列にデータが不足しているか、期待度数が0のセルがあります\")\n",
        "            chi2_results[column] = {'chi2_statistic': np.nan, 'p_value': np.nan}\n",
        "\n",
        "    # 結果の表示\n",
        "    print(\"\\nT検定の結果:\")\n",
        "    for column, result in t_test_results.items():\n",
        "        print(f\"{column}: t統計量 = {result['t_statistic']:.4f}, p値 = {result['p_value']:.4f}\")\n",
        "\n",
        "    print(\"\\nカイ二乗検定の結果:\")\n",
        "    for column, result in chi2_results.items():\n",
        "        print(f\"{column}: カイ二乗統計量 = {result['chi2_statistic']:.4f}, p値 = {result['p_value']:.4f}\")\n",
        "\n",
        "    # 有意差のある項目をリストアップ\n",
        "    significant_items = [column for column, result in t_test_results.items() if result['p_value'] < 0.05]\n",
        "    significant_items.extend([column for column, result in chi2_results.items() if result['p_value'] < 0.05])\n",
        "\n",
        "    print(\"\\n有意差のある項目:\")\n",
        "    for item in significant_items:\n",
        "        print(item)\n",
        "\n",
        "    # 各変数の記述統計量を性別ごとに計算\n",
        "    descriptive_stats = data.groupby('sex')[numeric_columns].agg(['mean', 'std'])\n",
        "    descriptive_stats.index = ['Female', 'Male']  # 0をFemale、1をMaleに変更\n",
        "    print(\"\\n性別ごとの記述統計量:\")\n",
        "    print(descriptive_stats)\n",
        "\n",
        "    # カテゴリカル変数の分布を表示\n",
        "    for column in categorical_columns:\n",
        "        print(f\"\\n{column}の分布:\")\n",
        "        print(pd.crosstab(data['sex'], data[column], normalize='index'))\n",
        "\n",
        "    return t_test_results, chi2_results, significant_items, descriptive_stats\n",
        "\n",
        "# 分析の実行\n",
        "t_test_results, chi2_results, significant_items, descriptive_stats = analyze_gender_differences(data_relevant)"
      ],
      "metadata": {
        "id": "xDEnPspRCFi_",
        "outputId": "3d53c11f-b88d-44ed-aac5-0e6a2234ca93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データの基本情報:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 160 entries, 0 to 188\n",
            "Data columns (total 16 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   ID                160 non-null    int64  \n",
            " 1   MRD-1 pre         160 non-null    float64\n",
            " 2   MRD-1 3M          160 non-null    float64\n",
            " 3   asg_0_pre         160 non-null    float64\n",
            " 4   asg_45_pre        160 non-null    float64\n",
            " 5   asg_0_3M          160 non-null    float64\n",
            " 6   asg_45_3M         160 non-null    float64\n",
            " 7   Δasg_0            160 non-null    float64\n",
            " 8   Δasg_45           160 non-null    float64\n",
            " 9   age               160 non-null    int64  \n",
            " 10  sex               160 non-null    int64  \n",
            " 11  side              160 non-null    int64  \n",
            " 12  levator_function  160 non-null    float64\n",
            " 13  ΔMRD-1            160 non-null    float64\n",
            " 14  glaucoma          160 non-null    int64  \n",
            " 15  intraocular_surg  160 non-null    int64  \n",
            "dtypes: float64(10), int64(6)\n",
            "memory usage: 21.2 KB\n",
            "None\n",
            "\n",
            "データの先頭数行:\n",
            "        ID  MRD-1 pre  MRD-1 3M  asg_0_pre  asg_45_pre  asg_0_3M  asg_45_3M  \\\n",
            "0  1655521        0.5       2.5  -0.743145    0.669131 -0.370820   1.141268   \n",
            "1  1655521       -2.0       1.5  -2.347554    0.498988 -2.068096   0.364661   \n",
            "2  1932018       -0.5       4.0  -0.707066    0.842649  0.594161  -0.083504   \n",
            "3  2142221        2.0       4.0  -0.692820    0.400000 -0.915871  -0.161493   \n",
            "4  2142221        0.5       4.0  -0.891774   -0.802957 -0.518418  -0.110193   \n",
            "\n",
            "     Δasg_0   Δasg_45  age  sex  side  levator_function  ΔMRD-1  glaucoma  \\\n",
            "0  0.372324  0.472137   84    1     1               9.0     2.0         0   \n",
            "1  0.279458 -0.134327   84    1     0               8.0     3.5         0   \n",
            "2  1.301227 -0.926153   81    0     1               7.0     4.5         1   \n",
            "3 -0.223051 -0.561493   81    0     0              12.0     2.0         0   \n",
            "4  0.373356  0.692764   81    0     1              12.0     3.5         0   \n",
            "\n",
            "   intraocular_surg  \n",
            "0                 1  \n",
            "1                 1  \n",
            "2                 1  \n",
            "3                 1  \n",
            "4                 1  \n",
            "\n",
            "T検定の結果:\n",
            "MRD-1 pre: t統計量 = -0.4791, p値 = 0.6325\n",
            "MRD-1 3M: t統計量 = -2.5953, p値 = 0.0103\n",
            "asg_0_pre: t統計量 = -1.3983, p値 = 0.1640\n",
            "asg_45_pre: t統計量 = 2.7403, p値 = 0.0068\n",
            "asg_0_3M: t統計量 = -2.4279, p値 = 0.0163\n",
            "asg_45_3M: t統計量 = 2.2913, p値 = 0.0233\n",
            "Δasg_0: t統計量 = -2.1010, p値 = 0.0372\n",
            "Δasg_45: t統計量 = 0.1548, p値 = 0.8772\n",
            "age: t統計量 = 1.0606, p値 = 0.2905\n",
            "levator_function: t統計量 = -0.7625, p値 = 0.4469\n",
            "ΔMRD-1: t統計量 = -1.4200, p値 = 0.1576\n",
            "\n",
            "カイ二乗検定の結果:\n",
            "side: カイ二乗統計量 = 0.0000, p値 = 1.0000\n",
            "intraocular_surg: カイ二乗統計量 = 0.5618, p値 = 0.4535\n",
            "glaucoma: カイ二乗統計量 = 2.6598, p値 = 0.1029\n",
            "\n",
            "有意差のある項目:\n",
            "MRD-1 3M\n",
            "asg_45_pre\n",
            "asg_0_3M\n",
            "asg_45_3M\n",
            "Δasg_0\n",
            "\n",
            "性別ごとの記述統計量:\n",
            "       MRD-1 pre            MRD-1 3M           asg_0_pre           asg_45_pre  \\\n",
            "            mean       std      mean       std      mean       std       mean   \n",
            "Female  0.494898  1.143099  3.622449  1.015502 -0.023864  0.892145  -0.112659   \n",
            "Male    0.403226  1.234207  3.201613  0.972826 -0.245506  1.098035   0.120085   \n",
            "\n",
            "                 asg_0_3M           asg_45_3M             Δasg_0            \\\n",
            "             std     mean       std      mean      std      mean       std   \n",
            "Female  0.517235  0.28888  1.076508 -0.171112  0.71502  0.312744  0.668026   \n",
            "Male    0.533069 -0.13592  1.080958  0.076988  0.58328  0.109586  0.458325   \n",
            "\n",
            "         Δasg_45                  age           levator_function            \\\n",
            "            mean       std       mean       std             mean       std   \n",
            "Female -0.058453  0.713547  75.142857  9.543174         9.494898  2.464694   \n",
            "Male   -0.043098  0.397667  76.596774  6.325747         9.209677  2.025551   \n",
            "\n",
            "          ΔMRD-1            \n",
            "            mean       std  \n",
            "Female  3.127551  1.445418  \n",
            "Male    2.798387  1.400994  \n",
            "\n",
            "sideの分布:\n",
            "side         0         1\n",
            "sex                     \n",
            "0     0.510204  0.489796\n",
            "1     0.516129  0.483871\n",
            "\n",
            "intraocular_surgの分布:\n",
            "intraocular_surg         0         1\n",
            "sex                                 \n",
            "0                 0.275510  0.724490\n",
            "1                 0.209677  0.790323\n",
            "\n",
            "glaucomaの分布:\n",
            "glaucoma         0         1\n",
            "sex                         \n",
            "0         0.693878  0.306122\n",
            "1         0.822581  0.177419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['Δasg_0', 'Δasg_45', 'asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1', 'levator_function', 'intraocular_surg', 'glaucoma']\n",
        "regression_data = data_relevant[columns].dropna()\n",
        "\n",
        "# 各項目の統計量を表示\n",
        "statistics = regression_data.describe(include='all')\n",
        "print(statistics)\n",
        "\n",
        "# Δasg_0とΔasg_45の箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['Δasg_0', 'Δasg_45']].boxplot()\n",
        "plt.title('Boxplot of Δasg_0 and Δasg_45')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_0_preとasg_45_preの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_0_pre', 'asg_45_pre']].boxplot()\n",
        "plt.title('Boxplot of asg_0_pre and asg_45_pre')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_0_preとasg_0_3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_0_pre', 'asg_0_3M']].boxplot()\n",
        "plt.title('Boxplot of asg_0_pre and asg_0_3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_45_preとasg_45_3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_45_pre', 'asg_45_3M']].boxplot()\n",
        "plt.title('Boxplot of asg_45_pre and asg_45_3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# MRD-1 preとMRD-1 3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['MRD-1 pre', 'MRD-1 3M']].boxplot()\n",
        "plt.title('Boxplot of MRD-1 pre and MRD-1 3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# levator_functionの箱ひげ図を作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data.boxplot(column=['levator_function'])\n",
        "plt.title('Boxplot of levator_function')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FB3uDLV5CWLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from scipy.stats import ttest_rel\n",
        "import pandas as pd\n",
        "\n",
        "# Define a function to remove outliers based on IQR\n",
        "def remove_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)\n",
        "    Q3 = data.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return data[(data >= lower_bound) & (data <= upper_bound)]\n",
        "\n",
        "# Define a function to calculate mean, SD, and p-value for paired t-test\n",
        "def calculate_statistics(pre, post):\n",
        "    # pre_no_outliers = remove_outliers_iqr(pre)\n",
        "    # post_no_outliers = remove_outliers_iqr(post)\n",
        "    pre_no_outliers = pre\n",
        "    post_no_outliers = post\n",
        "\n",
        "\n",
        "    matched_data = pd.DataFrame({'pre': pre_no_outliers, 'post': post}).dropna()\n",
        "\n",
        "    mean_pre = pre_no_outliers.mean()\n",
        "    std_pre = pre_no_outliers.std()\n",
        "    mean_post = matched_data['post'].mean()\n",
        "    std_post = matched_data['post'].std()\n",
        "\n",
        "    t_test = ttest_rel(matched_data['pre'], matched_data['post'], nan_policy='omit')\n",
        "\n",
        "    return {\n",
        "        'pre_mean_sd': f\"{mean_pre:.3f} ± {std_pre:.3f}\",\n",
        "        'post_mean_sd': f\"{mean_post:.3f} ± {std_post:.3f}\",\n",
        "        'p_value': f\"{t_test.pvalue:.3e}\"\n",
        "    }\n",
        "\n",
        "# Applying the function to evaluate pre and post-surgery changes in asg_0 and asg_45\n",
        "asg_0_stats = calculate_statistics(data_relevant['asg_0_pre'], data_relevant['asg_0_3M'])\n",
        "asg_45_stats = calculate_statistics(data_relevant['asg_45_pre'], data_relevant['asg_45_3M'])\n",
        "\n",
        "print(f\"change in asg_0: {asg_0_stats}\")\n",
        "print(f\"change in asg_45: {asg_45_stats}\")"
      ],
      "metadata": {
        "id": "wHcgPm4BCfRo",
        "outputId": "deebef8b-f069-4d83-db92-8e1490faa185",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change in asg_0: {'pre_mean_sd': '-0.110 ± 0.980', 'post_mean_sd': '0.124 ± 1.095', 'p_value': '2.189e-06'}\n",
            "change in asg_45: {'pre_mean_sd': '-0.022 ± 0.534', 'post_mean_sd': '-0.075 ± 0.676', 'p_value': '2.774e-01'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "asg_0_preとasg_45_preに関連する項目の検討\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Prepare the data for regression analysis for asg_0_pre and asg_45_pre\n",
        "X_asg_pre = data_relevant[['age', 'sex', 'side', 'MRD-1 pre', 'levator_function', 'intraocular_surg', 'glaucoma']]\n",
        "y_asg_0_pre = data_relevant['asg_0_pre']\n",
        "y_asg_45_pre = data_relevant['asg_45_pre']\n",
        "\n",
        "# Perform regression analysis for asg_0_pre\n",
        "model_asg_0_pre = sm.OLS(y_asg_0_pre, sm.add_constant(X_asg_pre)).fit()\n",
        "\n",
        "# Perform regression analysis for asg_45_pre\n",
        "model_asg_45_pre = sm.OLS(y_asg_45_pre, sm.add_constant(X_asg_pre)).fit()\n",
        "\n",
        "# Get the summary of the regression analysis\n",
        "summary_asg_0_pre = model_asg_0_pre.summary()\n",
        "summary_asg_45_pre = model_asg_45_pre.summary()\n",
        "\n",
        "summary_asg_0_pre, summary_asg_45_pre\n"
      ],
      "metadata": {
        "id": "iNtONRhoC1FE",
        "outputId": "1d611612-8095-4efe-b9bc-1c1cfe48e7dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<class 'statsmodels.iolib.summary.Summary'>\n",
              " \"\"\"\n",
              "                             OLS Regression Results                            \n",
              " ==============================================================================\n",
              " Dep. Variable:              asg_0_pre   R-squared:                       0.142\n",
              " Model:                            OLS   Adj. R-squared:                  0.103\n",
              " Method:                 Least Squares   F-statistic:                     3.606\n",
              " Date:                Sun, 01 Sep 2024   Prob (F-statistic):            0.00127\n",
              " Time:                        14:46:26   Log-Likelihood:                -210.96\n",
              " No. Observations:                 160   AIC:                             437.9\n",
              " Df Residuals:                     152   BIC:                             462.5\n",
              " Df Model:                           7                                         \n",
              " Covariance Type:            nonrobust                                         \n",
              " ====================================================================================\n",
              "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
              " ------------------------------------------------------------------------------------\n",
              " const                2.1144      0.825      2.563      0.011       0.484       3.744\n",
              " age                 -0.0288      0.009     -3.144      0.002      -0.047      -0.011\n",
              " sex                 -0.1660      0.154     -1.076      0.284      -0.471       0.139\n",
              " side                 0.1985      0.148      1.339      0.183      -0.094       0.492\n",
              " MRD-1 pre            0.0836      0.067      1.249      0.214      -0.049       0.216\n",
              " levator_function     0.0146      0.036      0.403      0.688      -0.057       0.086\n",
              " intraocular_surg    -0.2835      0.176     -1.610      0.109      -0.631       0.064\n",
              " glaucoma            -0.1397      0.184     -0.761      0.448      -0.503       0.223\n",
              " ==============================================================================\n",
              " Omnibus:                        0.283   Durbin-Watson:                   1.316\n",
              " Prob(Omnibus):                  0.868   Jarque-Bera (JB):                0.391\n",
              " Skew:                           0.092   Prob(JB):                        0.822\n",
              " Kurtosis:                       2.843   Cond. No.                         864.\n",
              " ==============================================================================\n",
              " \n",
              " Notes:\n",
              " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              " \"\"\",\n",
              " <class 'statsmodels.iolib.summary.Summary'>\n",
              " \"\"\"\n",
              "                             OLS Regression Results                            \n",
              " ==============================================================================\n",
              " Dep. Variable:             asg_45_pre   R-squared:                       0.105\n",
              " Model:                            OLS   Adj. R-squared:                  0.064\n",
              " Method:                 Least Squares   F-statistic:                     2.548\n",
              " Date:                Sun, 01 Sep 2024   Prob (F-statistic):             0.0165\n",
              " Time:                        14:46:26   Log-Likelihood:                -117.28\n",
              " No. Observations:                 160   AIC:                             250.6\n",
              " Df Residuals:                     152   BIC:                             275.2\n",
              " Df Model:                           7                                         \n",
              " Covariance Type:            nonrobust                                         \n",
              " ====================================================================================\n",
              "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
              " ------------------------------------------------------------------------------------\n",
              " const                0.4002      0.459      0.871      0.385      -0.507       1.308\n",
              " age                 -0.0036      0.005     -0.714      0.476      -0.014       0.006\n",
              " sex                  0.2258      0.086      2.626      0.010       0.056       0.396\n",
              " side                -0.1853      0.083     -2.243      0.026      -0.348      -0.022\n",
              " MRD-1 pre            0.0042      0.037      0.113      0.910      -0.069       0.078\n",
              " levator_function    -0.0053      0.020     -0.262      0.794      -0.045       0.034\n",
              " intraocular_surg    -0.0866      0.098     -0.883      0.379      -0.280       0.107\n",
              " glaucoma            -0.1225      0.102     -1.198      0.233      -0.325       0.080\n",
              " ==============================================================================\n",
              " Omnibus:                        6.380   Durbin-Watson:                   2.102\n",
              " Prob(Omnibus):                  0.041   Jarque-Bera (JB):                6.101\n",
              " Skew:                           0.396   Prob(JB):                       0.0473\n",
              " Kurtosis:                       3.535   Cond. No.                         864.\n",
              " ==============================================================================\n",
              " \n",
              " Notes:\n",
              " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              " \"\"\")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "\n",
        "def print_bold(text):\n",
        "    print('\\033[1m' + text + '\\033[0m')\n",
        "\n",
        "def multivariate_regression_analysis(X, y, target):\n",
        "    print_bold(f\"\\n--- Multivariate Linear Regression Analysis for {target} ---\")\n",
        "    X_sm = sm.add_constant(X)\n",
        "    model = sm.OLS(y, X_sm).fit()\n",
        "    print(model.summary())\n",
        "\n",
        "    # Calculate and print MSE\n",
        "    y_pred = model.predict(X_sm)\n",
        "    mse = np.mean((y - y_pred)**2)\n",
        "    print_bold(f\"\\nMean Squared Error (MSE): {mse:.4f}\")\n",
        "\n",
        "def univariate_regression_analysis(X, y, target):\n",
        "    print_bold(f\"\\n--- Univariate Linear Regression Analysis for {target} ---\")\n",
        "    results = []\n",
        "    for column in X.columns:\n",
        "        X_uni = X[[column]]\n",
        "\n",
        "        # statsmodelsを使用して回帰分析を実行\n",
        "        X_sm = sm.add_constant(X_uni)\n",
        "        model_sm = sm.OLS(y, X_sm).fit()\n",
        "\n",
        "        # 結果を取得\n",
        "        coef = model_sm.params[column]  # 変数名を使用して係数を取得\n",
        "        std_err = model_sm.bse[column]\n",
        "        t_value = model_sm.tvalues[column]\n",
        "        p_value = model_sm.pvalues[column]\n",
        "        ci = model_sm.conf_int().loc[column]\n",
        "        r_squared = model_sm.rsquared\n",
        "\n",
        "        results.append({\n",
        "            'Variable': column,\n",
        "            'Coefficient': coef,\n",
        "            'Std Error': std_err,\n",
        "            't-value': t_value,\n",
        "            'P-value': p_value,\n",
        "            'CI Lower': ci[0],\n",
        "            'CI Upper': ci[1],\n",
        "            'R-squared': r_squared\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    pd.set_option('display.float_format', '{:.4f}'.format)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "# Prepare the data for regression analysis for Δasg_0 and Δasg_45\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1', 'levator_function', 'intraocular_surg', 'glaucoma']]\n",
        "X = sm.add_constant(X)  # Adding a constant term for the intercept\n",
        "\n",
        "# Dependent variables\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# Perform multivariate regression analysis\n",
        "multivariate_regression_analysis(X, y_asg_0, 'Δasg_0')\n",
        "multivariate_regression_analysis(X, y_asg_45, 'Δasg_45')\n",
        "\n",
        "# Perform univariate regression analysis\n",
        "univariate_regression_analysis(X, y_asg_0, 'Δasg_0')\n",
        "univariate_regression_analysis(X, y_asg_45, 'Δasg_45')"
      ],
      "metadata": {
        "id": "BMhdrWrqC-ad",
        "outputId": "d3bcc3b9-a492-408d-87d4-a98078eb6e70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "--- Multivariate Linear Regression Analysis for Δasg_0 ---\u001b[0m\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                 Δasg_0   R-squared:                       0.089\n",
            "Model:                            OLS   Adj. R-squared:                  0.027\n",
            "Method:                 Least Squares   F-statistic:                     1.448\n",
            "Date:                Sun, 01 Sep 2024   Prob (F-statistic):              0.165\n",
            "Time:                        14:48:34   Log-Likelihood:                -137.97\n",
            "No. Observations:                 160   AIC:                             297.9\n",
            "Df Residuals:                     149   BIC:                             331.8\n",
            "Df Model:                          10                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "====================================================================================\n",
            "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------\n",
            "const                1.0153      0.573      1.772      0.078      -0.117       2.147\n",
            "age                 -0.0023      0.006     -0.386      0.700      -0.014       0.010\n",
            "sex                 -0.2825      0.103     -2.739      0.007      -0.486      -0.079\n",
            "side                 0.0469      0.097      0.483      0.630      -0.145       0.239\n",
            "asg_0_pre           -0.0979      0.055     -1.788      0.076      -0.206       0.010\n",
            "asg_45_pre           0.1286      0.094      1.366      0.174      -0.057       0.315\n",
            "MRD-1 pre           -0.0333      0.031     -1.088      0.278      -0.094       0.027\n",
            "MRD-1 3M            -0.0585      0.035     -1.687      0.094      -0.127       0.010\n",
            "ΔMRD-1              -0.0252      0.025     -0.989      0.324      -0.076       0.025\n",
            "levator_function    -0.0241      0.023     -1.039      0.300      -0.070       0.022\n",
            "intraocular_surg    -0.0324      0.114     -0.284      0.777      -0.258       0.193\n",
            "glaucoma             0.0722      0.120      0.599      0.550      -0.166       0.310\n",
            "==============================================================================\n",
            "Omnibus:                        3.258   Durbin-Watson:                   1.739\n",
            "Prob(Omnibus):                  0.196   Jarque-Bera (JB):                2.933\n",
            "Skew:                           0.213   Prob(JB):                        0.231\n",
            "Kurtosis:                       3.508   Cond. No.                     2.23e+17\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 1.91e-29. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n",
            "\u001b[1m\n",
            "Mean Squared Error (MSE): 0.3285\u001b[0m\n",
            "\u001b[1m\n",
            "--- Multivariate Linear Regression Analysis for Δasg_45 ---\u001b[0m\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                Δasg_45   R-squared:                       0.163\n",
            "Model:                            OLS   Adj. R-squared:                  0.106\n",
            "Method:                 Least Squares   F-statistic:                     2.893\n",
            "Date:                Sun, 01 Sep 2024   Prob (F-statistic):            0.00248\n",
            "Time:                        14:48:34   Log-Likelihood:                -133.08\n",
            "No. Observations:                 160   AIC:                             288.2\n",
            "Df Residuals:                     149   BIC:                             322.0\n",
            "Df Model:                          10                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "====================================================================================\n",
            "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------\n",
            "const                0.6111      0.556      1.100      0.273      -0.487       1.709\n",
            "age                 -0.0035      0.006     -0.600      0.549      -0.015       0.008\n",
            "sex                  0.1150      0.100      1.150      0.252      -0.083       0.313\n",
            "side                -0.1813      0.094     -1.924      0.056      -0.367       0.005\n",
            "asg_0_pre           -0.0389      0.053     -0.732      0.465      -0.144       0.066\n",
            "asg_45_pre          -0.4231      0.091     -4.633      0.000      -0.604      -0.243\n",
            "MRD-1 pre           -0.0322      0.030     -1.087      0.279      -0.091       0.026\n",
            "MRD-1 3M            -0.0259      0.034     -0.770      0.442      -0.092       0.041\n",
            "ΔMRD-1               0.0063      0.025      0.257      0.798      -0.042       0.055\n",
            "levator_function    -0.0147      0.022     -0.656      0.513      -0.059       0.030\n",
            "intraocular_surg    -0.2105      0.111     -1.900      0.059      -0.429       0.008\n",
            "glaucoma             0.0605      0.117      0.518      0.605      -0.170       0.291\n",
            "==============================================================================\n",
            "Omnibus:                       61.832   Durbin-Watson:                   1.923\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              378.091\n",
            "Skew:                          -1.237   Prob(JB):                     7.92e-83\n",
            "Kurtosis:                      10.113   Cond. No.                     2.23e+17\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 1.91e-29. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n",
            "\u001b[1m\n",
            "Mean Squared Error (MSE): 0.3090\u001b[0m\n",
            "\u001b[1m\n",
            "--- Univariate Linear Regression Analysis for Δasg_0 ---\u001b[0m\n",
            "        Variable  Coefficient  Std Error  t-value  P-value  CI Lower  CI Upper  R-squared\n",
            "           const       0.2340     0.0476   4.9152   0.0000    0.1400    0.3281     0.0000\n",
            "             age       0.0000     0.0057   0.0084   0.9933   -0.0112    0.0112     0.0000\n",
            "             sex      -0.2032     0.0967  -2.1010   0.0372   -0.3941   -0.0122     0.0272\n",
            "            side       0.0263     0.0955   0.2750   0.7837   -0.1624    0.2150     0.0005\n",
            "       asg_0_pre      -0.0647     0.0486  -1.3302   0.1854   -0.1607    0.0314     0.0111\n",
            "      asg_45_pre       0.0898     0.0894   1.0041   0.3169   -0.0868    0.2664     0.0063\n",
            "       MRD-1 pre      -0.0448     0.0406  -1.1052   0.2707   -0.1250    0.0353     0.0077\n",
            "        MRD-1 3M      -0.0354     0.0470  -0.7523   0.4530   -0.1282    0.0575     0.0036\n",
            "          ΔMRD-1       0.0124     0.0334   0.3709   0.7112   -0.0536    0.0784     0.0009\n",
            "levator_function      -0.0279     0.0207  -1.3471   0.1799   -0.0688    0.0130     0.0114\n",
            "intraocular_surg      -0.0168     0.1103  -0.1523   0.8791   -0.2346    0.2010     0.0001\n",
            "        glaucoma       0.1103     0.1091   1.0114   0.3134   -0.1051    0.3257     0.0064\n",
            "\u001b[1m\n",
            "--- Univariate Linear Regression Analysis for Δasg_45 ---\u001b[0m\n",
            "        Variable  Coefficient  Std Error  t-value  P-value  CI Lower  CI Upper  R-squared\n",
            "           const      -0.0525     0.0482  -1.0898   0.2774   -0.1476    0.0426    -0.0000\n",
            "             age      -0.0005     0.0057  -0.0796   0.9366   -0.0118    0.0109     0.0000\n",
            "             sex       0.0154     0.0992   0.1548   0.8772   -0.1806    0.2113     0.0002\n",
            "            side      -0.1053     0.0963  -1.0929   0.2761   -0.2955    0.0850     0.0075\n",
            "       asg_0_pre      -0.0250     0.0494  -0.5058   0.6137   -0.1227    0.0726     0.0016\n",
            "      asg_45_pre      -0.3496     0.0864  -4.0454   0.0001   -0.5203   -0.1789     0.0939\n",
            "       MRD-1 pre      -0.0613     0.0409  -1.4978   0.1362   -0.1421    0.0195     0.0140\n",
            "        MRD-1 3M       0.0127     0.0477   0.2655   0.7909   -0.0815    0.1068     0.0004\n",
            "          ΔMRD-1       0.0477     0.0336   1.4182   0.1581   -0.0187    0.1141     0.0126\n",
            "levator_function      -0.0221     0.0210  -1.0550   0.2930   -0.0636    0.0193     0.0070\n",
            "intraocular_surg      -0.1521     0.1109  -1.3712   0.1723   -0.3713    0.0670     0.0118\n",
            "        glaucoma       0.0978     0.1104   0.8854   0.3773   -0.1203    0.3159     0.0049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Δasg_0について、関連しそうな変数を使用した多変量線形回帰分析\n",
        "X_reduced = X[['sex', 'asg_0_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "multivariate_regression_analysis(X_reduced, y_asg_0, 'Δasg_0')"
      ],
      "metadata": {
        "id": "gBt51TULDxMS",
        "outputId": "bb4a529c-6c88-4bf3-c1a9-ad4f813312b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "--- Multivariate Linear Regression Analysis for Δasg_0 ---\u001b[0m\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                 Δasg_0   R-squared:                       0.065\n",
            "Model:                            OLS   Adj. R-squared:                  0.041\n",
            "Method:                 Least Squares   F-statistic:                     2.703\n",
            "Date:                Sun, 01 Sep 2024   Prob (F-statistic):             0.0326\n",
            "Time:                        14:50:20   Log-Likelihood:                -140.00\n",
            "No. Observations:                 160   AIC:                             290.0\n",
            "Df Residuals:                     155   BIC:                             305.4\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.6263      0.189      3.309      0.001       0.252       1.000\n",
            "sex           -0.2628      0.099     -2.645      0.009      -0.459      -0.067\n",
            "asg_0_pre     -0.0996      0.052     -1.930      0.055      -0.201       0.002\n",
            "MRD-1 pre     -0.0266      0.041     -0.650      0.517      -0.108       0.054\n",
            "MRD-1 3M      -0.0836      0.051     -1.654      0.100      -0.183       0.016\n",
            "==============================================================================\n",
            "Omnibus:                        5.242   Durbin-Watson:                   1.763\n",
            "Prob(Omnibus):                  0.073   Jarque-Bera (JB):                5.266\n",
            "Skew:                           0.294   Prob(JB):                       0.0719\n",
            "Kurtosis:                       3.667   Cond. No.                         16.3\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\u001b[1m\n",
            "Mean Squared Error (MSE): 0.3369\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Δasg_45について、関連しそうな変数を使用した多変量線形回帰分析\n",
        "X_reduced = X[['asg_45_pre']]\n",
        "multivariate_regression_analysis(X_reduced, y_asg_45, 'Δasg_45')"
      ],
      "metadata": {
        "id": "yRSgAnoDEZJH",
        "outputId": "d9302508-b329-4d5c-e981-dd1c1e3cf2fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "--- Multivariate Linear Regression Analysis for Δasg_45 ---\u001b[0m\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                Δasg_45   R-squared:                       0.094\n",
            "Model:                            OLS   Adj. R-squared:                  0.088\n",
            "Method:                 Least Squares   F-statistic:                     16.37\n",
            "Date:                Sun, 01 Sep 2024   Prob (F-statistic):           8.15e-05\n",
            "Time:                        14:51:18   Log-Likelihood:                -139.39\n",
            "No. Observations:                 160   AIC:                             282.8\n",
            "Df Residuals:                     158   BIC:                             288.9\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.0604      0.046     -1.311      0.192      -0.151       0.031\n",
            "asg_45_pre    -0.3496      0.086     -4.045      0.000      -0.520      -0.179\n",
            "==============================================================================\n",
            "Omnibus:                       75.137   Durbin-Watson:                   1.925\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              655.295\n",
            "Skew:                          -1.440   Prob(JB):                    5.06e-143\n",
            "Kurtosis:                      12.487   Cond. No.                         1.88\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\u001b[1m\n",
            "Mean Squared Error (MSE): 0.3344\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Stepwise linear regression analysis #####\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tools import add_constant\n",
        "\n",
        "def print_bold(text):\n",
        "    print(f\"\\033[1m{text}\\033[0m\")\n",
        "\n",
        "def stepwise_selection(X, y, initial_list=[], threshold_in=0.01, threshold_out=0.05, verbose=True):\n",
        "    \"\"\" Perform a forward-backward feature selection\n",
        "    based on p-value from statsmodels.api.OLS\n",
        "    Arguments:\n",
        "        X - pandas.DataFrame with candidate features\n",
        "        y - list-like with the target\n",
        "        initial_list - list of features to start with (keep fixed)\n",
        "        threshold_in - include a feature if its p-value < threshold_in\n",
        "        threshold_out - exclude a feature if its p-value > threshold_out\n",
        "        verbose - whether to print the sequence of inclusions and exclusions\n",
        "    Returns: list of selected features\n",
        "    \"\"\"\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed = False\n",
        "        # forward step\n",
        "        excluded = list(set(X.columns) - set(included))\n",
        "        new_pval = pd.Series(index=excluded, dtype=float)\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        best_pval = new_pval.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_feature = new_pval.idxmin()\n",
        "            included.append(best_feature)\n",
        "            changed = True\n",
        "            if verbose:\n",
        "                print(f'Add  {best_feature} with p-value {best_pval}')\n",
        "        # backward step\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        # use all coefs except intercept\n",
        "        pvalues = model.pvalues.iloc[1:]\n",
        "        worst_pval = pvalues.max()\n",
        "        if worst_pval > threshold_out:\n",
        "            changed = True\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            included.remove(worst_feature)\n",
        "            if verbose:\n",
        "                print(f'Drop {worst_feature} with p-value {worst_pval}')\n",
        "        if not changed:\n",
        "            break\n",
        "    return included\n",
        "\n",
        "def linear_regression_analysis(X, y, target, test_size=0.2, random_state=0):\n",
        "    print_bold(f\"\\n--- Linear Regression Analysis for {target} ---\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    selected_features = stepwise_selection(X_train, y_train)\n",
        "    if not selected_features:\n",
        "        print(\"No features were selected using stepwise selection.\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    print(f\"Selected features: {selected_features}\")\n",
        "\n",
        "    X_train_selected = X_train[selected_features]\n",
        "    X_test_selected = X_test[selected_features]\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_selected, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
        "\n",
        "    X_train_sm = sm.add_constant(X_train_selected)\n",
        "    model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
        "    print(model_sm.summary())\n",
        "\n",
        "    # Calculate AIC\n",
        "    aic = model_sm.aic\n",
        "    print(f\"AIC: {aic:.4f}\")\n",
        "\n",
        "    return model, X_train_selected, X_test_selected, y_train, y_test, aic\n",
        "\n",
        "# Perform regression analysis for Δasg_0\n",
        "model_asg_0, X_train_asg_0, X_test_asg_0, y_train_asg_0, y_test_asg_0, aic_asg_0 = linear_regression_analysis(X, y_asg_0, 'Δasg_0')\n",
        "\n",
        "# Perform regression analysis for Δasg_45\n",
        "model_asg_45, X_train_asg_45, X_test_asg_45, y_train_asg_45, y_test_asg_45, aic_asg_45 = linear_regression_analysis(X, y_asg_45, 'Δasg_45')\n"
      ],
      "metadata": {
        "id": "0DCaNq73El9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Analysis\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the data\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1', \"intraocular_surg\", 'glaucoma']]\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_asg_0_train, y_asg_0_test = train_test_split(X, y_asg_0, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_asg_45_train, y_asg_45_test = train_test_split(X, y_asg_45, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Function to perform GridSearchCV and return the best model\n",
        "def get_best_rf_model(X_train, y_train):\n",
        "    rf = RandomForestRegressor(random_state=43)\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Get the best model for Δasg_0\n",
        "print(\"Tuning for Δasg_0:\")\n",
        "best_rf_asg_0 = get_best_rf_model(X_train, y_asg_0_train)\n",
        "\n",
        "# Get the best model for Δasg_45\n",
        "print(\"\\nTuning for Δasg_45:\")\n",
        "best_rf_asg_45 = get_best_rf_model(X_train, y_asg_45_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_0\n",
        "y_asg_0_pred = best_rf_asg_0.predict(X_test)\n",
        "mse_asg_0 = mean_squared_error(y_asg_0_test, y_asg_0_pred)\n",
        "r2_asg_0 = r2_score(y_asg_0_test, y_asg_0_pred)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_45\n",
        "y_asg_45_pred = best_rf_asg_45.predict(X_test)\n",
        "mse_asg_45 = mean_squared_error(y_asg_45_test, y_asg_45_pred)\n",
        "r2_asg_45 = r2_score(y_asg_45_test, y_asg_45_pred)\n",
        "\n",
        "print(f\"\\nResults after tuning:\")\n",
        "print(f\"MSE_Δasg0: {mse_asg_0}, r2_Δasg0: {r2_asg_0}\")\n",
        "print(f\"MSE_Δasg45: {mse_asg_45}, r2_Δasg45: {r2_asg_45}\")\n",
        "\n",
        "# Get feature importances for Δasg_0 model\n",
        "importances_asg_0 = best_rf_asg_0.feature_importances_\n",
        "feature_importances_asg_0 = pd.Series(importances_asg_0, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Get feature importances for Δasg_45 model\n",
        "importances_asg_45 = best_rf_asg_45.feature_importances_\n",
        "feature_importances_asg_45 = pd.Series(importances_asg_45, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Display top 5 important features\n",
        "print(\"\\nTop 5 important features for Δasg_0:\")\n",
        "print(feature_importances_asg_0.head())\n",
        "\n",
        "print(\"\\nTop 5 important features for Δasg_45:\")\n",
        "print(feature_importances_asg_45.head())"
      ],
      "metadata": {
        "id": "SFhpAXETE2PK",
        "outputId": "e5b3a958-77c0-46ea-adc7-51cf8d3765ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning for Δasg_0:\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
            "\n",
            "Tuning for Δasg_45:\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
            "\n",
            "Results after tuning:\n",
            "MSE_Δasg0: 0.6128959889745358, r2_Δasg0: -0.10805400518611608\n",
            "MSE_Δasg45: 0.23323029963705993, r2_Δasg45: 0.01651053915690459\n",
            "\n",
            "Top 5 important features for Δasg_0:\n",
            "asg_0_pre    0.2893\n",
            "asg_45_pre   0.2145\n",
            "age          0.1333\n",
            "MRD-1 3M     0.0814\n",
            "ΔMRD-1       0.0661\n",
            "dtype: float64\n",
            "\n",
            "Top 5 important features for Δasg_45:\n",
            "asg_45_pre   0.3943\n",
            "age          0.1691\n",
            "asg_0_pre    0.1594\n",
            "MRD-1 pre    0.0729\n",
            "ΔMRD-1       0.0681\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}