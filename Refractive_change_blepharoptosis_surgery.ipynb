{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRg6WH3/5qxtMDAeMdhBmN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/statistics_for_articles/blob/main/Refractive_change_blepharoptosis_surgery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Refractive change in blepharoptosis surgery**"
      ],
      "metadata": {
        "id": "OqObWQc1_T1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yup3T2Lay4gD",
        "outputId": "3f3590e2-0830-4f40-efa4-831aaffe4f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 300)\n",
        "pd.set_option('display.max_rows', 300)"
      ],
      "metadata": {
        "id": "9nC8Dlyz7RBz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂.xlsx\"\n",
        "\n",
        "data = pd.read_excel(xlsx_path, header=1)\n",
        "\n",
        "# Display the first few rows of the dataframe and its columns to understand its structure\n",
        "#data"
      ],
      "metadata": {
        "id": "nVb210bozJ73",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Filter rows where surgery is bilateral (手術側 == 'B')\n",
        "bilateral_cases = data[data['手術側'] == 'B'].copy()\n",
        "unilateral_cases = data[data['手術側'] != 'B'].copy()\n",
        "unilateral_right_cases = data[data['手術側'] == 'R'].copy()\n",
        "unilateral_left_cases = data[data['手術側'] == 'L'].copy()\n",
        "print(f\"Number of bilateral cases: {len(bilateral_cases)}\")\n",
        "print(f\"Number of unilateral cases: {len(unilateral_cases)}\")\n",
        "\n",
        "# Step 2: Duplicate these rows for 'R' and 'L'\n",
        "bilateral_right_cases = bilateral_cases.copy()\n",
        "bilateral_left_cases = bilateral_cases.copy()\n",
        "\n",
        "# Assign 'R' and 'L' to the new surgery side columns\n",
        "bilateral_right_cases.loc[:, '手術側'] = 'R'\n",
        "bilateral_left_cases.loc[:, '手術側'] = 'L'\n",
        "\n",
        "# Step 3: Concatenate the modified bilateral and unilateral cases\n",
        "right_cases = pd.concat([bilateral_right_cases, unilateral_right_cases])\n",
        "left_cases = pd.concat([bilateral_left_cases, unilateral_left_cases])\n",
        "\n",
        "# Step 3: Rename and reallocate columns containing 'R' or 'L' for bilateral cases\n",
        "for column in right_cases.columns:\n",
        "    if ' R' in column:\n",
        "        # Extract the base column name without ' R'\n",
        "        new_column_name = column.replace(' R', '')\n",
        "        # Copy data to a new column without side specification\n",
        "        right_cases.loc[:, new_column_name] = right_cases[column]\n",
        "        # Drop the original ' R' column\n",
        "        right_cases.drop(column, axis=1, inplace=True)\n",
        "    elif ' L' in column:\n",
        "        # # Extract the base column name without ' L'\n",
        "        # new_column_name = column.replace(' L', '')\n",
        "        # # Copy data to a new column without side specification\n",
        "        # right_cases.loc[:, new_column_name] = right_cases[column]\n",
        "        # Drop the original ' L' column\n",
        "        right_cases.drop(column, axis=1, inplace=True)\n",
        "\n",
        "for column in left_cases.columns:\n",
        "    if ' R' in column:\n",
        "        # # Extract the base column name without ' R'\n",
        "        # new_column_name = column.replace(' R', '')\n",
        "        # # Copy data to a new column without side specification\n",
        "        # left_cases.loc[:, new_column_name] = left_cases[column]\n",
        "        # # Drop the original ' R' column\n",
        "        left_cases.drop(column, axis=1, inplace=True)\n",
        "    elif ' L' in column:\n",
        "        # Extract the base column name without ' L'\n",
        "        new_column_name = column.replace(' L', '')\n",
        "        # Copy data to a new column without side specification\n",
        "        left_cases.loc[:, new_column_name] = left_cases[column]\n",
        "        # Drop the original ' L' column\n",
        "        left_cases.drop(column, axis=1, inplace=True)\n",
        "\n",
        "# Combine the duplicated rows back into a single dataframe\n",
        "final_df = pd.concat([right_cases, left_cases])\n",
        "final_df = final_df.sort_values(by='ID').reset_index(drop=True)\n",
        "# ソート後のデータフレームを表示して確認\n",
        "#final_df\n",
        "\n",
        "#final_df.to_excel('output.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "knMc1iJR6Ciu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f89c9b0-333e-448e-c0c4-3370b2733648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of bilateral cases: 94\n",
            "Number of unilateral cases: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['波面3M'] = final_df[['波面3M', '波面4M', '波面post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['波面4M', '波面post'], inplace=True)\n",
        "    print(\"波面3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['AveK 3M'] = final_df[['AveK 3M', 'AveK post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['AveK post'], inplace=True)\n",
        "    print(\"AveK 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['CYL 3M'] = final_df[['CYL 3M', 'CYL post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['CYL post'], inplace=True)\n",
        "    print(\"CYL 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "lgJLhag6ELZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b4f4a6-54e8-41b5-b0d9-820cac9d9df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "波面3M updated!\n",
            "AveK 3M updated!\n",
            "CYL 3M updated!\n",
            "angle 3M updated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# レフケラの欠損値を削除：Drop rows with missing values only in specified columns\n",
        "specified_columns = ['AveK pre', 'AveK 3M', 'CYL pre', 'CYL 3M', 'angle pre', 'angle 3M', 'MRD-1 pre', 'MRD-1 3M']\n",
        "final_df = final_df.dropna(subset=specified_columns).reset_index(drop=True)\n",
        "\n",
        "# SPKの有無を数字に置換\n",
        "final_df[\"SPK pre\"] = final_df[\"SPK pre\"].replace({\"あり\": 1, \"なし\": 0})\n",
        "final_df[\"SPK post\"] = final_df[\"SPK post\"].replace({\"あり\": 1, \"なし\": 0})\n",
        "# 57行目の\"MRD-1 pre\"列の値を0.5に置換\n",
        "final_df.at[57, \"MRD-1 pre\"] = 0.5\n",
        "\n",
        "# # 挙筋機能\"good\"のカラムを10に置換\n",
        "# final_df[\"挙筋機能 pre\"] = final_df[\"挙筋機能 pre\"].replace(\"good\", 10)\n",
        "\n",
        "# 挙筋機能\"good\"のカラムを10に置換し、10より大きい値も10に制限する\n",
        "final_df[\"挙筋機能 pre\"] = final_df[\"挙筋機能 pre\"].replace(\"good\", 10)\n",
        "final_df[\"挙筋機能 pre\"] = pd.to_numeric(final_df[\"挙筋機能 pre\"], errors='coerce')\n",
        "final_df[\"挙筋機能 pre\"] = final_df[\"挙筋機能 pre\"].clip(upper=10)\n",
        "\n",
        "\n",
        "# \"MRD-1 3M\"列と\"挙筋機能 pre\"列をfloat型に変換\n",
        "final_df[\"MRD-1 pre\"] = final_df[\"MRD-1 pre\"].astype(float)\n",
        "final_df[\"MRD-1 3M\"] = final_df[\"MRD-1 3M\"].astype(float)\n",
        "final_df[\"挙筋機能 pre\"] = final_df[\"挙筋機能 pre\"].astype(float)\n",
        "\n",
        "final_df[\"sex\"] = final_df[\"sex\"].replace({\"M\": 1, \"F\": 0})\n",
        "final_df[\"手術側\"] = final_df[\"手術側\"].replace({\"L\": 1, \"R\": 0})\n",
        "\n",
        "#ΔMRD-1という列を新規に作成\n",
        "final_df[\"ΔMRD-1\"] = final_df[\"MRD-1 3M\"] - final_df[\"MRD-1 pre\"]\n",
        "\n",
        "final_df"
      ],
      "metadata": {
        "id": "Fb8lFR0bz-vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_excel('眼瞼下垂_proprocessed1.1.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "qc9S9nxE3N49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########\n",
        "#分析用のカラムに変更。SIAの計算\n",
        "##########\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 元のカラムリスト\n",
        "original_columns = ['ID', 'name', 'date', 'birthday', 'age', 'sex', '手術側', '備考', '挙筋短縮術後', 'Unnamed: 9', 'date.1', '手術側.1', '波面', 'post date', 'CASIA post date', 'レフケラ post date', '手術側.2', '矯正視力pre', '矯正視力3M', 'preMS(4mm)>=0.3', '波面pre', '波面1Ｍ', '波面2Ｍ', '波面3M', 'AveK pre', 'AveK 3M', 'CYL pre', 'CYL 3M', 'angle pre', 'angle 3M', 'レフケラAVE pre', 'レフケラAVE 3～12M', 'レフケラAVE post', 'レフケラCYL pre', 'レフケラCYL 3～12M', 'レフケラCYL post', 'レフケラangle pre', 'レフケラangle 3～12M', 'レフケラangle post', 'MRD-1 pre', 'MRD-1 3M', '挙筋機能 pre', '挙筋機能 3M', 'SPK pre', 'SPK post']\n",
        "\n",
        "# 新しいカラムリスト\n",
        "new_columns = ['ID', 'name', 'date', 'birthday', 'age', 'sex', 'side', 'intraoocular_surg', 'corneal_matter', 'gla_surg', 'glaucoma', 'eyelid_surg', '備考', '挙筋短縮術後', 'Unnamed: 9', 'date.1', '手術側.1', '矯正視力pre', '矯正視力3M', '波面pre', '波面1Ｍ', '波面2Ｍ', '波面3M', 'AveK pre', 'AveK 3M', 'CYL pre', 'CYL 3M', 'angle pre', 'angle 3M', 'asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45', 'SIA_D', 'SIA_ax', 'MRD-1 pre', 'MRD-1 3M', 'levator_function', '挙筋機能 3M', 'SPK pre', 'SPK post']\n",
        "\n",
        "# カラムのマッピングを作成\n",
        "column_mapping = {\n",
        "    'ID': 'ID',\n",
        "    'name': 'name',\n",
        "    'date': 'date',\n",
        "    'birthday': 'birthday',\n",
        "    'age': 'age',\n",
        "    'sex': 'sex',\n",
        "    'side': '手術側',\n",
        "    'intraoocular_surg': None,\n",
        "    'corneal_matter': None,\n",
        "    'gla_surg': None,\n",
        "    'glaucoma': None,\n",
        "    'eyelid_surg': None,\n",
        "    '備考': '備考',\n",
        "    '挙筋短縮術後': '挙筋短縮術後',\n",
        "    'Unnamed: 9': 'Unnamed: 9',\n",
        "    'date.1': 'date.1',\n",
        "    '手術側.1': '手術側.1',\n",
        "    '矯正視力pre': '矯正視力pre',\n",
        "    '矯正視力3M': '矯正視力3M',\n",
        "    '波面pre': '波面pre',\n",
        "    '波面1Ｍ': '波面1Ｍ',\n",
        "    '波面2Ｍ': '波面2Ｍ',\n",
        "    '波面3M': '波面3M',\n",
        "    'AveK pre': 'AveK pre',\n",
        "    'AveK 3M': 'AveK 3M',\n",
        "    'CYL pre': 'CYL pre',\n",
        "    'CYL 3M': 'CYL 3M',\n",
        "    'angle pre': 'angle pre',\n",
        "    'angle 3M': 'angle 3M',\n",
        "    'MRD-1 pre': 'MRD-1 pre',\n",
        "    'MRD-1 3M': 'MRD-1 3M',\n",
        "    'levator_function': '挙筋機能 pre',\n",
        "    '挙筋機能 3M': '挙筋機能 3M',\n",
        "    'SPK pre': 'SPK pre',\n",
        "    'SPK post': 'SPK post'\n",
        "}\n",
        "\n",
        "# データを読み込む（ファイル名は適宜変更してください）\n",
        "df = pd.read_excel('眼瞼下垂_proprocessed1.1.xlsx')\n",
        "\n",
        "# 新しいデータフレームを作成\n",
        "new_df = pd.DataFrame()\n",
        "\n",
        "# 新しいカラムに対応するデータを設定\n",
        "for new_col in new_columns:\n",
        "    if new_col in column_mapping and column_mapping[new_col] is not None and column_mapping[new_col] in df.columns:\n",
        "        new_df[new_col] = df[column_mapping[new_col]]\n",
        "    else:\n",
        "        new_df[new_col] = None\n",
        "\n",
        "# asg_0_pre と asg_45_pre の計算\n",
        "new_df['asg_0_pre'] = np.abs(new_df['CYL pre']) * np.cos(np.radians(new_df['angle pre'] * 2))\n",
        "new_df['asg_45_pre'] = np.abs(new_df['CYL pre']) * np.sin(np.radians(new_df['angle pre'] * 2))\n",
        "\n",
        "# asg_0_3M と asg_45_3M の計算\n",
        "new_df['asg_0_3M'] = np.abs(new_df['CYL 3M']) * np.cos(np.radians(new_df['angle 3M'] * 2))\n",
        "new_df['asg_45_3M'] = np.abs(new_df['CYL 3M']) * np.sin(np.radians(new_df['angle 3M'] * 2))\n",
        "\n",
        "# Δasg_0 と Δasg_45 の計算\n",
        "new_df['Δasg_0'] = new_df['asg_0_3M'] - new_df['asg_0_pre']\n",
        "new_df['Δasg_45'] = new_df['asg_45_3M'] - new_df['asg_45_pre']\n",
        "\n",
        "# SIA_D と SIA_ax の計算\n",
        "new_df['SIA_D'] = np.sqrt(new_df['Δasg_0']**2 + new_df['Δasg_45']**2)\n",
        "new_df['SIA_ax'] = 0.5 * np.degrees(np.arctan2(new_df['Δasg_45'], new_df['Δasg_0']))\n",
        "\n",
        "# 新しいExcelファイルとして保存（ファイル名は適宜変更してください）\n",
        "new_df.to_excel('眼瞼下垂_proprocessed1.2.xlsx', index=False)\n",
        "\n",
        "print(\"新しいExcelファイルが作成されました。\")"
      ],
      "metadata": {
        "id": "8qITWJ6y4Ox8",
        "outputId": "a3038d11-5f98-4d0e-8156-38a9f0a61992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "新しいExcelファイルが作成されました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessed_dataを用いて解析**"
      ],
      "metadata": {
        "id": "lns4IjGOVq77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J5sUBakWORy",
        "outputId": "ab6d1ead-2335-4a44-e1cb-6c40daa7e989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 300)\n",
        "pd.set_option('display.max_rows', 300)"
      ],
      "metadata": {
        "id": "C-JwDuMtWLWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂_proprocessed.xlsx\"\n",
        "\n",
        "data = pd.read_excel(xlsx_path, header=0)\n",
        "\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "id": "12LgQoOAWQqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2f4257-f9db-459a-d735-8fd32388b996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 112\n",
            "Total number of rows: 189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 眼瞼手術歴を除外\n",
        "##################\n",
        "\n",
        "# Filter out rows where 'exclude' column is equal to 1\n",
        "data = data[data['eyelid_surg'] != 1]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY-iSF1bSX-q",
        "outputId": "2771b495-2279-4a72-f020-e9c1880718dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 107\n",
            "Total number of rows: 179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# 角膜混濁/HCL症例を除外\n",
        "########################\n",
        "\n",
        "# Filter out rows where 'exclude' column is equal to 1\n",
        "data = data[data['corneal_matter'] != 1]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9ZtBRlEuM30",
        "outputId": "f1f65278-854e-4535-a3e5-55dbb6b7169a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 101\n",
            "Total number of rows: 167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 緑内障症例を抽出\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['glaucoma'] == 1]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kJkYilnu7sX",
        "outputId": "86f194fe-71a7-4812-ebd8-698001d21ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 31\n",
            "Total number of rows: 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 緑内障症例を除外\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['glaucoma'] == 0]\n",
        "\n",
        "# Display the first few rows of the resulting data to confirm\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZtMiHX_vBbw",
        "outputId": "aa7e1100-c81d-4beb-ddfe-f71df0721bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 眼内手術歴なしを抽出\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['intraoocular_surg'] == 0]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBESEHHnTShV",
        "outputId": "1ec93f46-d05f-406f-fea7-7e876b64d308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 眼内手術歴ありを抽出\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['intraoocular_surg'] != 0]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uxhtfvYTrld",
        "outputId": "750334ce-4254-487e-eceb-428c25ce3eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 79\n",
            "Total number of rows: 129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 外れ値を除外\n",
        "##################\n",
        "\n",
        "def remove_outliers(data, columns):\n",
        "    for column in columns:\n",
        "        q1 = data[column].quantile(0.25)\n",
        "        q3 = data[column].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "        data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
        "    return data\n",
        "\n",
        "# 外れ値を除外する列のリスト\n",
        "columns_to_remove_outliers = [\"asg_0_pre\", \"asg_45_pre\", \"MRD-1 3M\"]\n",
        "\n",
        "# Count the number of unique IDs\n",
        "unique_id_count = data['ID'].nunique()\n",
        "\n",
        "# Get the total number of rows\n",
        "total_rows = len(data)\n",
        "print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "print(f\"Total number of rows: {total_rows}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWXMZ2qqHwtR",
        "outputId": "f5512bcf-24f0-4263-9b2e-8357c91c9761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique IDs: 104\n",
            "Total number of rows: 172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 緑内障手術歴ありを抽出\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['gla_surg'] == 1]\n",
        "\n",
        "# Display the first few rows of the resulting data to confirm\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qisi3sTiYrYv",
        "outputId": "85f124e7-5442-4654-c89a-58a930942d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "# 緑内障手術歴なしを抽出\n",
        "##################\n",
        "\n",
        "# Filter the data to include only rows where 'intraoocular_surg' is equal to 0\n",
        "data = data[data['gla_surg'] == 0]\n",
        "\n",
        "# Display the first few rows of the resulting data to confirm\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-6d2sq7YxuI",
        "outputId": "eff557e9-b196-40d0-ff61-ee7acda67ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**術前の屈折（sideによる有意差）**"
      ],
      "metadata": {
        "id": "tbN_MZ8bz-cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なライブラリのインポート\n",
        "from scipy.stats import ttest_ind\n",
        "import pandas as pd\n",
        "\n",
        "# 独立t検定のための平均、標準偏差、およびp値を計算する関数\n",
        "def calculate_independent_statistics(side0, side1):\n",
        "    mean_side0 = side0.mean()\n",
        "    std_side0 = side0.std()\n",
        "    mean_side1 = side1.mean()\n",
        "    std_side1 = side1.std()\n",
        "\n",
        "    t_test = ttest_ind(side0.dropna(), side1.dropna(), nan_policy='omit')\n",
        "\n",
        "    return {\n",
        "        'side0_mean_sd': f\"{mean_side0:.3f} ± {std_side0:.3f}\",\n",
        "        'side1_mean_sd': f\"{mean_side1:.3f} ± {std_side1:.3f}\",\n",
        "        'p_value': f\"{t_test.pvalue:.3e}\"\n",
        "    }\n",
        "\n",
        "# サイドごとの統計量を計算し、結果を表示する関数\n",
        "def process_and_print_statistics(data, column_name):\n",
        "    side0 = data[data['side'] == 0][column_name]\n",
        "    side1 = data[data['side'] == 1][column_name]\n",
        "    stats = calculate_independent_statistics(side0, side1)\n",
        "    print(f\"{column_name}: {stats}\")\n",
        "\n",
        "# 統計量を計算する列のリスト\n",
        "columns_to_process = ['asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45']\n",
        "\n",
        "# 各列に対して統計量を計算し、結果を表示\n",
        "for column in columns_to_process:\n",
        "    process_and_print_statistics(data, column)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hny5i4F6Dbo0",
        "outputId": "0c8c1af6-8a1b-4f95-d8ac-f1c5bc46d474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asg_0_pre: {'side0_mean_sd': '-0.146 ± 0.922', 'side1_mean_sd': '-0.075 ± 0.989', 'p_value': '6.442e-01'}\n",
            "asg_45_pre: {'side0_mean_sd': '0.104 ± 0.435', 'side1_mean_sd': '-0.131 ± 0.574', 'p_value': '4.624e-03'}\n",
            "asg_0_3M: {'side0_mean_sd': '0.073 ± 1.066', 'side1_mean_sd': '0.156 ± 1.049', 'p_value': '6.259e-01'}\n",
            "asg_45_3M: {'side0_mean_sd': '0.083 ± 0.624', 'side1_mean_sd': '-0.230 ± 0.702', 'p_value': '3.919e-03'}\n",
            "Δasg_0: {'side0_mean_sd': '0.219 ± 0.600', 'side1_mean_sd': '0.231 ± 0.597', 'p_value': '9.012e-01'}\n",
            "Δasg_45: {'side0_mean_sd': '-0.022 ± 0.539', 'side1_mean_sd': '-0.099 ± 0.681', 'p_value': '4.327e-01'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr, linregress\n",
        "\n",
        "def calculate_correlation_and_p_value(column1, column2):\n",
        "    column1_clean = column1.dropna()\n",
        "    column2_clean = column2.dropna()\n",
        "    common_index = column1_clean.index.intersection(column2_clean.index)\n",
        "    column1_clean = column1_clean.loc[common_index]\n",
        "    column2_clean = column2_clean.loc[common_index]\n",
        "\n",
        "    correlation, p_value = pearsonr(column1_clean, column2_clean)\n",
        "    return correlation, p_value, column1_clean, column2_clean\n",
        "\n",
        "def analyze_and_plot_correlation_with_MRD1_pre(data, target_column, x_lim, y_lim):\n",
        "    MRD1_pre = data['MRD-1 pre']\n",
        "    correlation, p_value, target_data_clean, MRD1_pre_clean = calculate_correlation_and_p_value(data[target_column], MRD1_pre)\n",
        "\n",
        "    # Calculate regression line\n",
        "    slope, intercept, _, _, _ = linregress(MRD1_pre_clean, target_data_clean)\n",
        "    regression_line = slope * MRD1_pre_clean + intercept\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.scatter(MRD1_pre_clean, target_data_clean, alpha=0.5, color='black', s=200)\n",
        "    plt.plot(MRD1_pre_clean, regression_line, color='red', linewidth=5)\n",
        "    plt.title(f'Correlation between {target_column} and MRD-1 pre\\n'\n",
        "              f'r={correlation:.3f}, p={p_value:.3f}', fontsize=24)  # Reduced font size by half\n",
        "    plt.xlabel('MRD-1 pre', fontsize=44)\n",
        "    plt.ylabel(target_column, fontsize=44)\n",
        "    # Legend removed\n",
        "    plt.xlim(x_lim)\n",
        "    plt.ylim(y_lim)\n",
        "    plt.xticks(fontsize=36)\n",
        "    plt.yticks(fontsize=36)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 調査する列のリスト\n",
        "columns_to_analyze = ['asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45']\n",
        "\n",
        "# グラフのスケールを決定\n",
        "x_min = data['MRD-1 pre'].min()\n",
        "x_max = data['MRD-1 3M'].max()\n",
        "y_min = min(data[col].min() for col in columns_to_analyze)\n",
        "y_max = max(data[col].max() for col in columns_to_analyze)\n",
        "\n",
        "# 各列に対して相関を分析してグラフを描画\n",
        "for column in columns_to_analyze:\n",
        "    analyze_and_plot_correlation_with_MRD1_pre(data, column, (x_min, x_max), (y_min, y_max))"
      ],
      "metadata": {
        "id": "VQ5LDk2lGRY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr, linregress\n",
        "\n",
        "def calculate_correlation_and_p_value(column1, column2):\n",
        "    column1_clean = column1.dropna()\n",
        "    column2_clean = column2.dropna()\n",
        "    common_index = column1_clean.index.intersection(column2_clean.index)\n",
        "    column1_clean = column1_clean.loc[common_index]\n",
        "    column2_clean = column2_clean.loc[common_index]\n",
        "\n",
        "    correlation, p_value = pearsonr(column1_clean, column2_clean)\n",
        "    return correlation, p_value, column1_clean, column2_clean\n",
        "\n",
        "def analyze_and_plot_correlation_with_MRD1_pre(data, target_column, x_lim, y_lim):\n",
        "    MRD1_pre = data['MRD-1 3M']\n",
        "    correlation, p_value, target_data_clean, MRD1_pre_clean = calculate_correlation_and_p_value(data[target_column], MRD1_pre)\n",
        "\n",
        "    # Calculate regression line\n",
        "    slope, intercept, _, _, _ = linregress(MRD1_pre_clean, target_data_clean)\n",
        "    regression_line = slope * MRD1_pre_clean + intercept\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.scatter(MRD1_pre_clean, target_data_clean, alpha=0.5, color='black', s=200)\n",
        "    plt.plot(MRD1_pre_clean, regression_line, color='red', linewidth=5)\n",
        "    plt.title(f'Correlation between {target_column} and MRD-1 3M\\n'\n",
        "              f'r={correlation:.3f}, p={p_value:.3f}', fontsize=24)  # Reduced font size by half\n",
        "    plt.xlabel('MRD-1 3M', fontsize=44)\n",
        "    plt.ylabel(target_column, fontsize=44)\n",
        "    # Legend removed\n",
        "    plt.xlim(x_lim)\n",
        "    plt.ylim(y_lim)\n",
        "    plt.xticks(fontsize=36)\n",
        "    plt.yticks(fontsize=36)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 調査する列のリスト\n",
        "columns_to_analyze = ['asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45']\n",
        "\n",
        "# グラフのスケールを決定\n",
        "x_min = data['MRD-1 pre'].min()\n",
        "x_max = data['MRD-1 3M'].max()\n",
        "y_min = min(data[col].min() for col in columns_to_analyze)\n",
        "y_max = max(data[col].max() for col in columns_to_analyze)\n",
        "\n",
        "# 各列に対して相関を分析してグラフを描画\n",
        "for column in columns_to_analyze:\n",
        "    analyze_and_plot_correlation_with_MRD1_pre(data, column, (x_min, x_max), (y_min, y_max))"
      ],
      "metadata": {
        "id": "d3ofPJMylk48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr, linregress\n",
        "\n",
        "def calculate_correlation_and_p_value(column1, column2):\n",
        "    column1_clean = column1.dropna()\n",
        "    column2_clean = column2.dropna()\n",
        "    common_index = column1_clean.index.intersection(column2_clean.index)\n",
        "    column1_clean = column1_clean.loc[common_index]\n",
        "    column2_clean = column2_clean.loc[common_index]\n",
        "\n",
        "    correlation, p_value = pearsonr(column1_clean, column2_clean)\n",
        "    return correlation, p_value, column1_clean, column2_clean\n",
        "\n",
        "def analyze_and_plot_correlation_with_MRD1_pre(data, target_column, x_lim, y_lim):\n",
        "    MRD1_pre = data['ΔMRD-1']\n",
        "    correlation, p_value, target_data_clean, MRD1_pre_clean = calculate_correlation_and_p_value(data[target_column], MRD1_pre)\n",
        "\n",
        "    # Calculate regression line\n",
        "    slope, intercept, _, _, _ = linregress(MRD1_pre_clean, target_data_clean)\n",
        "    regression_line = slope * MRD1_pre_clean + intercept\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.scatter(MRD1_pre_clean, target_data_clean, alpha=0.5, color='black', s=200)\n",
        "    plt.plot(MRD1_pre_clean, regression_line, color='red', linewidth=5)\n",
        "    plt.title(f'Correlation between {target_column} and ΔMRD-1\\n'\n",
        "              f'r={correlation:.3f}, p={p_value:.3f}', fontsize=24)  # Reduced font size by half\n",
        "    plt.xlabel('ΔMRD-1', fontsize=44)\n",
        "    plt.ylabel(target_column, fontsize=44)\n",
        "    # Legend removed\n",
        "    plt.xlim(x_lim)\n",
        "    plt.ylim(y_lim)\n",
        "    plt.xticks(fontsize=36)\n",
        "    plt.yticks(fontsize=36)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 調査する列のリスト\n",
        "columns_to_analyze = ['asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45']\n",
        "\n",
        "# グラフのスケールを決定\n",
        "x_min = data['ΔMRD-1'].min()\n",
        "x_max = data['ΔMRD-1'].max()\n",
        "y_min = min(data[col].min() for col in columns_to_analyze)\n",
        "y_max = max(data[col].max() for col in columns_to_analyze)\n",
        "\n",
        "# 各列に対して相関を分析してグラフを描画\n",
        "for column in columns_to_analyze:\n",
        "    analyze_and_plot_correlation_with_MRD1_pre(data, column, (x_min, x_max), (y_min, y_max))"
      ],
      "metadata": {
        "id": "27vkLNUJuTz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MRD-1 preとasg45_preとの関係（side別）\n",
        "\n",
        "# MRD-1 pre との関連を調べてグラフを描画するための関数（side別）\n",
        "def analyze_and_plot_correlation_with_MRD1_pre_by_side(data, target_column):\n",
        "    sides = data['side'].unique()\n",
        "\n",
        "    for side in sides:\n",
        "        side_data = data[data['side'] == side]\n",
        "        MRD1_pre = side_data['MRD-1 pre']\n",
        "        correlation, p_value, target_data_clean, MRD1_pre_clean = calculate_correlation_and_p_value(side_data[target_column], MRD1_pre)\n",
        "\n",
        "        # 回帰線の計算\n",
        "        slope, intercept, _, _, _ = linregress(MRD1_pre_clean, target_data_clean)\n",
        "        regression_line = slope * MRD1_pre_clean + intercept\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(MRD1_pre_clean, target_data_clean, alpha=0.5, color='black', label='Data points')\n",
        "        plt.plot(MRD1_pre_clean, regression_line, color='red', label='Fit line')\n",
        "        plt.title(f'Correlation between {target_column} and MRD-1 pre (side {side})\\n'\n",
        "                  f'r={correlation:.3f}, p={p_value:.3f}')\n",
        "        plt.xlabel('MRD-1 pre')\n",
        "        plt.ylabel(target_column)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "# グラフ化したい列の指定\n",
        "target_column = 'asg_45_pre'\n",
        "\n",
        "# 指定した列に対して相関を分析し、side別にグラフを描画\n",
        "analyze_and_plot_correlation_with_MRD1_pre_by_side(data, target_column)\n"
      ],
      "metadata": {
        "id": "JYYMdEFxNHS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**各項目の変化**"
      ],
      "metadata": {
        "id": "Ct-sEXI_u8ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#正規分布でないことを確認\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import shapiro\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Extract relevant columns\n",
        "asg_0_pre = data['asg_0_pre']\n",
        "asg_0_3M = data['asg_0_3M']\n",
        "asg_45_pre = data['asg_45_pre']\n",
        "asg_45_3M = data['asg_45_3M']\n",
        "\n",
        "# Define a function to check normality\n",
        "def check_normality(data):\n",
        "    stat, p = shapiro(data.dropna())\n",
        "    return stat, p\n",
        "\n",
        "# Check normality for each group\n",
        "asg_0_pre_normality = check_normality(asg_0_pre)\n",
        "asg_0_3M_normality = check_normality(asg_0_3M)\n",
        "asg_45_pre_normality = check_normality(asg_45_pre)\n",
        "asg_45_3M_normality = check_normality(asg_45_3M)\n",
        "# Define a function to plot Q-Q plots\n",
        "def plot_qq(data, ax, title):\n",
        "    stats.probplot(data.dropna(), dist=\"norm\", plot=ax)\n",
        "    ax.set_title(title)\n",
        "\n",
        "# Create histograms and Q-Q plots for visual inspection\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "\n",
        "# Histograms\n",
        "sns.histplot(asg_0_pre.dropna(), kde=True, ax=axes[0, 0]).set(title='asg_0_pre Histogram')\n",
        "sns.histplot(asg_0_3M.dropna(), kde=True, ax=axes[0, 1]).set(title='asg_0_3M Histogram')\n",
        "sns.histplot(asg_45_pre.dropna(), kde=True, ax=axes[0, 2]).set(title='asg_45_pre Histogram')\n",
        "sns.histplot(asg_45_3M.dropna(), kde=True, ax=axes[0, 3]).set(title='asg_45_3M Histogram')\n",
        "\n",
        "# Q-Q plots\n",
        "plot_qq(asg_0_pre, axes[1, 0], 'asg_0_pre Q-Q Plot')\n",
        "plot_qq(asg_0_3M, axes[1, 1], 'asg_0_3M Q-Q Plot')\n",
        "plot_qq(asg_45_pre, axes[1, 2], 'asg_45_pre Q-Q Plot')\n",
        "plot_qq(asg_45_3M, axes[1, 3], 'asg_45_3M Q-Q Plot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "asg_0_pre_normality, asg_0_3M_normality, asg_45_pre_normality, asg_45_3M_normality\n"
      ],
      "metadata": {
        "id": "qoAh9sFvvCND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Wilcoxon signed-rank test to compare pre and 3M values\n",
        "asg_0_wilcoxon = stats.wilcoxon(asg_0_pre.dropna(), asg_0_3M.dropna())\n",
        "asg_45_wilcoxon = stats.wilcoxon(asg_45_pre.dropna(), asg_45_3M.dropna())\n",
        "\n",
        "asg_0_wilcoxon, asg_45_wilcoxon\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8c7NWGNv27q",
        "outputId": "a7d665ab-3f30-478f-8cb5-e679755b485a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(WilcoxonResult(statistic=4269.0, pvalue=1.9673109497202122e-06),\n",
              " WilcoxonResult(statistic=6715.0, pvalue=0.3250911574386459))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from scipy.stats import ttest_rel\n",
        "import pandas as pd\n",
        "\n",
        "# Define a function to remove outliers based on IQR\n",
        "def remove_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)\n",
        "    Q3 = data.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return data[(data >= lower_bound) & (data <= upper_bound)]\n",
        "\n",
        "# Define a function to calculate mean, SD, and p-value for paired t-test\n",
        "def calculate_statistics(pre, post):\n",
        "    pre_no_outliers = remove_outliers_iqr(pre)\n",
        "    post_no_outliers = remove_outliers_iqr(post)\n",
        "\n",
        "    matched_data = pd.DataFrame({'pre': pre_no_outliers, 'post': post}).dropna()\n",
        "\n",
        "    mean_pre = pre_no_outliers.mean()\n",
        "    std_pre = pre_no_outliers.std()\n",
        "    mean_post = matched_data['post'].mean()\n",
        "    std_post = matched_data['post'].std()\n",
        "\n",
        "    t_test = ttest_rel(matched_data['pre'], matched_data['post'], nan_policy='omit')\n",
        "\n",
        "    return {\n",
        "        'pre_mean_sd': f\"{mean_pre:.3f} ± {std_pre:.3f}\",\n",
        "        'post_mean_sd': f\"{mean_post:.3f} ± {std_post:.3f}\",\n",
        "        'p_value': f\"{t_test.pvalue:.3e}\"\n",
        "    }\n",
        "\n",
        "# Applying the function to evaluate pre and post-surgery changes in asg_0 and asg_45\n",
        "asg_0_stats = calculate_statistics(data['asg_0_pre'], data['asg_0_3M'])\n",
        "asg_45_stats = calculate_statistics(data['asg_45_pre'], data['asg_45_3M'])\n",
        "\n",
        "print(f\"change in asg_0: {asg_0_stats}\")\n",
        "print(f\"change in asg_45: {asg_45_stats}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLVcSTL6y71Y",
        "outputId": "cedb584c-f53f-4ac5-925c-9f7b024703b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change in asg_0: {'pre_mean_sd': '-0.088 ± 0.981', 'post_mean_sd': '0.160 ± 1.100', 'p_value': '2.195e-07'}\n",
            "change in asg_45: {'pre_mean_sd': '-0.016 ± 0.547', 'post_mean_sd': '-0.076 ± 0.671', 'p_value': '2.058e-01'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Linear regression analysis**\n",
        "\n",
        "線形回帰モデルのAIC（赤池情報量基準）を用いた多変量解析も併用\n",
        "\n"
      ],
      "metadata": {
        "id": "tpw9-FE4e8JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂_proprocessed.xlsx\"\n",
        "\n",
        "# data = pd.read_excel(xlsx_path, header=0)"
      ],
      "metadata": {
        "id": "AJQS1L8Y1iv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['ID', 'Δasg_0', 'Δasg_45', 'age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function', 'ΔMRD-1']\n",
        "regression_data = data[columns].dropna()\n",
        "\n",
        "# 各項目の統計量を表示\n",
        "statistics = regression_data.describe(include='all')\n",
        "\n",
        "# age, sex, sideの内訳を表示\n",
        "sex_counts = regression_data['sex'].value_counts()\n",
        "side_counts = regression_data['side'].value_counts()\n",
        "\n",
        "# idが同じものは1例に数える\n",
        "unique_sex_counts = regression_data.drop_duplicates(subset='ID')['sex'].value_counts()\n",
        "\n",
        "print(statistics)\n",
        "print(\"Sex counts:\\n\", sex_counts)\n",
        "print(\"Side counts:\\n\", side_counts)\n",
        "print(\"Unique Sex counts:\\n\", unique_sex_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSmcXd1ha2tv",
        "outputId": "97391fa5-c9a2-433e-d487-852e691903fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 ID   Δasg_0  Δasg_45      age      sex     side  asg_0_pre  \\\n",
            "count      165.0000 165.0000 165.0000 165.0000 165.0000 165.0000   165.0000   \n",
            "mean   9836909.8182   0.2478  -0.0537  75.4667   0.3758   0.4909    -0.0846   \n",
            "std    2562205.8830   0.6006   0.6045   8.5108   0.4858   0.5014     0.9873   \n",
            "min    1655521.0000  -1.2409  -3.7378  46.0000   0.0000   0.0000    -2.5256   \n",
            "25%    8037167.0000  -0.1286  -0.3331  70.0000   0.0000   0.0000    -0.7431   \n",
            "50%   10948582.0000   0.2203  -0.0240  76.0000   0.0000   0.0000    -0.0832   \n",
            "75%   11751109.0000   0.6020   0.2709  81.0000   1.0000   1.0000     0.5393   \n",
            "max   12422011.0000   2.0000   1.7585  92.0000   1.0000   1.0000     2.3776   \n",
            "\n",
            "       asg_45_pre  MRD-1 pre  MRD-1 3M  levator_function   ΔMRD-1  \n",
            "count    165.0000   165.0000  165.0000          165.0000 165.0000  \n",
            "mean      -0.0243     0.4636    3.4667            9.3667   3.0030  \n",
            "std        0.5375     1.1655    1.0048            2.2914   1.4169  \n",
            "min       -1.2318    -3.0000    1.0000            4.0000   0.0000  \n",
            "25%       -0.3694     0.0000    3.0000            8.0000   2.0000  \n",
            "50%        0.0000     0.5000    3.5000            9.0000   3.0000  \n",
            "75%        0.2884     1.0000    4.0000           11.0000   4.0000  \n",
            "max        1.3856     3.0000    7.0000           16.0000   8.0000  \n",
            "Sex counts:\n",
            " sex\n",
            "0    103\n",
            "1     62\n",
            "Name: count, dtype: int64\n",
            "Side counts:\n",
            " side\n",
            "0    84\n",
            "1    81\n",
            "Name: count, dtype: int64\n",
            "Unique Sex counts:\n",
            " sex\n",
            "0    62\n",
            "1    38\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['Δasg_0', 'Δasg_45', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']\n",
        "regression_data = data[columns].dropna()\n",
        "\n",
        "# 各項目の統計量を表示\n",
        "statistics = regression_data.describe(include='all')\n",
        "print(statistics)\n",
        "\n",
        "# Δasg_0とΔasg_45の箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['Δasg_0', 'Δasg_45']].boxplot()\n",
        "plt.title('Boxplot of Δasg_0 and Δasg_45')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_0_preとasg_45_preの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_0_pre', 'asg_45_pre']].boxplot()\n",
        "plt.title('Boxplot of asg_0_pre and asg_45_pre')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# MRD-1 preとMRD-1 3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['MRD-1 pre', 'MRD-1 3M']].boxplot()\n",
        "plt.title('Boxplot of MRD-1 pre and MRD-1 3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# levator_functionの箱ひげ図を作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data.boxplot(column=['levator_function'])\n",
        "plt.title('Boxplot of levator_function')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jBZ3zioDinsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['Δasg_0','Δasg_45', 'age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']\n",
        "regression_data = data[columns].dropna()\n",
        "\n",
        "# 説明変数と目的変数の設定\n",
        "def set_variables(target):\n",
        "    X = regression_data[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']]\n",
        "    y = regression_data[target]\n",
        "    return X, y\n",
        "\n",
        "# 太字表示のための関数\n",
        "def print_bold(text):\n",
        "    print(f\"\\033[1m{text}\\033[0m\")\n",
        "\n",
        "# 線形回帰モデルを作成・評価\n",
        "def linear_regression_analysis(X, y, target, test_size=0.2, random_state=0):\n",
        "    print_bold(f\"\\n--- Linear Regression Analysis for {target} ---\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"MSE: {mse}, R2: {r2}\")\n",
        "\n",
        "    X_train_sm = sm.add_constant(X_train)\n",
        "    model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
        "    print(model_sm.summary())\n",
        "\n",
        "    return model, X_train, X_test, y_train, y_test\n",
        "\n",
        "# ステップワイズ回帰関数\n",
        "def stepwise_selection(X, y, initial_list=[], threshold_in=0.05, threshold_out=0.10, verbose=True):\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed = False\n",
        "        excluded = list(set(X.columns) - set(included))\n",
        "        new_pval = pd.Series(index=excluded)\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        best_pval = new_pval.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_feature = new_pval.idxmin()\n",
        "            included.append(best_feature)\n",
        "            changed = True\n",
        "            if verbose:\n",
        "                print(f'Add  {best_feature} with p-value {best_pval}')\n",
        "\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        pvalues = model.pvalues.iloc[1:]\n",
        "        worst_pval = pvalues.max()\n",
        "        if worst_pval > threshold_out:\n",
        "            changed = True\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            included.remove(worst_feature)\n",
        "            if verbose:\n",
        "                print(f'Drop {worst_feature} with p-value {worst_pval}')\n",
        "        if not changed:\n",
        "            break\n",
        "\n",
        "    return included\n",
        "\n",
        "# ステップワイズ回帰を実行し、選択された変数で線形回帰を行う\n",
        "def stepwise_regression_analysis(X, y, target, test_size=0.2, random_state=0, threshold_in=0.01, threshold_out=0.05):\n",
        "    print_bold(f\"\\n--- Stepwise Regression Analysis for {target} ---\")\n",
        "    X_with_constant = sm.add_constant(X)\n",
        "    selected_features = stepwise_selection(X_with_constant, y, threshold_in=threshold_in, threshold_out=threshold_out)\n",
        "\n",
        "    if 'const' in selected_features:\n",
        "        selected_features.remove('const')\n",
        "\n",
        "    if not selected_features:\n",
        "        print(f\"No features were selected for {target}.\")\n",
        "        return\n",
        "\n",
        "    print(f'Selected features: {selected_features}')\n",
        "\n",
        "    X_selected = X[selected_features]\n",
        "    X_train_selected, X_test_selected, y_train, y_test = train_test_split(X_selected, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    model_selected = LinearRegression()\n",
        "    model_selected.fit(X_train_selected, y_train)\n",
        "\n",
        "    y_pred_selected = model_selected.predict(X_test_selected)\n",
        "\n",
        "    mse_selected = mean_squared_error(y_test, y_pred_selected)\n",
        "    r2_selected = r2_score(y_test, y_pred_selected)\n",
        "\n",
        "    print(f\"Selected model MSE: {mse_selected}, R2: {r2_selected}\")\n",
        "\n",
        "    X_train_selected_sm = sm.add_constant(X_train_selected)\n",
        "    model_selected_sm = sm.OLS(y_train, X_train_selected_sm).fit()\n",
        "    print(model_selected_sm.summary())\n",
        "\n",
        "# 線形回帰とステップワイズ回帰を実行するメイン関数\n",
        "def main_analysis(target):\n",
        "    X, y = set_variables(target)\n",
        "    linear_regression_analysis(X, y, target)\n",
        "    stepwise_regression_analysis(X, y, target)\n",
        "\n",
        "# Δasg_0とΔasg_45についての解析\n",
        "main_analysis('Δasg_0')\n",
        "main_analysis('Δasg_45')\n"
      ],
      "metadata": {
        "id": "Dhz6tBzJhm_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpXLRB9ehnD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['Δasg_0','Δasg_45', 'age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']\n",
        "regression_data = data[columns].dropna()\n",
        "\n",
        "# 外れ値を除外する関数\n",
        "def remove_outliers(df, outlier_columns):\n",
        "    filtered_df = df.copy()\n",
        "    for column in outlier_columns:\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        filtered_df = filtered_df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "    return filtered_df\n",
        "\n",
        "# 説明変数と目的変数の設定\n",
        "def set_variables(target, outliers_excluded=False, outlier_columns=[]):\n",
        "    if outliers_excluded:\n",
        "        filtered_data = remove_outliers(regression_data, outlier_columns)\n",
        "        X = filtered_data[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']]\n",
        "        y = filtered_data[target]\n",
        "    else:\n",
        "        X = regression_data[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']]\n",
        "        y = regression_data[target]\n",
        "    return X, y\n",
        "\n",
        "# 太字表示のための関数\n",
        "def print_bold(text):\n",
        "    print(f\"\\033[1m{text}\\033[0m\")\n",
        "\n",
        "# データを訓練セットとテストセットに分割し、SVRモデルを作成・評価\n",
        "def svr_regression_analysis(X, y, target, kernel='rbf', test_size=0.2, random_state=0):\n",
        "    print_bold(f\"\\n--- SVR Regression Analysis for {target} ---\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    model = SVR(kernel=kernel)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"MSE: {mse}, R2: {r2}\")\n",
        "\n",
        "    return model, X_train, X_test, y_train, y_test\n",
        "\n",
        "# Δasg_0についての解析\n",
        "X, y = set_variables('Δasg_0', outliers_excluded=False)\n",
        "svr_regression_analysis(X, y, 'Δasg_0')\n",
        "\n",
        "X, y = set_variables('Δasg_0', outliers_excluded=True, outlier_columns=['asg_0_pre', 'asg_45_pre'])\n",
        "svr_regression_analysis(X, y, 'Δasg_0 (Outliers Excluded)')\n",
        "\n",
        "# Δasg_45についての解析\n",
        "X, y = set_variables('Δasg_45', outliers_excluded=False)\n",
        "svr_regression_analysis(X, y, 'Δasg_45')\n",
        "\n",
        "X, y = set_variables('Δasg_45', outliers_excluded=True, outlier_columns=['asg_0_pre', 'asg_45_pre'])\n",
        "svr_regression_analysis(X, y, 'Δasg_45 (Outliers Excluded)')\n"
      ],
      "metadata": {
        "id": "bZYqs7KghnGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ytjJ1S4-Zz0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kG2v9FPIZz2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Random forest analysis**"
      ],
      "metadata": {
        "id": "gqdt-ZxZgOp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Selecting the relevant columns\n",
        "analysis_data = data[['Δasg_0', 'asg_0_pre', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "# Define features and target\n",
        "X = analysis_data[['asg_0_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "y = analysis_data['Δasg_0']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForestRegressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "mse, r2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC4xXQa6gWDc",
        "outputId": "ddd72da3-db01-456d-ad21-c756b66e2265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4928290860567575, -0.25533069874429226)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 解析データの準備\n",
        "analysis_data = data[['Δasg_0', 'asg_0_pre', 'Δasg_45', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "# Δasg_0 の解析\n",
        "# 特徴量と目的変数の定義\n",
        "X_0 = analysis_data[['asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "y_0 = analysis_data['Δasg_0']\n",
        "\n",
        "# データを訓練セットとテストセットに分割\n",
        "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_0, y_0, test_size=0.3, random_state=42)\n",
        "\n",
        "# ランダムフォレスト回帰モデルの初期化と訓練\n",
        "rf_model_0 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model_0.fit(X_train_0, y_train_0)\n",
        "\n",
        "# テストセットでの予測\n",
        "predictions_0 = rf_model_0.predict(X_test_0)\n",
        "\n",
        "# モデルの評価\n",
        "mse_0 = mean_squared_error(y_test_0, predictions_0)\n",
        "r2_0 = r2_score(y_test_0, predictions_0)\n",
        "\n",
        "# Δasg_45 の解析\n",
        "# 特徴量と目的変数の定義\n",
        "X_45 = analysis_data[['asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "y_45 = analysis_data['Δasg_45']\n",
        "\n",
        "# データを訓練セットとテストセットに分割\n",
        "X_train_45, X_test_45, y_train_45, y_test_45 = train_test_split(X_45, y_45, test_size=0.3, random_state=42)\n",
        "\n",
        "# ランダムフォレスト回帰モデルの初期化と訓練\n",
        "rf_model_45 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model_45.fit(X_train_45, y_train_45)\n",
        "\n",
        "# テストセットでの予測\n",
        "predictions_45 = rf_model_45.predict(X_test_45)\n",
        "\n",
        "# モデルの評価\n",
        "mse_45 = mean_squared_error(y_test_45, predictions_45)\n",
        "r2_45 = r2_score(y_test_45, predictions_45)\n",
        "\n",
        "mse_0, r2_0, mse_45, r2_45\n"
      ],
      "metadata": {
        "id": "JaXJz0vN9cB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 解析データの準備\n",
        "analysis_data = data[['Δasg_0', 'asg_0_pre', 'Δasg_45', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "def train_and_evaluate_model(X, y):\n",
        "    # データを訓練セットとテストセットに分割\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # ランダムフォレスト回帰モデルの初期化と訓練\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    # テストセットでの予測\n",
        "    predictions = rf_model.predict(X_test)\n",
        "\n",
        "    # モデルの評価\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    # 特徴量の重要度を取得\n",
        "    feature_importances = rf_model.feature_importances_\n",
        "\n",
        "    return mse, r2, feature_importances\n",
        "\n",
        "# Δasg_0 の解析\n",
        "X_0 = analysis_data[['asg_0_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "y_0 = analysis_data['Δasg_0']\n",
        "mse_0, r2_0, feature_importances_0 = train_and_evaluate_model(X_0, y_0)\n",
        "\n",
        "# Δasg_0 の特徴量重要度をデータフレームに変換\n",
        "feature_importance_df_0 = pd.DataFrame({\n",
        "    'Feature': X_0.columns,\n",
        "    'Importance': feature_importances_0\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Δasg_45 の解析\n",
        "X_45 = analysis_data[['asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "y_45 = analysis_data['Δasg_45']\n",
        "mse_45, r2_45, feature_importances_45 = train_and_evaluate_model(X_45, y_45)\n",
        "\n",
        "# Δasg_45 の特徴量重要度をデータフレームに変換\n",
        "feature_importance_df_45 = pd.DataFrame({\n",
        "    'Feature': X_45.columns,\n",
        "    'Importance': feature_importances_45\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 結果の表示\n",
        "print(\"Δasg_0 Model Evaluation\")\n",
        "print(f\"MSE: {mse_0}\")\n",
        "print(f\"R²: {r2_0}\")\n",
        "print(feature_importance_df_0)\n",
        "\n",
        "print(\"\\nΔasg_45 Model Evaluation\")\n",
        "print(f\"MSE: {mse_45}\")\n",
        "print(f\"R²: {r2_45}\")\n",
        "print(feature_importance_df_45)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py-8urgEwTHE",
        "outputId": "17fa1899-5cd4-44ad-ae47-3f11e2b5174b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Δasg_0 Model Evaluation\n",
            "MSE: 0.4928290860567575\n",
            "R²: -0.25533069874429226\n",
            "     Feature  Importance\n",
            "0  asg_0_pre    0.618630\n",
            "1  MRD-1 pre    0.217431\n",
            "2   MRD-1 3M    0.163939\n",
            "\n",
            "Δasg_45 Model Evaluation\n",
            "MSE: 0.40930488761670164\n",
            "R²: -0.30633992043812697\n",
            "      Feature  Importance\n",
            "0  asg_45_pre    0.680591\n",
            "1   MRD-1 pre    0.175465\n",
            "2    MRD-1 3M    0.143944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# 解析データの準備\n",
        "analysis_data = data[['Δasg_0', 'asg_0_pre', 'Δasg_45', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "def train_and_evaluate_model(X, y):\n",
        "    # データを訓練セットとテストセットに分割\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # ランダムフォレスト回帰モデルの初期化と訓練\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    # テストセットでの予測\n",
        "    predictions = rf_model.predict(X_test)\n",
        "\n",
        "    # モデルの評価\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "\n",
        "    # 特徴量の重要度を取得\n",
        "    feature_importances = rf_model.feature_importances_\n",
        "\n",
        "    return rf_model, mse, r2, feature_importances\n",
        "\n",
        "def analyze_variable(target_var, feature_vars):\n",
        "    X = analysis_data[feature_vars]\n",
        "    y = analysis_data[target_var]\n",
        "    rf_model, mse, r2, feature_importances = train_and_evaluate_model(X, y)\n",
        "\n",
        "    feature_importance_df = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': feature_importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # モデルから一つのツリーを抽出して可視化\n",
        "    tree_example = rf_model.estimators_[0]\n",
        "    dot_data = export_graphviz(tree_example, out_file=None,\n",
        "                               feature_names=X.columns,\n",
        "                               filled=True, rounded=True,\n",
        "                               special_characters=True)\n",
        "    graph = graphviz.Source(dot_data)\n",
        "    graph.render(f\"{target_var}_tree\")  # 画像として保存\n",
        "\n",
        "    return mse, r2, feature_importance_df, graph\n",
        "\n",
        "# Δasg_0 の解析\n",
        "mse_0, r2_0, feature_importance_df_0, graph_0 = analyze_variable('Δasg_0', ['MRD-1 3M'])\n",
        "\n",
        "# Δasg_45 の解析\n",
        "mse_45, r2_45, feature_importance_df_45, graph_45 = analyze_variable('Δasg_45', ['MRD-1 3M'])\n",
        "\n",
        "# 結果の表示\n",
        "print(\"Δasg_0 Model Evaluation\")\n",
        "print(f\"MSE: {mse_0}\")\n",
        "print(f\"R²: {r2_0}\")\n",
        "print(feature_importance_df_0)\n",
        "\n",
        "print(\"\\nΔasg_45 Model Evaluation\")\n",
        "print(f\"MSE: {mse_45}\")\n",
        "print(f\"R²: {r2_45}\")\n",
        "print(feature_importance_df_45)\n",
        "\n",
        "# 表示\n",
        "graph_0\n",
        "# graph_45\n"
      ],
      "metadata": {
        "id": "MaRhgHorhugH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the graph to a file\n",
        "graph_path = '/content/graph.dot'\n",
        "graph_0.render(graph_path)\n",
        "\n",
        "# Provide the path to the saved graph file\n",
        "graph_path + '.pdf'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CDS9c11jkJ3X",
        "outputId": "d7fd3ba9-95f6-4804-e1bb-33f0066334a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/graph.dot.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Decision tree analysis**"
      ],
      "metadata": {
        "id": "Dp12aNSRFw4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# データの準備\n",
        "analysis_data = data[['Δasg_0', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "# 特徴量と目的変数の定義\n",
        "X = analysis_data[['MRD-1 3M']]\n",
        "y = analysis_data['Δasg_0']\n",
        "\n",
        "# データを訓練セットとテストセットに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 決定木回帰モデルの初期化と訓練\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# テストセットでの予測\n",
        "predictions = dt_model.predict(X_test)\n",
        "\n",
        "# モデルの評価\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"R²: {r2}\")\n",
        "\n",
        "# 決定木の可視化\n",
        "dot_data = export_graphviz(dt_model, out_file=None,\n",
        "                           feature_names=X.columns,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree_Δasg_0\")  # 画像として保存\n",
        "\n",
        "# グラフを表示\n",
        "graph\n"
      ],
      "metadata": {
        "id": "Gt7dUKb5hRAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import graphviz\n",
        "\n",
        "# データの準備\n",
        "analysis_data = data[['Δasg_0', 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "# 特徴量と目的変数の定義\n",
        "X = analysis_data[['MRD-1 pre']]\n",
        "y = (analysis_data['Δasg_0'] > analysis_data['Δasg_0'].mean()).astype(int)\n",
        "\n",
        "# データを訓練セットとテストセットに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 決定木分類モデルの初期化と訓練\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# テストセットでの予測\n",
        "predictions = dt_model.predict(X_test)\n",
        "\n",
        "# モデルの評価\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# 決定木の可視化\n",
        "dot_data = export_graphviz(dt_model, out_file=None,\n",
        "                           feature_names=X.columns,\n",
        "                           class_names=['Below Average', 'Above Average'],\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree_Δasg_0_classification\")  # 画像として保存\n",
        "\n",
        "# グラフを表示\n",
        "graph\n"
      ],
      "metadata": {
        "id": "Hb4Z526QYWoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(data[\"MRD-1 3M\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ly8eqZfF1_C",
        "outputId": "36468272-5f9c-4593-dbe4-eb5a24bdd93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.0"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MRD-1 preとMRD-1 3Mのプロット（Δasg-0で色分けあり）\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(data['MRD-1 3M'], data['MRD-1 pre'], c=data['Δasg_0'], cmap='viridis')\n",
        "plt.colorbar(scatter, label='Δasg_0')\n",
        "\n",
        "plt.title('Scatter Plot of MRD-1 pre vs MRD-1 3M with Δasg_0 Color Coding')\n",
        "plt.xlabel('MRD-1 3M')\n",
        "plt.ylabel('MRD-1 pre')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GegUf6ipx6NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0UiBlgzRFJmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JoV-iGS4voZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qNCvp01zvoav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yKqnpF1jvoc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**一括して解析**"
      ],
      "metadata": {
        "id": "mbmP8y-kvopJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "pd.set_option('display.max_columns', 300)\n",
        "pd.set_option('display.max_rows', 300)\n",
        "\n",
        "xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂_proprocessed.xlsx\"\n",
        "data = pd.read_excel(xlsx_path, header=0)\n",
        "\n",
        "def print_stats(data, step_name):\n",
        "    unique_id_count = data['ID'].nunique()\n",
        "    total_rows = len(data)\n",
        "    print(f\"\\n{step_name}\")\n",
        "    print(f\"Number of unique IDs: {unique_id_count}\")\n",
        "    print(f\"Total number of rows: {total_rows}\")\n",
        "\n",
        "print_stats(data, \"Initial data\")\n",
        "\n",
        "##################\n",
        "# 眼瞼手術歴を除外\n",
        "##################\n",
        "excluded_data = data[data['eyelid_surg'] == 1]\n",
        "excluded_count = excluded_data['ID'].nunique()\n",
        "data = data[data['eyelid_surg'] != 1]\n",
        "print_stats(data, \"眼瞼手術歴を除外\")\n",
        "print(f\"Number of unique IDs excluded: {excluded_count}\")\n",
        "\n",
        "########################\n",
        "# 角膜混濁/HCL症例を除外\n",
        "########################\n",
        "excluded_data = data[data['corneal_matter'] == 1]\n",
        "excluded_count = excluded_data['ID'].nunique()\n",
        "data = data[data['corneal_matter'] != 1]\n",
        "print_stats(data, \"角膜混濁を除外\")\n",
        "print(f\"Number of unique IDs excluded: {excluded_count}\")\n",
        "\n",
        "#################\n",
        "# 外れ値を除外\n",
        "#################\n",
        "def remove_outliers(data, columns):\n",
        "    excluded_ids = set()\n",
        "    for column in columns:\n",
        "        q1 = data[column].quantile(0.25)\n",
        "        q3 = data[column].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "        excluded_ids.update(outliers['ID'])\n",
        "        data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
        "    return data, len(excluded_ids)\n",
        "\n",
        "# 外れ値を除外する列のリスト\n",
        "#columns_to_remove_outliers = [\"asg_0_pre\", \"asg_45_pre\", \"MRD-1 3M\"]\n",
        "columns_to_remove_outliers = [\"asg_0_pre\", \"asg_45_pre\"]\n",
        "\n",
        "\n",
        "# 外れ値を除外\n",
        "data, excluded_count = remove_outliers(data, columns_to_remove_outliers)\n",
        "print_stats(data, \"外れ値を除外\")\n",
        "print(f\"Number of unique IDs excluded: {excluded_count}\")\n",
        "\n",
        "print(\"\\nFinal dataset:\")\n",
        "print_stats(data, \"After all exclusions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeV2wSpRvtO4",
        "outputId": "228d36cd-42e5-47b7-c594-0adcfafbaa02"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Initial data\n",
            "Number of unique IDs: 112\n",
            "Total number of rows: 189\n",
            "\n",
            "眼瞼手術歴を除外\n",
            "Number of unique IDs: 107\n",
            "Total number of rows: 179\n",
            "Number of unique IDs excluded: 6\n",
            "\n",
            "角膜混濁を除外\n",
            "Number of unique IDs: 104\n",
            "Total number of rows: 172\n",
            "Number of unique IDs excluded: 5\n",
            "\n",
            "外れ値を除外\n",
            "Number of unique IDs: 100\n",
            "Total number of rows: 165\n",
            "Number of unique IDs excluded: 7\n",
            "\n",
            "Final dataset:\n",
            "\n",
            "After all exclusions\n",
            "Number of unique IDs: 100\n",
            "Total number of rows: 165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# このスクリプトは処理済みのDataFrameをExcelファイルとして保存します。\n",
        "# 保存先は /content/ ディレクトリで、ファイル名には現在の日時が含まれます。\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# 現在の日時を取得\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# タイムスタンプを含むファイル名を作成\n",
        "file_name = f\"processed_data_{timestamp}.xlsx\"\n",
        "\n",
        "# 新しいExcelファイルの完全なパスを設定\n",
        "output_path = f\"/content/{file_name}\"\n",
        "\n",
        "# DataFrameをExcelファイルとして保存\n",
        "# index=Falseを指定して、インデックスを除外\n",
        "data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"DataFrameを次の場所に保存しました: {output_path}\")"
      ],
      "metadata": {
        "id": "i-rZQztsI-Bv",
        "outputId": "7fc1d221-a126-4ba3-ec72-8686ef0a8642",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrameを次の場所に保存しました: /content/processed_data_20240806_085155.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant columns\n",
        "columns_of_interest = ['ID', 'MRD-1 pre', 'MRD-1 3M', 'asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'Δasg_0', 'Δasg_45', 'age', 'sex', 'side', 'levator_function', 'ΔMRD-1']\n",
        "data_relevant = data[columns_of_interest]\n",
        "\n",
        "# 各項目の統計量を表示\n",
        "statistics = data_relevant.describe(include='all')\n",
        "\n",
        "# age, sex, sideの内訳を表示\n",
        "sex_counts = data_relevant['sex'].value_counts()\n",
        "side_counts = data_relevant['side'].value_counts()\n",
        "\n",
        "# idが同じものは1例に数える\n",
        "unique_sex_counts = data_relevant.drop_duplicates(subset='ID')['sex'].value_counts()\n",
        "\n",
        "print(statistics)\n",
        "print(\"Sex counts:\\n\", sex_counts)\n",
        "print(\"Side counts:\\n\", side_counts)\n",
        "print(\"Unique Sex counts:\\n\", unique_sex_counts)\n"
      ],
      "metadata": {
        "id": "h5Lg_VxCwCvB",
        "outputId": "9a615c69-a48f-4df8-b13b-78a993b930b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 ID   MRD-1 pre    MRD-1 3M   asg_0_pre  asg_45_pre  \\\n",
            "count  1.650000e+02  165.000000  165.000000  165.000000  165.000000   \n",
            "mean   9.836910e+06    0.463636    3.466667   -0.084612   -0.024323   \n",
            "std    2.562206e+06    1.165515    1.004765    0.987324    0.537544   \n",
            "min    1.655521e+06   -3.000000    1.000000   -2.525611   -1.231823   \n",
            "25%    8.037167e+06    0.000000    3.000000   -0.743145   -0.369397   \n",
            "50%    1.094858e+07    0.500000    3.500000   -0.083165    0.000000   \n",
            "75%    1.175111e+07    1.000000    4.000000    0.539276    0.288379   \n",
            "max    1.242201e+07    3.000000    7.000000    2.377641    1.385641   \n",
            "\n",
            "         asg_0_3M   asg_45_3M      Δasg_0     Δasg_45         age         sex  \\\n",
            "count  165.000000  165.000000  165.000000  165.000000  165.000000  165.000000   \n",
            "mean     0.163171   -0.078024    0.247783   -0.053701   75.466667    0.375758   \n",
            "std      1.109829    0.672239    0.600591    0.604528    8.510777    0.485792   \n",
            "min     -2.586874   -3.654182   -1.240938   -3.737805   46.000000    0.000000   \n",
            "25%     -0.602218   -0.414519   -0.128558   -0.333111   70.000000    0.000000   \n",
            "50%      0.110255   -0.090739    0.220275   -0.023984   76.000000    0.000000   \n",
            "75%      0.822191    0.334565    0.601973    0.270858   81.000000    1.000000   \n",
            "max      2.713754    1.695742    2.000000    1.758522   92.000000    1.000000   \n",
            "\n",
            "             side  levator_function      ΔMRD-1  \n",
            "count  165.000000        165.000000  165.000000  \n",
            "mean     0.490909          9.366667    3.003030  \n",
            "std      0.501439          2.291377    1.416903  \n",
            "min      0.000000          4.000000    0.000000  \n",
            "25%      0.000000          8.000000    2.000000  \n",
            "50%      0.000000          9.000000    3.000000  \n",
            "75%      1.000000         11.000000    4.000000  \n",
            "max      1.000000         16.000000    8.000000  \n",
            "Sex counts:\n",
            " sex\n",
            "0    103\n",
            "1     62\n",
            "Name: count, dtype: int64\n",
            "Side counts:\n",
            " side\n",
            "0    84\n",
            "1    81\n",
            "Name: count, dtype: int64\n",
            "Unique Sex counts:\n",
            " sex\n",
            "0    62\n",
            "1    38\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "性別との交絡因子の解析\n",
        "'''\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_gender_differences(data):\n",
        "    # データの基本情報を確認\n",
        "    print(\"データの基本情報:\")\n",
        "    print(data.info())\n",
        "\n",
        "    print(\"\\nデータの先頭数行:\")\n",
        "    print(data.head())\n",
        "\n",
        "    # 数値データの列を抽出（'ID'と'sex'と'side'を除外）\n",
        "    numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    numeric_columns = [col for col in numeric_columns if col not in ['ID', 'sex', 'side']]\n",
        "\n",
        "    # 性別ごとのグループを作成（元のデータを変更せずに）\n",
        "    male_group = data[data['sex'] == 1]\n",
        "    female_group = data[data['sex'] == 0]\n",
        "\n",
        "    # 各数値列に対して t検定を実施\n",
        "    t_test_results = {}\n",
        "    for column in numeric_columns:\n",
        "        male_data = male_group[column].dropna()\n",
        "        female_data = female_group[column].dropna()\n",
        "\n",
        "        if len(male_data) > 0 and len(female_data) > 0:\n",
        "            t_stat, p_value = stats.ttest_ind(male_data, female_data)\n",
        "            t_test_results[column] = {'t_statistic': t_stat, 'p_value': p_value}\n",
        "        else:\n",
        "            print(f\"警告: {column}列にデータが不足しています\")\n",
        "\n",
        "    # カテゴリカルデータ（side）に対してはカイ二乗検定を実施\n",
        "    side_crosstab = pd.crosstab(data['sex'], data['side'])\n",
        "    if side_crosstab.size > 0 and side_crosstab.min().min() > 0:\n",
        "        chi2, p_value, dof, expected = stats.chi2_contingency(side_crosstab)\n",
        "        chi2_result = {'chi2_statistic': chi2, 'p_value': p_value}\n",
        "    else:\n",
        "        print(\"警告: 'side'列にデータが不足しているか、期待度数が0のセルがあります\")\n",
        "        chi2_result = {'chi2_statistic': np.nan, 'p_value': np.nan}\n",
        "\n",
        "    # 結果の表示\n",
        "    print(\"\\nT検定の結果:\")\n",
        "    for column, result in t_test_results.items():\n",
        "        print(f\"{column}: t統計量 = {result['t_statistic']:.4f}, p値 = {result['p_value']:.4f}\")\n",
        "\n",
        "    print(\"\\nカイ二乗検定の結果 (side):\")\n",
        "    print(f\"カイ二乗統計量 = {chi2_result['chi2_statistic']:.4f}, p値 = {chi2_result['p_value']:.4f}\")\n",
        "\n",
        "    # 有意差のある項目をリストアップ\n",
        "    significant_items = [column for column, result in t_test_results.items() if result['p_value'] < 0.05]\n",
        "    if chi2_result['p_value'] < 0.05:\n",
        "        significant_items.append('side')\n",
        "\n",
        "    print(\"\\n有意差のある項目:\")\n",
        "    for item in significant_items:\n",
        "        print(item)\n",
        "\n",
        "    # 各変数の記述統計量を性別ごとに計算\n",
        "    descriptive_stats = data.groupby('sex')[numeric_columns].agg(['mean', 'std'])\n",
        "    descriptive_stats.index = ['Female', 'Male']  # 0をFemale、1をMaleに変更\n",
        "    print(\"\\n性別ごとの記述統計量:\")\n",
        "    print(descriptive_stats)\n",
        "\n",
        "    return t_test_results, chi2_result, significant_items, descriptive_stats\n",
        "\n",
        "# 分析の実行\n",
        "t_test_results, chi2_result, significant_items, descriptive_stats = analyze_gender_differences(data_relevant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAHeQe682018",
        "outputId": "2438007f-e7a1-4593-9dfb-fab5c6c9de8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データの基本情報:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 165 entries, 0 to 188\n",
            "Data columns (total 14 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   ID                165 non-null    int64  \n",
            " 1   MRD-1 pre         165 non-null    float64\n",
            " 2   MRD-1 3M          165 non-null    float64\n",
            " 3   asg_0_pre         165 non-null    float64\n",
            " 4   asg_45_pre        165 non-null    float64\n",
            " 5   asg_0_3M          165 non-null    float64\n",
            " 6   asg_45_3M         165 non-null    float64\n",
            " 7   Δasg_0            165 non-null    float64\n",
            " 8   Δasg_45           165 non-null    float64\n",
            " 9   age               165 non-null    int64  \n",
            " 10  sex               165 non-null    int64  \n",
            " 11  side              165 non-null    int64  \n",
            " 12  levator_function  165 non-null    float64\n",
            " 13  ΔMRD-1            165 non-null    float64\n",
            "dtypes: float64(10), int64(4)\n",
            "memory usage: 19.3 KB\n",
            "None\n",
            "\n",
            "データの先頭数行:\n",
            "        ID  MRD-1 pre  MRD-1 3M  asg_0_pre  asg_45_pre  asg_0_3M  asg_45_3M  \\\n",
            "0  1655521     0.5000    2.5000    -0.7431      0.6691   -0.3708     1.1413   \n",
            "1  1655521    -2.0000    1.5000    -2.3476      0.4990   -2.0681     0.3647   \n",
            "2  1932018    -0.5000    4.0000    -0.7071      0.8426    0.5942    -0.0835   \n",
            "3  2142221     2.0000    4.0000    -0.6928      0.4000   -0.9159    -0.1615   \n",
            "4  2142221     0.5000    4.0000    -0.8918     -0.8030   -0.5184    -0.1102   \n",
            "\n",
            "   Δasg_0  Δasg_45  age  sex  side  levator_function  ΔMRD-1  \n",
            "0  0.3723   0.4721   84    1     1            9.0000  2.0000  \n",
            "1  0.2795  -0.1343   84    1     0            8.0000  3.5000  \n",
            "2  1.3012  -0.9262   81    0     1            7.0000  4.5000  \n",
            "3 -0.2231  -0.5615   81    0     0           12.0000  2.0000  \n",
            "4  0.3734   0.6928   81    0     1           12.0000  3.5000  \n",
            "\n",
            "T検定の結果:\n",
            "MRD-1 pre: t統計量 = -0.5154, p値 = 0.6070\n",
            "MRD-1 3M: t統計量 = -2.6780, p値 = 0.0082\n",
            "asg_0_pre: t統計量 = -1.6323, p値 = 0.1046\n",
            "asg_45_pre: t統計量 = 2.7294, p値 = 0.0070\n",
            "asg_0_3M: t統計量 = -2.7385, p値 = 0.0069\n",
            "asg_45_3M: t統計量 = 2.3288, p値 = 0.0211\n",
            "Δasg_0: t統計量 = -2.3237, p値 = 0.0214\n",
            "Δasg_45: t統計量 = 0.1743, p値 = 0.8619\n",
            "age: t統計量 = 1.3264, p値 = 0.1866\n",
            "levator_function: t統計量 = -0.6817, p値 = 0.4964\n",
            "ΔMRD-1: t統計量 = -1.4441, p値 = 0.1506\n",
            "\n",
            "カイ二乗検定の結果 (side):\n",
            "カイ二乗統計量 = 0.0000, p値 = 1.0000\n",
            "\n",
            "有意差のある項目:\n",
            "MRD-1 3M\n",
            "asg_45_pre\n",
            "asg_0_3M\n",
            "asg_45_3M\n",
            "Δasg_0\n",
            "\n",
            "性別ごとの記述統計量:\n",
            "       MRD-1 pre        MRD-1 3M        asg_0_pre        asg_45_pre         \\\n",
            "            mean    std     mean    std      mean    std       mean    std   \n",
            "Female    0.5000 1.1268   3.6262 0.9944    0.0122 0.9061    -0.1112 0.5238   \n",
            "Male      0.4032 1.2342   3.2016 0.9728   -0.2455 1.0980     0.1201 0.5331   \n",
            "\n",
            "       asg_0_3M        asg_45_3M        Δasg_0        Δasg_45            age  \\\n",
            "           mean    std      mean    std   mean    std    mean    std    mean   \n",
            "Female   0.3432 1.0929   -0.1713 0.7069 0.3310 0.6601 -0.0601 0.7021 74.7864   \n",
            "Male    -0.1359 1.0810    0.0770 0.5833 0.1096 0.4583 -0.0431 0.3977 76.5968   \n",
            "\n",
            "              levator_function        ΔMRD-1         \n",
            "          std             mean    std   mean    std  \n",
            "Female 9.5544           9.4612 2.4422 3.1262 1.4189  \n",
            "Male   6.3257           9.2097 2.0256 2.7984 1.4010  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 必要な列を選択し、欠損値を削除\n",
        "columns = ['Δasg_0', 'Δasg_45', 'asg_0_pre', 'asg_45_pre', 'asg_0_3M', 'asg_45_3M', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1', 'levator_function']\n",
        "regression_data = data_relevant[columns].dropna()\n",
        "\n",
        "# 各項目の統計量を表示\n",
        "statistics = regression_data.describe(include='all')\n",
        "print(statistics)\n",
        "\n",
        "# Δasg_0とΔasg_45の箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['Δasg_0', 'Δasg_45']].boxplot()\n",
        "plt.title('Boxplot of Δasg_0 and Δasg_45')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_0_preとasg_45_preの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_0_pre', 'asg_45_pre']].boxplot()\n",
        "plt.title('Boxplot of asg_0_pre and asg_45_pre')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_0_preとasg_0_3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_0_pre', 'asg_0_3M']].boxplot()\n",
        "plt.title('Boxplot of asg_0_pre and asg_0_3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# asg_45_preとasg_45_3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['asg_45_pre', 'asg_45_3M']].boxplot()\n",
        "plt.title('Boxplot of asg_45_pre and asg_45_3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# MRD-1 preとMRD-1 3Mの箱ひげ図をまとめて作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data[['MRD-1 pre', 'MRD-1 3M']].boxplot()\n",
        "plt.title('Boxplot of MRD-1 pre and MRD-1 3M')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "\n",
        "# levator_functionの箱ひげ図を作成\n",
        "plt.figure(figsize=(8, 6))\n",
        "regression_data.boxplot(column=['levator_function'])\n",
        "plt.title('Boxplot of levator_function')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mf99GdYc4CbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from scipy.stats import ttest_rel\n",
        "import pandas as pd\n",
        "\n",
        "# Define a function to remove outliers based on IQR\n",
        "def remove_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)\n",
        "    Q3 = data.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return data[(data >= lower_bound) & (data <= upper_bound)]\n",
        "\n",
        "# Define a function to calculate mean, SD, and p-value for paired t-test\n",
        "def calculate_statistics(pre, post):\n",
        "    # pre_no_outliers = remove_outliers_iqr(pre)\n",
        "    # post_no_outliers = remove_outliers_iqr(post)\n",
        "    pre_no_outliers = pre\n",
        "    post_no_outliers = post\n",
        "\n",
        "\n",
        "    matched_data = pd.DataFrame({'pre': pre_no_outliers, 'post': post}).dropna()\n",
        "\n",
        "    mean_pre = pre_no_outliers.mean()\n",
        "    std_pre = pre_no_outliers.std()\n",
        "    mean_post = matched_data['post'].mean()\n",
        "    std_post = matched_data['post'].std()\n",
        "\n",
        "    t_test = ttest_rel(matched_data['pre'], matched_data['post'], nan_policy='omit')\n",
        "\n",
        "    return {\n",
        "        'pre_mean_sd': f\"{mean_pre:.3f} ± {std_pre:.3f}\",\n",
        "        'post_mean_sd': f\"{mean_post:.3f} ± {std_post:.3f}\",\n",
        "        'p_value': f\"{t_test.pvalue:.3e}\"\n",
        "    }\n",
        "\n",
        "# Applying the function to evaluate pre and post-surgery changes in asg_0 and asg_45\n",
        "asg_0_stats = calculate_statistics(data_relevant['asg_0_pre'], data_relevant['asg_0_3M'])\n",
        "asg_45_stats = calculate_statistics(data_relevant['asg_45_pre'], data_relevant['asg_45_3M'])\n",
        "\n",
        "print(f\"change in asg_0: {asg_0_stats}\")\n",
        "print(f\"change in asg_45: {asg_45_stats}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-QkjO233Pez",
        "outputId": "eacfaa43-d2cb-4b57-ceb1-e562af550dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change in asg_0: {'pre_mean_sd': '-0.085 ± 0.987', 'post_mean_sd': '0.163 ± 1.110', 'p_value': '3.699e-07'}\n",
            "change in asg_45: {'pre_mean_sd': '-0.024 ± 0.538', 'post_mean_sd': '-0.078 ± 0.672', 'p_value': '2.555e-01'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "asg_0_preとasg_45_preに関連する項目の検討\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Prepare the data for regression analysis for asg_0_pre and asg_45_pre\n",
        "X_asg_pre = data_relevant[['age', 'sex', 'side', 'MRD-1 pre', 'levator_function']]\n",
        "y_asg_0_pre = data_relevant['asg_0_pre']\n",
        "y_asg_45_pre = data_relevant['asg_45_pre']\n",
        "\n",
        "# Perform regression analysis for asg_0_pre\n",
        "model_asg_0_pre = sm.OLS(y_asg_0_pre, sm.add_constant(X_asg_pre)).fit()\n",
        "\n",
        "# Perform regression analysis for asg_45_pre\n",
        "model_asg_45_pre = sm.OLS(y_asg_45_pre, sm.add_constant(X_asg_pre)).fit()\n",
        "\n",
        "# Get the summary of the regression analysis\n",
        "summary_asg_0_pre = model_asg_0_pre.summary()\n",
        "summary_asg_45_pre = model_asg_45_pre.summary()\n",
        "\n",
        "summary_asg_0_pre, summary_asg_45_pre\n"
      ],
      "metadata": {
        "id": "AjuWua991cq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import statsmodels.api as sm\n",
        "\n",
        "# # Ordinary Least Squares (最小二乗法)を用いた解析\n",
        "\n",
        "# # Prepare the data for regression analysis for Δasg_0 and Δasg_45\n",
        "# X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "# X = sm.add_constant(X)  # Adding a constant term for the intercept\n",
        "\n",
        "# # Dependent variables\n",
        "# y_asg_0 = data_relevant['Δasg_0']\n",
        "# y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# # Perform regression analysis for Δasg_0\n",
        "# model_asg_0 = sm.OLS(y_asg_0, X).fit()\n",
        "\n",
        "# # Perform regression analysis for Δasg_45\n",
        "# model_asg_45 = sm.OLS(y_asg_45, X).fit()\n",
        "\n",
        "# # Get the summary of the regression analysis\n",
        "# summary_asg_0 = model_asg_0.summary()\n",
        "# summary_asg_45 = model_asg_45.summary()\n",
        "\n",
        "# summary_asg_0, summary_asg_45\n"
      ],
      "metadata": {
        "id": "DN7K_dBYwMp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "\n",
        "def print_bold(text):\n",
        "    print('\\033[1m' + text + '\\033[0m')\n",
        "\n",
        "def multivariate_regression_analysis(X, y, target):\n",
        "    print_bold(f\"\\n--- Multivariate Linear Regression Analysis for {target} ---\")\n",
        "    X_sm = sm.add_constant(X)\n",
        "    model = sm.OLS(y, X_sm).fit()\n",
        "    print(model.summary())\n",
        "\n",
        "    # Calculate and print MSE\n",
        "    y_pred = model.predict(X_sm)\n",
        "    mse = np.mean((y - y_pred)**2)\n",
        "    print_bold(f\"\\nMean Squared Error (MSE): {mse:.4f}\")\n",
        "\n",
        "def univariate_regression_analysis(X, y, target):\n",
        "    print_bold(f\"\\n--- Univariate Linear Regression Analysis for {target} ---\")\n",
        "    results = []\n",
        "    for column in X.columns:\n",
        "        X_uni = X[[column]]\n",
        "\n",
        "        # statsmodelsを使用して回帰分析を実行\n",
        "        X_sm = sm.add_constant(X_uni)\n",
        "        model_sm = sm.OLS(y, X_sm).fit()\n",
        "\n",
        "        # 結果を取得\n",
        "        coef = model_sm.params[column]  # 変数名を使用して係数を取得\n",
        "        std_err = model_sm.bse[column]\n",
        "        t_value = model_sm.tvalues[column]\n",
        "        p_value = model_sm.pvalues[column]\n",
        "        ci = model_sm.conf_int().loc[column]\n",
        "        r_squared = model_sm.rsquared\n",
        "\n",
        "        results.append({\n",
        "            'Variable': column,\n",
        "            'Coefficient': coef,\n",
        "            'Std Error': std_err,\n",
        "            't-value': t_value,\n",
        "            'P-value': p_value,\n",
        "            'CI Lower': ci[0],\n",
        "            'CI Upper': ci[1],\n",
        "            'R-squared': r_squared\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    pd.set_option('display.float_format', '{:.4f}'.format)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "# Prepare the data for regression analysis for Δasg_0 and Δasg_45\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "X = sm.add_constant(X)  # Adding a constant term for the intercept\n",
        "\n",
        "# Dependent variables\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# Perform multivariate regression analysis\n",
        "multivariate_regression_analysis(X, y_asg_0, 'Δasg_0')\n",
        "multivariate_regression_analysis(X, y_asg_45, 'Δasg_45')\n",
        "\n",
        "# Perform univariate regression analysis\n",
        "univariate_regression_analysis(X, y_asg_0, 'Δasg_0')\n",
        "univariate_regression_analysis(X, y_asg_45, 'Δasg_45')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl46UPL_MQAM",
        "outputId": "75322255-1081-4252-c49f-3dc4e920109f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "--- Multivariate Linear Regression Analysis for Δasg_0 ---\u001b[0m\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                 Δasg_0   R-squared:                       0.076\n",
            "Model:                            OLS   Adj. R-squared:                  0.035\n",
            "Method:                 Least Squares   F-statistic:                     1.849\n",
            "Date:                Tue, 06 Aug 2024   Prob (F-statistic):             0.0815\n",
            "Time:                        04:45:47   Log-Likelihood:                -142.96\n",
            "No. Observations:                 165   AIC:                             301.9\n",
            "Df Residuals:                     157   BIC:                             326.8\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.7641      0.467      1.635      0.104      -0.159       1.687\n",
            "age           -0.0024      0.006     -0.424      0.672      -0.014       0.009\n",
            "sex           -0.2977      0.101     -2.957      0.004      -0.497      -0.099\n",
            "side           0.0600      0.094      0.641      0.523      -0.125       0.245\n",
            "asg_0_pre     -0.0930      0.053     -1.764      0.080      -0.197       0.011\n",
            "asg_45_pre     0.1087      0.090      1.203      0.231      -0.070       0.287\n",
            "MRD-1 pre     -0.0272      0.041     -0.667      0.506      -0.108       0.053\n",
            "MRD-1 3M      -0.0698      0.051     -1.371      0.172      -0.170       0.031\n",
            "==============================================================================\n",
            "Omnibus:                        4.702   Durbin-Watson:                   1.751\n",
            "Prob(Omnibus):                  0.095   Jarque-Bera (JB):                4.472\n",
            "Skew:                           0.290   Prob(JB):                        0.107\n",
            "Kurtosis:                       3.561   Cond. No.                         775.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\u001b[1m\n",
            "Mean Squared Error (MSE): 0.3312\u001b[0m\n",
            "\u001b[1m\n",
            "--- Multivariate Linear Regression Analysis for Δasg_45 ---\u001b[0m\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                Δasg_45   R-squared:                       0.136\n",
            "Model:                            OLS   Adj. R-squared:                  0.097\n",
            "Method:                 Least Squares   F-statistic:                     3.527\n",
            "Date:                Tue, 06 Aug 2024   Prob (F-statistic):            0.00152\n",
            "Time:                        04:45:47   Log-Likelihood:                -138.53\n",
            "No. Observations:                 165   AIC:                             293.1\n",
            "Df Residuals:                     157   BIC:                             317.9\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.3175      0.455      0.698      0.486      -0.581       1.216\n",
            "age           -0.0037      0.006     -0.657      0.512      -0.015       0.007\n",
            "sex            0.0992      0.098      1.012      0.313      -0.094       0.293\n",
            "side          -0.1702      0.091     -1.867      0.064      -0.350       0.010\n",
            "asg_0_pre     -0.0264      0.051     -0.514      0.608      -0.128       0.075\n",
            "asg_45_pre    -0.4040      0.088     -4.593      0.000      -0.578      -0.230\n",
            "MRD-1 pre     -0.0495      0.040     -1.247      0.214      -0.128       0.029\n",
            "MRD-1 3M      -0.0104      0.050     -0.209      0.835      -0.108       0.088\n",
            "==============================================================================\n",
            "Omnibus:                       60.747   Durbin-Watson:                   1.976\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              423.265\n",
            "Skew:                          -1.125   Prob(JB):                     1.23e-92\n",
            "Kurtosis:                      10.517   Cond. No.                         775.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\u001b[1m\n",
            "Mean Squared Error (MSE): 0.3139\u001b[0m\n",
            "\u001b[1m\n",
            "--- Univariate Linear Regression Analysis for Δasg_0 ---\u001b[0m\n",
            "  Variable  Coefficient  Std Error  t-value  P-value  CI Lower  CI Upper  R-squared\n",
            "     const       0.2478     0.0468   5.2995   0.0000    0.1555    0.3401     0.0000\n",
            "       age      -0.0019     0.0055  -0.3383   0.7356   -0.0128    0.0090     0.0007\n",
            "       sex      -0.2214     0.0953  -2.3237   0.0214   -0.4095   -0.0333     0.0321\n",
            "      side       0.0394     0.0938   0.4202   0.6749   -0.1457    0.2245     0.0011\n",
            " asg_0_pre      -0.0532     0.0475  -1.1217   0.2636   -0.1470    0.0405     0.0077\n",
            "asg_45_pre       0.0740     0.0873   0.8474   0.3980   -0.0984    0.2464     0.0044\n",
            " MRD-1 pre      -0.0410     0.0402  -1.0190   0.3097   -0.1204    0.0384     0.0063\n",
            "  MRD-1 3M      -0.0331     0.0467  -0.7083   0.4798   -0.1254    0.0592     0.0031\n",
            "\u001b[1m\n",
            "--- Univariate Linear Regression Analysis for Δasg_45 ---\u001b[0m\n",
            "  Variable  Coefficient  Std Error  t-value  P-value  CI Lower  CI Upper  R-squared\n",
            "     const      -0.0537     0.0471  -1.1411   0.2555   -0.1466    0.0392     0.0000\n",
            "       age      -0.0002     0.0056  -0.0350   0.9721   -0.0112    0.0108     0.0000\n",
            "       sex       0.0170     0.0975   0.1743   0.8619   -0.1755    0.2094     0.0002\n",
            "      side      -0.0984     0.0941  -1.0461   0.2971   -0.2843    0.0874     0.0067\n",
            " asg_0_pre      -0.0226     0.0479  -0.4724   0.6372   -0.1173    0.0720     0.0014\n",
            "asg_45_pre      -0.3504     0.0837  -4.1864   0.0000   -0.5157   -0.1851     0.0971\n",
            " MRD-1 pre      -0.0543     0.0404  -1.3435   0.1810   -0.1341    0.0255     0.0110\n",
            "  MRD-1 3M       0.0134     0.0471   0.2853   0.7758   -0.0796    0.1065     0.0005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Δasg_0について、関連しそうな変数を使用した多変量線形回帰分析\n",
        "X_reduced = X[['sex', 'asg_0_pre', 'MRD-1 pre', 'MRD-1 3M']]\n",
        "multivariate_regression_analysis(X_reduced, y_asg_0, 'Δasg_0')"
      ],
      "metadata": {
        "id": "u9tbBrgVepNA",
        "outputId": "06ebd45b-8e2b-46ff-d8d3-93036f073cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "--- Multivariate Linear Regression Analysis for Δasg_0 ---\u001b[0m\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                 Δasg_0   R-squared:                       0.065\n",
            "Model:                            OLS   Adj. R-squared:                  0.042\n",
            "Method:                 Least Squares   F-statistic:                     2.776\n",
            "Date:                Tue, 06 Aug 2024   Prob (F-statistic):             0.0289\n",
            "Time:                        04:46:34   Log-Likelihood:                -143.96\n",
            "No. Observations:                 165   AIC:                             297.9\n",
            "Df Residuals:                     160   BIC:                             313.5\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.6373      0.188      3.387      0.001       0.266       1.009\n",
            "sex           -0.2811      0.098     -2.854      0.005      -0.476      -0.087\n",
            "asg_0_pre     -0.0894      0.050     -1.782      0.077      -0.189       0.010\n",
            "MRD-1 pre     -0.0248      0.041     -0.612      0.542      -0.105       0.055\n",
            "MRD-1 3M      -0.0808      0.050     -1.611      0.109      -0.180       0.018\n",
            "==============================================================================\n",
            "Omnibus:                        3.791   Durbin-Watson:                   1.751\n",
            "Prob(Omnibus):                  0.150   Jarque-Bera (JB):                3.606\n",
            "Skew:                           0.223   Prob(JB):                        0.165\n",
            "Kurtosis:                       3.571   Cond. No.                         16.6\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\u001b[1m\n",
            "Mean Squared Error (MSE): 0.3353\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Δasg_45について、関連しそうな変数を使用した多変量線形回帰分析\n",
        "X_reduced = X[['asg_45_pre']]\n",
        "multivariate_regression_analysis(X_reduced, y_asg_45, 'Δasg_45')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OgdeL0z0iQy",
        "outputId": "5092717c-673c-4f13-c520-909c3dd6f3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "--- Multivariate Linear Regression Analysis for Δasg_45 ---\u001b[0m\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                Δasg_45   R-squared:                       0.086\n",
            "Model:                            OLS   Adj. R-squared:                  0.081\n",
            "Method:                 Least Squares   F-statistic:                     14.84\n",
            "Date:                Tue, 06 Aug 2024   Prob (F-statistic):           0.000170\n",
            "Time:                        04:18:23   Log-Likelihood:                -138.59\n",
            "No. Observations:                 159   AIC:                             281.2\n",
            "Df Residuals:                     157   BIC:                             287.3\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.0657      0.046     -1.422      0.157      -0.157       0.026\n",
            "asg_45_pre    -0.3401      0.088     -3.852      0.000      -0.514      -0.166\n",
            "==============================================================================\n",
            "Omnibus:                       74.390   Durbin-Watson:                   1.981\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              651.577\n",
            "Skew:                          -1.428   Prob(JB):                    3.25e-142\n",
            "Kurtosis:                      12.497   Cond. No.                         1.91\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Stepwise linear regression analysis #####\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tools import add_constant\n",
        "\n",
        "def print_bold(text):\n",
        "    print(f\"\\033[1m{text}\\033[0m\")\n",
        "\n",
        "def stepwise_selection(X, y, initial_list=[], threshold_in=0.01, threshold_out=0.05, verbose=True):\n",
        "    \"\"\" Perform a forward-backward feature selection\n",
        "    based on p-value from statsmodels.api.OLS\n",
        "    Arguments:\n",
        "        X - pandas.DataFrame with candidate features\n",
        "        y - list-like with the target\n",
        "        initial_list - list of features to start with (keep fixed)\n",
        "        threshold_in - include a feature if its p-value < threshold_in\n",
        "        threshold_out - exclude a feature if its p-value > threshold_out\n",
        "        verbose - whether to print the sequence of inclusions and exclusions\n",
        "    Returns: list of selected features\n",
        "    \"\"\"\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed = False\n",
        "        # forward step\n",
        "        excluded = list(set(X.columns) - set(included))\n",
        "        new_pval = pd.Series(index=excluded, dtype=float)\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        best_pval = new_pval.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_feature = new_pval.idxmin()\n",
        "            included.append(best_feature)\n",
        "            changed = True\n",
        "            if verbose:\n",
        "                print(f'Add  {best_feature} with p-value {best_pval}')\n",
        "        # backward step\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        # use all coefs except intercept\n",
        "        pvalues = model.pvalues.iloc[1:]\n",
        "        worst_pval = pvalues.max()\n",
        "        if worst_pval > threshold_out:\n",
        "            changed = True\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            included.remove(worst_feature)\n",
        "            if verbose:\n",
        "                print(f'Drop {worst_feature} with p-value {worst_pval}')\n",
        "        if not changed:\n",
        "            break\n",
        "    return included\n",
        "\n",
        "def linear_regression_analysis(X, y, target, test_size=0.2, random_state=0):\n",
        "    print_bold(f\"\\n--- Linear Regression Analysis for {target} ---\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    selected_features = stepwise_selection(X_train, y_train)\n",
        "    if not selected_features:\n",
        "        print(\"No features were selected using stepwise selection.\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    print(f\"Selected features: {selected_features}\")\n",
        "\n",
        "    X_train_selected = X_train[selected_features]\n",
        "    X_test_selected = X_test[selected_features]\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_selected, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
        "\n",
        "    X_train_sm = sm.add_constant(X_train_selected)\n",
        "    model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
        "    print(model_sm.summary())\n",
        "\n",
        "    # Calculate AIC\n",
        "    aic = model_sm.aic\n",
        "    print(f\"AIC: {aic:.4f}\")\n",
        "\n",
        "    return model, X_train_selected, X_test_selected, y_train, y_test, aic\n",
        "\n",
        "# Perform regression analysis for Δasg_0\n",
        "model_asg_0, X_train_asg_0, X_test_asg_0, y_train_asg_0, y_test_asg_0, aic_asg_0 = linear_regression_analysis(X, y_asg_0, 'Δasg_0')\n",
        "\n",
        "# Perform regression analysis for Δasg_45\n",
        "model_asg_45, X_train_asg_45, X_test_asg_45, y_train_asg_45, y_test_asg_45, aic_asg_45 = linear_regression_analysis(X, y_asg_45, 'Δasg_45')\n"
      ],
      "metadata": {
        "id": "sZIPxQap_b4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the data\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1']]\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_asg_0_train, y_asg_0_test = train_test_split(X, y_asg_0, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_asg_45_train, y_asg_45_test = train_test_split(X, y_asg_45, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Function to perform GridSearchCV and return the best model\n",
        "def get_best_rf_model(X_train, y_train):\n",
        "    rf = RandomForestRegressor(random_state=43)\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Get the best model for Δasg_0\n",
        "print(\"Tuning for Δasg_0:\")\n",
        "best_rf_asg_0 = get_best_rf_model(X_train, y_asg_0_train)\n",
        "\n",
        "# Get the best model for Δasg_45\n",
        "print(\"\\nTuning for Δasg_45:\")\n",
        "best_rf_asg_45 = get_best_rf_model(X_train, y_asg_45_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_0\n",
        "y_asg_0_pred = best_rf_asg_0.predict(X_test)\n",
        "mse_asg_0 = mean_squared_error(y_asg_0_test, y_asg_0_pred)\n",
        "r2_asg_0 = r2_score(y_asg_0_test, y_asg_0_pred)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_45\n",
        "y_asg_45_pred = best_rf_asg_45.predict(X_test)\n",
        "mse_asg_45 = mean_squared_error(y_asg_45_test, y_asg_45_pred)\n",
        "r2_asg_45 = r2_score(y_asg_45_test, y_asg_45_pred)\n",
        "\n",
        "print(f\"\\nResults after tuning:\")\n",
        "print(f\"MSE_Δasg0: {mse_asg_0}, r2_Δasg0: {r2_asg_0}\")\n",
        "print(f\"MSE_Δasg45: {mse_asg_45}, r2_Δasg45: {r2_asg_45}\")\n",
        "\n",
        "# Get feature importances for Δasg_0 model\n",
        "importances_asg_0 = best_rf_asg_0.feature_importances_\n",
        "feature_importances_asg_0 = pd.Series(importances_asg_0, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Get feature importances for Δasg_45 model\n",
        "importances_asg_45 = best_rf_asg_45.feature_importances_\n",
        "feature_importances_asg_45 = pd.Series(importances_asg_45, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "# Display top 5 important features\n",
        "print(\"\\nTop 5 important features for Δasg_0:\")\n",
        "print(feature_importances_asg_0.head())\n",
        "\n",
        "print(\"\\nTop 5 important features for Δasg_45:\")\n",
        "print(feature_importances_asg_45.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc8tqdWn01Oz",
        "outputId": "9f3ac7ad-b7df-4681-9fcf-a4a19aabf4ff"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning for Δasg_0:\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300}\n",
            "\n",
            "Tuning for Δasg_45:\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
            "\n",
            "Results after tuning:\n",
            "MSE_Δasg0: 0.4095526353837397, r2_Δasg0: 0.02073085652550888\n",
            "MSE_Δasg45: 0.33548523506013234, r2_Δasg45: 0.06155703397901624\n",
            "\n",
            "Top 5 important features for Δasg_0:\n",
            "asg_0_pre     0.263654\n",
            "asg_45_pre    0.225466\n",
            "age           0.170403\n",
            "ΔMRD-1        0.086996\n",
            "sex           0.080589\n",
            "dtype: float64\n",
            "\n",
            "Top 5 important features for Δasg_45:\n",
            "asg_45_pre    0.421450\n",
            "age           0.223706\n",
            "asg_0_pre     0.160995\n",
            "ΔMRD-1        0.088155\n",
            "MRD-1 pre     0.050017\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eZoEM6JH7kkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OIFWaonM7kmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Prepare the polynomial features\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1']]\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_poly_train, X_poly_test, y_asg_0_train, y_asg_0_test = train_test_split(X_poly, y_asg_0, test_size=0.2, random_state=42)\n",
        "X_poly_train, X_poly_test, y_asg_45_train, y_asg_45_test = train_test_split(X_poly, y_asg_45, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the LinearRegression model for Δasg_0\n",
        "poly_model_asg_0 = LinearRegression()\n",
        "poly_model_asg_0.fit(X_poly_train, y_asg_0_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_0\n",
        "y_asg_0_poly_pred = poly_model_asg_0.predict(X_poly_test)\n",
        "mse_poly_asg_0 = mean_squared_error(y_asg_0_test, y_asg_0_poly_pred)\n",
        "r2_poly_asg_0 = r2_score(y_asg_0_test, y_asg_0_poly_pred)\n",
        "\n",
        "# Initialize and train the LinearRegression model for Δasg_45\n",
        "poly_model_asg_45 = LinearRegression()\n",
        "poly_model_asg_45.fit(X_poly_train, y_asg_45_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_45\n",
        "y_asg_45_poly_pred = poly_model_asg_45.predict(X_poly_test)\n",
        "mse_poly_asg_45 = mean_squared_error(y_asg_45_test, y_asg_45_poly_pred)\n",
        "r2_poly_asg_45 = r2_score(y_asg_45_test, y_asg_45_poly_pred)\n",
        "\n",
        "print(mse_poly_asg_0, r2_poly_asg_0, mse_poly_asg_45, r2_poly_asg_45)\n",
        "\n",
        "def get_top_features(model, feature_names, top_n=5):\n",
        "    # Get the absolute coefficients\n",
        "    coef = np.abs(model.coef_)\n",
        "\n",
        "    # Sort the coefficients in descending order\n",
        "    sorted_idx = np.argsort(coef)[::-1]\n",
        "\n",
        "    # Get the top N feature names and their coefficients\n",
        "    top_features = [(feature_names[i], coef[i]) for i in sorted_idx[:top_n]]\n",
        "\n",
        "    return top_features\n",
        "\n",
        "# Get feature names\n",
        "feature_names = poly.get_feature_names_out(X.columns)\n",
        "\n",
        "# Get top 5 features for Δasg_0 model\n",
        "top_features_asg_0 = get_top_features(poly_model_asg_0, feature_names)\n",
        "\n",
        "# Get top 5 features for Δasg_45 model\n",
        "top_features_asg_45 = get_top_features(poly_model_asg_45, feature_names)\n",
        "\n",
        "print(\"Top 5 important features for Δasg_0:\")\n",
        "for feature, importance in top_features_asg_0:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "\n",
        "print(\"\\nTop 5 important features for Δasg_45:\")\n",
        "for feature, importance in top_features_asg_45:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSf-xsvb2XTk",
        "outputId": "9de46390-d2b1-4071-a921-fa594173bc4e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7530592814193761 -0.8006176832682315 0.6962521394232071 -0.947605600889279\n",
            "Top 5 important features for Δasg_0:\n",
            "1: 25882275032.8964\n",
            "asg_45_pre: 1.9304\n",
            "sex^2: 1.0975\n",
            "sex: 1.0975\n",
            "side: 1.0378\n",
            "\n",
            "Top 5 important features for Δasg_45:\n",
            "1: 45757363910.7826\n",
            "asg_0_pre: 1.9223\n",
            "sex: 0.9390\n",
            "sex^2: 0.9390\n",
            "sex side: 0.9184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Prepare the polynomial features\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1']]\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_poly_train, X_poly_test, y_asg_0_train, y_asg_0_test = train_test_split(X_poly, y_asg_0, test_size=0.2, random_state=42)\n",
        "X_poly_train, X_poly_test, y_asg_45_train, y_asg_45_test = train_test_split(X_poly, y_asg_45, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the LinearRegression model for Δasg_0\n",
        "poly_model_asg_0 = LinearRegression()\n",
        "poly_model_asg_0.fit(X_poly_train, y_asg_0_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_0\n",
        "y_asg_0_poly_pred = poly_model_asg_0.predict(X_poly_test)\n",
        "mse_poly_asg_0 = mean_squared_error(y_asg_0_test, y_asg_0_poly_pred)\n",
        "r2_poly_asg_0 = r2_score(y_asg_0_test, y_asg_0_poly_pred)\n",
        "\n",
        "# Initialize and train the LinearRegression model for Δasg_45\n",
        "poly_model_asg_45 = LinearRegression()\n",
        "poly_model_asg_45.fit(X_poly_train, y_asg_45_train)\n",
        "\n",
        "# Predict and evaluate the model for Δasg_45\n",
        "y_asg_45_poly_pred = poly_model_asg_45.predict(X_poly_test)\n",
        "mse_poly_asg_45 = mean_squared_error(y_asg_45_test, y_asg_45_poly_pred)\n",
        "r2_poly_asg_45 = r2_score(y_asg_45_test, y_asg_45_poly_pred)\n",
        "\n",
        "# Function to get feature importance\n",
        "def get_feature_importance(model, feature_names):\n",
        "    importance = np.abs(model.coef_)\n",
        "    feature_importance = pd.DataFrame({'feature': feature_names, 'importance': importance})\n",
        "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "    return feature_importance\n",
        "\n",
        "# Get feature names from PolynomialFeatures\n",
        "feature_names = poly.get_feature_names_out(X.columns)\n",
        "\n",
        "# Get feature importance for Δasg_0\n",
        "importance_asg_0 = get_feature_importance(poly_model_asg_0, feature_names)\n",
        "\n",
        "# Get feature importance for Δasg_45\n",
        "importance_asg_45 = get_feature_importance(poly_model_asg_45, feature_names)\n",
        "\n",
        "# Display top 5 important factors for Δasg_0\n",
        "print(\"Top 5 important factors for Δasg_0:\")\n",
        "print(importance_asg_0.head())\n",
        "\n",
        "# Display top 5 important factors for Δasg_45\n",
        "print(\"\\nTop 5 important factors for Δasg_45:\")\n",
        "print(importance_asg_45.head())\n",
        "\n",
        "# Print model performance metrics\n",
        "print(f\"\\nModel performance for Δasg_0: MSE = {mse_poly_asg_0:.4f}, R2 = {r2_poly_asg_0:.4f}\")\n",
        "print(f\"Model performance for Δasg_45: MSE = {mse_poly_asg_45:.4f}, R2 = {r2_poly_asg_45:.4f}\")"
      ],
      "metadata": {
        "id": "YMNjKpwSJKnT",
        "outputId": "d9e28fab-e237-407e-caca-09f597cdfa84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 important factors for Δasg_0:\n",
            "       feature    importance\n",
            "0            1  2.588228e+10\n",
            "5   asg_45_pre  1.930433e+00\n",
            "17       sex^2  1.097531e+00\n",
            "2          sex  1.097531e+00\n",
            "3         side  1.037757e+00\n",
            "\n",
            "Top 5 important factors for Δasg_45:\n",
            "      feature    importance\n",
            "0           1  4.575736e+10\n",
            "4   asg_0_pre  1.922297e+00\n",
            "2         sex  9.389934e-01\n",
            "17      sex^2  9.389934e-01\n",
            "18   sex side  9.183934e-01\n",
            "\n",
            "Model performance for Δasg_0: MSE = 0.7531, R2 = -0.8006\n",
            "Model performance for Δasg_45: MSE = 0.6963, R2 = -0.9476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# データの準備\n",
        "X = data_relevant[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'ΔMRD-1']]\n",
        "y_asg_0 = data_relevant['Δasg_0']\n",
        "y_asg_45 = data_relevant['Δasg_45']\n",
        "\n",
        "# トレーニングデータとテストデータに分割\n",
        "X_train, X_test, y_asg_0_train, y_asg_0_test, y_asg_45_train, y_asg_45_test = train_test_split(\n",
        "    X, y_asg_0, y_asg_45, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# パイプラインの定義\n",
        "pipeline = Pipeline([\n",
        "    ('feature_selection', SelectKBest(score_func=f_regression)),\n",
        "    ('polynomial_features', PolynomialFeatures()),\n",
        "    ('linear_regression', LinearRegression())\n",
        "])\n",
        "\n",
        "# パラメータグリッドの定義\n",
        "param_grid = {\n",
        "    'feature_selection__k': [3, 5, 7, 'all'],\n",
        "    'polynomial_features__degree': [2,3,4],\n",
        "    'polynomial_features__interaction_only': [True, False],\n",
        "    'polynomial_features__include_bias': [True, False]\n",
        "}\n",
        "\n",
        "# グリッドサーチの実行（Δasg_0）\n",
        "grid_search_asg_0 = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_asg_0.fit(X_train, y_asg_0_train)\n",
        "\n",
        "# 最適なモデルの評価（Δasg_0）\n",
        "best_model_asg_0 = grid_search_asg_0.best_estimator_\n",
        "y_asg_0_pred = best_model_asg_0.predict(X_test)\n",
        "mse_asg_0 = mean_squared_error(y_asg_0_test, y_asg_0_pred)\n",
        "r2_asg_0 = r2_score(y_asg_0_test, y_asg_0_pred)\n",
        "\n",
        "# グリッドサーチの実行（Δasg_45）\n",
        "grid_search_asg_45 = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search_asg_45.fit(X_train, y_asg_45_train)\n",
        "\n",
        "# 最適なモデルの評価（Δasg_45）\n",
        "best_model_asg_45 = grid_search_asg_45.best_estimator_\n",
        "y_asg_45_pred = best_model_asg_45.predict(X_test)\n",
        "mse_asg_45 = mean_squared_error(y_asg_45_test, y_asg_45_pred)\n",
        "r2_asg_45 = r2_score(y_asg_45_test, y_asg_45_pred)\n",
        "\n",
        "# 結果の表示\n",
        "print(\"Best parameters for Δasg_0:\", grid_search_asg_0.best_params_)\n",
        "print(f\"Model performance for Δasg_0: MSE = {mse_asg_0:.4f}, R2 = {r2_asg_0:.4f}\")\n",
        "\n",
        "print(\"\\nBest parameters for Δasg_45:\", grid_search_asg_45.best_params_)\n",
        "print(f\"Model performance for Δasg_45: MSE = {mse_asg_45:.4f}, R2 = {r2_asg_45:.4f}\")\n",
        "\n",
        "# 特徴量の重要度を取得する関数\n",
        "def get_feature_importance(model, feature_names):\n",
        "    if hasattr(model, 'coef_'):\n",
        "        importance = np.abs(model.coef_)\n",
        "    elif hasattr(model, 'feature_importances_'):\n",
        "        importance = model.feature_importances_\n",
        "    else:\n",
        "        raise ValueError(\"Model does not have coef_ or feature_importances_ attribute\")\n",
        "\n",
        "    feature_importance = pd.DataFrame({'feature': feature_names, 'importance': importance})\n",
        "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "    return feature_importance\n",
        "\n",
        "# 最適なモデルの特徴量の重要度を表示\n",
        "for target, best_model in [(\"Δasg_0\", best_model_asg_0), (\"Δasg_45\", best_model_asg_45)]:\n",
        "    feature_selector = best_model.named_steps['feature_selection']\n",
        "    poly_features = best_model.named_steps['polynomial_features']\n",
        "\n",
        "    selected_features = X.columns[feature_selector.get_support()].tolist()\n",
        "    poly_feature_names = poly_features.get_feature_names_out(selected_features)\n",
        "\n",
        "    importance = get_feature_importance(best_model.named_steps['linear_regression'], poly_feature_names)\n",
        "\n",
        "    print(f\"\\nTop 5 important factors for {target}:\")\n",
        "    print(importance.head())"
      ],
      "metadata": {
        "id": "oCft1nUEJenv",
        "outputId": "68cec107-5296-4962-8ffe-5622316fb537",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Δasg_0: {'feature_selection__k': 3, 'polynomial_features__degree': 2, 'polynomial_features__include_bias': False, 'polynomial_features__interaction_only': True}\n",
            "Model performance for Δasg_0: MSE = 0.4484, R2 = -0.0721\n",
            "\n",
            "Best parameters for Δasg_45: {'feature_selection__k': 3, 'polynomial_features__degree': 2, 'polynomial_features__include_bias': True, 'polynomial_features__interaction_only': True}\n",
            "Model performance for Δasg_45: MSE = 0.2997, R2 = 0.1616\n",
            "\n",
            "Top 5 important factors for Δasg_0:\n",
            "         feature  importance\n",
            "0            sex    0.271003\n",
            "1           side    0.128015\n",
            "4  sex asg_0_pre    0.126628\n",
            "3       sex side    0.021787\n",
            "2      asg_0_pre    0.012301\n",
            "\n",
            "Top 5 important factors for Δasg_45:\n",
            "                feature  importance\n",
            "1            asg_45_pre    0.442691\n",
            "2             MRD-1 pre    0.099582\n",
            "4  asg_45_pre MRD-1 pre    0.065046\n",
            "6      MRD-1 pre ΔMRD-1    0.038618\n",
            "5     asg_45_pre ΔMRD-1    0.037715\n"
          ]
        }
      ]
    }
  ]
}