{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMswyOGwu/6/HkjUrjXk665",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/statistics_for_articles/blob/main/Refractive_change_blepharoptosis_surgery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Refractive change in blepharoptosis surgery**"
      ],
      "metadata": {
        "id": "OqObWQc1_T1U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yup3T2Lay4gD",
        "outputId": "d519be9f-53d1-4240-b75f-7286b0a40c06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 300)\n",
        "pd.set_option('display.max_rows', 300)"
      ],
      "metadata": {
        "id": "9nC8Dlyz7RBz"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂.xlsx\"\n",
        "\n",
        "data = pd.read_excel(xlsx_path, header=1)\n",
        "\n",
        "# Display the first few rows of the dataframe and its columns to understand its structure\n",
        "data"
      ],
      "metadata": {
        "id": "nVb210bozJ73",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Filter rows where surgery is bilateral (手術側 == 'B')\n",
        "bilateral_cases = data[data['手術側'] == 'B'].copy()\n",
        "unilateral_cases = data[data['手術側'] != 'B'].copy()\n",
        "unilateral_right_cases = data[data['手術側'] == 'R'].copy()\n",
        "unilateral_left_cases = data[data['手術側'] == 'L'].copy()\n",
        "print(f\"Number of bilateral cases: {len(bilateral_cases)}\")\n",
        "print(f\"Number of unilateral cases: {len(unilateral_cases)}\")\n",
        "\n",
        "# Step 2: Duplicate these rows for 'R' and 'L'\n",
        "bilateral_right_cases = bilateral_cases.copy()\n",
        "bilateral_left_cases = bilateral_cases.copy()\n",
        "\n",
        "# Assign 'R' and 'L' to the new surgery side columns\n",
        "bilateral_right_cases.loc[:, '手術側'] = 'R'\n",
        "bilateral_left_cases.loc[:, '手術側'] = 'L'\n",
        "\n",
        "# Step 3: Concatenate the modified bilateral and unilateral cases\n",
        "right_cases = pd.concat([bilateral_right_cases, unilateral_right_cases])\n",
        "left_cases = pd.concat([bilateral_left_cases, unilateral_left_cases])\n",
        "\n",
        "# Step 3: Rename and reallocate columns containing 'R' or 'L' for bilateral cases\n",
        "for column in right_cases.columns:\n",
        "    if ' R' in column:\n",
        "        # Extract the base column name without ' R'\n",
        "        new_column_name = column.replace(' R', '')\n",
        "        # Copy data to a new column without side specification\n",
        "        right_cases.loc[:, new_column_name] = right_cases[column]\n",
        "        # Drop the original ' R' column\n",
        "        right_cases.drop(column, axis=1, inplace=True)\n",
        "    elif ' L' in column:\n",
        "        # # Extract the base column name without ' L'\n",
        "        # new_column_name = column.replace(' L', '')\n",
        "        # # Copy data to a new column without side specification\n",
        "        # right_cases.loc[:, new_column_name] = right_cases[column]\n",
        "        # Drop the original ' L' column\n",
        "        right_cases.drop(column, axis=1, inplace=True)\n",
        "\n",
        "for column in left_cases.columns:\n",
        "    if ' R' in column:\n",
        "        # # Extract the base column name without ' R'\n",
        "        # new_column_name = column.replace(' R', '')\n",
        "        # # Copy data to a new column without side specification\n",
        "        # left_cases.loc[:, new_column_name] = left_cases[column]\n",
        "        # # Drop the original ' R' column\n",
        "        left_cases.drop(column, axis=1, inplace=True)\n",
        "    elif ' L' in column:\n",
        "        # Extract the base column name without ' L'\n",
        "        new_column_name = column.replace(' L', '')\n",
        "        # Copy data to a new column without side specification\n",
        "        left_cases.loc[:, new_column_name] = left_cases[column]\n",
        "        # Drop the original ' L' column\n",
        "        left_cases.drop(column, axis=1, inplace=True)\n",
        "\n",
        "# Combine the duplicated rows back into a single dataframe\n",
        "final_df = pd.concat([right_cases, left_cases])\n",
        "final_df = final_df.sort_values(by='ID').reset_index(drop=True)\n",
        "# ソート後のデータフレームを表示して確認\n",
        "#final_df\n",
        "\n",
        "#final_df.to_excel('output.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "knMc1iJR6Ciu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['波面3M'] = final_df[['波面3M', '波面4M', '波面post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['波面4M', '波面post'], inplace=True)\n",
        "    print(\"波面3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['AveK 3M'] = final_df[['AveK 3M', 'AveK post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['AveK post'], inplace=True)\n",
        "    print(\"AveK 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['CYL 3M'] = final_df[['CYL 3M', 'CYL post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['CYL post'], inplace=True)\n",
        "    print(\"CYL 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    # Copy values from '波面4M' and '波面post' to '波面3M'\n",
        "    final_df['angle 3M'] = final_df[['angle 3M', 'angle post']].bfill(axis=1).iloc[:, 0]\n",
        "\n",
        "    # Drop the columns '波面4M' and '波面post'\n",
        "    final_df.drop(columns=['angle post'], inplace=True)\n",
        "    print(\"angle 3M updated!\")\n",
        "except:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "lgJLhag6ELZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# レフケラの欠損値を削除：Drop rows with missing values only in specified columns\n",
        "specified_columns = ['AveK pre', 'AveK 3M', 'CYL pre', 'CYL 3M', 'angle pre', 'angle 3M', 'MRD-1 pre', 'MRD-1 3M']\n",
        "final_df = final_df.dropna(subset=specified_columns).reset_index(drop=True)\n",
        "\n",
        "# SPKの有無を数字に置換\n",
        "final_df[\"SPK pre\"] = final_df[\"SPK pre\"].replace({\"あり\": 1, \"なし\": 0})\n",
        "final_df[\"SPK post\"] = final_df[\"SPK post\"].replace({\"あり\": 1, \"なし\": 0})\n",
        "# 57行目の\"MRD-1 pre\"列の値を0.5に置換\n",
        "final_df.at[57, \"MRD-1 pre\"] = 0.5\n",
        "\n",
        "# 挙筋機能\"good\"のカラムを10に置換\n",
        "final_df[\"挙筋機能 pre\"] = final_df[\"挙筋機能 pre\"].replace(\"good\", 10)\n",
        "\n",
        "# \"MRD-1 3M\"列と\"挙筋機能 pre\"列をfloat型に変換\n",
        "final_df[\"MRD-1 pre\"] = final_df[\"MRD-1 pre\"].astype(float)\n",
        "final_df[\"MRD-1 3M\"] = final_df[\"MRD-1 3M\"].astype(float)\n",
        "final_df[\"挙筋機能 pre\"] = final_df[\"挙筋機能 pre\"].astype(float)\n",
        "\n",
        "final_df[\"sex\"] = final_df[\"sex\"].replace({\"M\": 1, \"F\": 0})\n",
        "final_df[\"手術側\"] = final_df[\"手術側\"].replace({\"L\": 1, \"R\": 0})\n",
        "\n",
        "final_df"
      ],
      "metadata": {
        "id": "Fb8lFR0bz-vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_excel('output.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "qc9S9nxE3N49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8qITWJ6y4Ox8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessed_dataを用いて解析**"
      ],
      "metadata": {
        "id": "lns4IjGOVq77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J5sUBakWORy",
        "outputId": "2b5ce16e-3284-4a51-8c8c-bb2819182de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 300)\n",
        "pd.set_option('display.max_rows', 300)"
      ],
      "metadata": {
        "id": "C-JwDuMtWLWr"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "xlsx_path = \"/content/drive/MyDrive/研究/進行中の研究/眼瞼下垂手術による屈折変化/眼瞼下垂_proprocessed.xlsx\"\n",
        "\n",
        "data = pd.read_excel(xlsx_path, header=0)\n",
        "\n",
        "# Display the first few rows of the dataframe and its columns to understand its structure\n",
        "data.head()"
      ],
      "metadata": {
        "id": "12LgQoOAWQqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Linear regression analysis**"
      ],
      "metadata": {
        "id": "tpw9-FE4e8JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the dataset for linear regression analysis\n",
        "features = data[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function', 'SPK pre', 'SPK post']].dropna()\n",
        "#features = data[[ 'MRD-1 pre', 'MRD-1 3M']].dropna()\n",
        "\n",
        "target_delta_asg_0 = data.loc[features.index, 'Δasg_0']\n",
        "target_delta_asg_45 = data.loc[features.index, 'Δasg_45']\n",
        "\n",
        "# Initialize and fit the linear regression model for Δasg_0\n",
        "model_delta_asg_0 = LinearRegression()\n",
        "model_delta_asg_0.fit(features, target_delta_asg_0)\n",
        "coefficients_delta_asg_0 = model_delta_asg_0.coef_\n",
        "intercept_delta_asg_0 = model_delta_asg_0.intercept_\n",
        "\n",
        "# Initialize and fit the linear regression model for Δasg_45\n",
        "model_delta_asg_45 = LinearRegression()\n",
        "model_delta_asg_45.fit(features, target_delta_asg_45)\n",
        "coefficients_delta_asg_45 = model_delta_asg_45.coef_\n",
        "intercept_delta_asg_45 = model_delta_asg_45.intercept_\n",
        "\n",
        "# Show the results\n",
        "coefficients_delta_asg_0, intercept_delta_asg_0, coefficients_delta_asg_45, intercept_delta_asg_45\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsQN9jsYaHMR",
        "outputId": "2c78b532-39be-4301-c68c-20aca63d5211"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.00634443,  0.05265332,  0.05265332, -0.24818408,  0.09932661,\n",
              "         0.03110451, -0.02486901, -0.02776211,  0.05888294, -0.11236059]),\n",
              " 0.9794846199432152,\n",
              " array([-0.00056709, -0.06852279, -0.06852279,  0.05860446, -0.48123104,\n",
              "        -0.04605825, -0.04091017, -0.00151304, -0.01322485,  0.20624885]),\n",
              " 0.14322984395180194)"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import f_regression\n",
        "\n",
        "# Calculate p-values for both models\n",
        "p_values_delta_asg_0 = f_regression(features, target_delta_asg_0)[1]\n",
        "p_values_delta_asg_45 = f_regression(features, target_delta_asg_45)[1]\n",
        "\n",
        "p_values_delta_asg_0, p_values_delta_asg_45\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUpqrhRReGnt",
        "outputId": "54640f43-70cc-4d8c-f7b0-f9d149bf0cee"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([7.96460806e-02, 4.67203463e-01, 4.67203463e-01, 5.83804838e-08,\n",
              "        6.85150742e-01, 4.66708849e-01, 9.97209203e-01, 1.21682678e-01,\n",
              "        6.94852999e-01, 8.75242698e-01]),\n",
              " array([5.61570861e-01, 8.43617019e-01, 8.43617019e-01, 9.95111437e-01,\n",
              "        1.48893741e-12, 2.65766276e-01, 9.19529483e-01, 5.19321704e-01,\n",
              "        3.34418383e-01, 8.11639669e-02]))"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the columns that are present\n",
        "summary = features.describe()\n",
        "\n",
        "summary\n"
      ],
      "metadata": {
        "id": "n5lkXuwTaEiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating a DataFrame to display coefficients and p-values for Δasg_0 and Δasg_45\n",
        "\n",
        "# Coefficients and intercepts\n",
        "coeffs_delta_asg_0 = pd.Series(coefficients_delta_asg_0, index=features.columns, name='Coefficients Δasg_0')\n",
        "coeffs_delta_asg_45 = pd.Series(coefficients_delta_asg_45, index=features.columns, name='Coefficients Δasg_45')\n",
        "intercept_delta_asg_0 = pd.Series([intercept_delta_asg_0], index=['Intercept'], name='Coefficients Δasg_0')\n",
        "intercept_delta_asg_45 = pd.Series([intercept_delta_asg_45], index=['Intercept'], name='Coefficients Δasg_45')\n",
        "\n",
        "# p-values\n",
        "p_values_delta_asg_0 = pd.Series(p_values_delta_asg_0, index=features.columns, name='p-values Δasg_0')\n",
        "p_values_delta_asg_45 = pd.Series(p_values_delta_asg_45, index=features.columns, name='p-values Δasg_45')\n",
        "\n",
        "# Combine all data into one DataFrame for each target\n",
        "results_delta_asg_0 = pd.concat([intercept_delta_asg_0, coeffs_delta_asg_0, p_values_delta_asg_0], axis=1)\n",
        "results_delta_asg_45 = pd.concat([intercept_delta_asg_45, coeffs_delta_asg_45, p_values_delta_asg_45], axis=1)\n",
        "\n",
        "# Combine results into one DataFrame for easy display\n",
        "results = pd.concat([results_delta_asg_0, results_delta_asg_45], axis=1)\n",
        "results\n"
      ],
      "metadata": {
        "id": "tbjHAtmgd9Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Formatting the DataFrame to display p-values with decimal points\n",
        "results_formatted = results.copy()\n",
        "\n",
        "# Formatting p-values for better readability\n",
        "results_formatted['p-values Δasg_0'] = results['p-values Δasg_0'].map('{:.4f}'.format)\n",
        "results_formatted['p-values Δasg_45'] = results['p-values Δasg_45'].map('{:.4f}'.format)\n",
        "\n",
        "results_formatted\n"
      ],
      "metadata": {
        "id": "Po1dcqFzecKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**線形回帰モデルのAIC（赤池情報量基準）を用いた多変量解析**"
      ],
      "metadata": {
        "id": "ZVpI77ECfi65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Define the independent variables for the model\n",
        "X = features\n",
        "# Add a constant to the model (the intercept)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Define the dependent variable for Δasg_0\n",
        "y_delta_asg_0 = target_delta_asg_0\n",
        "\n",
        "# Fit the model\n",
        "model_delta_asg_0 = sm.OLS(y_delta_asg_0, X).fit()\n",
        "\n",
        "# Define the dependent variable for Δasg_45\n",
        "y_delta_asg_45 = target_delta_asg_45\n",
        "\n",
        "# Fit the model\n",
        "model_delta_asg_45 = sm.OLS(y_delta_asg_45, X).fit()\n",
        "\n",
        "# Get AIC values\n",
        "aic_delta_asg_0 = model_delta_asg_0.aic\n",
        "aic_delta_asg_45 = model_delta_asg_45.aic\n",
        "\n",
        "aic_delta_asg_0, aic_delta_asg_45, model_delta_asg_0.summary(), model_delta_asg_45.summary()\n"
      ],
      "metadata": {
        "id": "GXlVc5ZYfHu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**asg_0_preの外れ値を除外して計算**"
      ],
      "metadata": {
        "id": "lshOwhli7r8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#######################\n",
        "# asg_0_preの外れ値を除外して計算する\n",
        "#######################\n",
        "# Analyzing outliers based on quartile range\n",
        "Q1 = data['asg_0_pre'].quantile(0.25)\n",
        "Q3 = data['asg_0_pre'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define outliers as points outside of Q1 - 1.5*IQR and Q3 + 1.5*IQR\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filtering data to exclude these outliers\n",
        "quartile_filtered_data = data[(data['asg_0_pre'] >= lower_bound) & (data['asg_0_pre'] <= upper_bound)]\n",
        "quartile_filtered_data['asg_0_pre'].describe()\n"
      ],
      "metadata": {
        "id": "c2DlxJ-p1S5A",
        "outputId": "2a6359ff-c7c8-4e9b-d2fd-f35763c45299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    184.000000\n",
              "mean      -0.081356\n",
              "std        0.982539\n",
              "min       -2.525611\n",
              "25%       -0.715772\n",
              "50%       -0.085730\n",
              "75%        0.532146\n",
              "max        2.377641\n",
              "Name: asg_0_pre, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Selecting the filtered data and necessary columns for regression\n",
        "regression_data = quartile_filtered_data[['Δasg_0', 'age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']].dropna()\n",
        "\n",
        "# Define the predictor variables and the target variable\n",
        "X = regression_data[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']]\n",
        "y = regression_data['Δasg_0']\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Creating a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "(mse, r2)\n"
      ],
      "metadata": {
        "id": "8-CRaC_z37UH",
        "outputId": "c58ff0ff-d8ac-497a-f511-0e7cac9a1a01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5053517400965294, -0.11628637059119318)"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Adding a constant for the intercept term\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "\n",
        "# Fitting the regression model using statsmodels to get the coefficients and p-values\n",
        "model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
        "\n",
        "# Display the model summary which includes coefficients, p-values, and other diagnostics\n",
        "model_summary = model_sm.summary()\n",
        "model_summary\n"
      ],
      "metadata": {
        "id": "NUxbqv_K4lzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# Function to calculate the AIC for a given set of predictor variables\n",
        "def calculate_aic(X, y):\n",
        "    model = sm.OLS(y, sm.add_constant(X)).fit()\n",
        "    return model.aic\n",
        "\n",
        "# List of all predictor variables\n",
        "predictors = ['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']\n",
        "\n",
        "# Generate all possible combinations of predictor variables\n",
        "predictor_combinations = []\n",
        "for L in range(1, len(predictors)+1):\n",
        "    for subset in itertools.combinations(predictors, L):\n",
        "        predictor_combinations.append(list(subset))\n",
        "\n",
        "# Calculate AIC for each combination and store results\n",
        "aic_results = []\n",
        "for combo in predictor_combinations:\n",
        "    aic = calculate_aic(X[combo], y)\n",
        "    aic_results.append((aic, combo))\n",
        "\n",
        "# Find the combination with the lowest AIC\n",
        "best_aic = min(aic_results, key=lambda x: x[0])\n",
        "best_aic\n"
      ],
      "metadata": {
        "id": "WpIOMNtr5Aik",
        "outputId": "158d1267-bf57-4cfc-baf7-a6897b38551f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(340.41738022236524, ['asg_0_pre'])"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the predictor variable (only 'asg_0_pre') and the target variable\n",
        "X_single = regression_data[['asg_0_pre']]\n",
        "y_single = regression_data['Δasg_0']\n",
        "\n",
        "# Adding a constant for the intercept term\n",
        "X_single_sm = sm.add_constant(X_single)\n",
        "\n",
        "# Fitting the regression model using statsmodels\n",
        "model_single = sm.OLS(y_single, X_single_sm).fit()\n",
        "\n",
        "# Display the model summary\n",
        "model_single_summary = model_single.summary()\n",
        "model_single_summary\n"
      ],
      "metadata": {
        "id": "zhR-S11Z5WVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform linear regression for each predictor variable separately and summarize the results\n",
        "def perform_linear_regression_for_each_predictor(X, y):\n",
        "    results = []\n",
        "    for predictor in X.columns:\n",
        "        X_single = X[[predictor]]  # Selecting single predictor\n",
        "        X_single_sm = sm.add_constant(X_single)  # Adding constant for intercept\n",
        "\n",
        "        model = sm.OLS(y, X_single_sm).fit()  # Fitting the model\n",
        "        results.append({\n",
        "            'Predictor': predictor,\n",
        "            'Coefficient': model.params[predictor],\n",
        "            'P-Value': model.pvalues[predictor],\n",
        "            'R-Squared': model.rsquared,\n",
        "            'AIC': model.aic\n",
        "        })\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Applying the function to the regression data\n",
        "predictors_data = regression_data[['age', 'sex', 'side', 'asg_0_pre', 'asg_45_pre', 'MRD-1 pre', 'MRD-1 3M', 'levator_function']]\n",
        "results_summary = perform_linear_regression_for_each_predictor(predictors_data, y_single)\n",
        "results_summary\n"
      ],
      "metadata": {
        "id": "l78REYWq6ZF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Random forest analysis**"
      ],
      "metadata": {
        "id": "gqdt-ZxZgOp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Prepare data\n",
        "X_train, X_test, y_train_delta_asg_0, y_test_delta_asg_0 = train_test_split(X, y_delta_asg_0, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train_delta_asg_45, y_test_delta_asg_45 = train_test_split(X, y_delta_asg_45, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the Random Forest model for Δasg_0\n",
        "rf_model_delta_asg_0 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model_delta_asg_0.fit(X_train, y_train_delta_asg_0)\n",
        "\n",
        "# Predictions and evaluation for Δasg_0\n",
        "predictions_delta_asg_0 = rf_model_delta_asg_0.predict(X_test)\n",
        "mse_delta_asg_0 = mean_squared_error(y_test_delta_asg_0, predictions_delta_asg_0)\n",
        "r2_delta_asg_0 = r2_score(y_test_delta_asg_0, predictions_delta_asg_0)\n",
        "\n",
        "# Initialize and fit the Random Forest model for Δasg_45\n",
        "rf_model_delta_asg_45 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model_delta_asg_45.fit(X_train, y_train_delta_asg_45)\n",
        "\n",
        "# Predictions and evaluation for Δasg_45\n",
        "predictions_delta_asg_45 = rf_model_delta_asg_45.predict(X_test)\n",
        "mse_delta_asg_45 = mean_squared_error(y_test_delta_asg_45, predictions_delta_asg_45)\n",
        "r2_delta_asg_45 = r2_score(y_test_delta_asg_45, predictions_delta_asg_45)\n",
        "\n",
        "print(f\"MSE_0: {mse_delta_asg_0}, R2_0: {r2_delta_asg_0}, MSE_45: {mse_delta_asg_45}, R2_45: {r2_delta_asg_45}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "nC4xXQa6gWDc",
        "outputId": "44b2f738-acac-4df2-e5e6-5a47ec573637"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [184, 189]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-261-9162d286aed3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_delta_asg_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_delta_asg_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_delta_asg_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_delta_asg_45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_delta_asg_45\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_delta_asg_45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2559\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [184, 189]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance from the Random Forest models\n",
        "importances_delta_asg_0 = rf_model_delta_asg_0.feature_importances_\n",
        "importances_delta_asg_45 = rf_model_delta_asg_45.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importance\n",
        "feature_importance_delta_asg_0 = pd.Series(importances_delta_asg_0, index=X.columns).sort_values(ascending=False)\n",
        "feature_importance_delta_asg_45 = pd.Series(importances_delta_asg_45, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "print(feature_importance_delta_asg_0)\n",
        "print(\"\")\n",
        "print(feature_importance_delta_asg_45)\n"
      ],
      "metadata": {
        "id": "oheoSDwQgpYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Extract one tree from the Random Forest model for Δasg_45\n",
        "tree_example = rf_model_delta_asg_0.estimators_[0]\n",
        "\n",
        "# Export the tree in DOT format\n",
        "dot_data = export_graphviz(tree_example, out_file=None,\n",
        "                           feature_names=X.columns,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "\n",
        "# Generate a graph from DOT data\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "metadata": {
        "id": "MaRhgHorhugH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the graph to a file\n",
        "graph_path = '/content/graph.dot'\n",
        "graph.render(graph_path)\n",
        "\n",
        "# Provide the path to the saved graph file\n",
        "graph_path + '.pdf'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CDS9c11jkJ3X",
        "outputId": "fcdf57f4-54c3-4127-ce2e-f381738f8454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/graph.dot.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Extract one tree from the Random Forest model for Δasg_45\n",
        "tree_example = rf_model_delta_asg_45.estimators_[0]\n",
        "\n",
        "# Export the tree in DOT format\n",
        "dot_data = export_graphviz(tree_example, out_file=None,\n",
        "                           feature_names=X.columns,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "\n",
        "# Generate a graph from DOT data\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph\n"
      ],
      "metadata": {
        "id": "Gt7dUKb5hRAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MRD-1 preとMRD-1 3Mのプロット（Δasg-0で色分けあり）\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(data['MRD-1 3M'], data['MRD-1 pre'], c=data['Δasg_0'], cmap='viridis')\n",
        "plt.colorbar(scatter, label='Δasg_0')\n",
        "\n",
        "plt.title('Scatter Plot of MRD-1 pre vs MRD-1 3M with Δasg_0 Color Coding')\n",
        "plt.xlabel('MRD-1 3M')\n",
        "plt.ylabel('MRD-1 pre')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GegUf6ipx6NG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}